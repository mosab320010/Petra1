# Petra1

import os
import json
from datetime import datetime

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_config_file():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù config.yaml"""
    content = """# BTEC EduverseAI - Main Configuration
# Main configuration file for the system

# Application Information
app:
  name: "BTEC EduverseAI"
  version: "1.0.0"
  description: "Intelligent Educational Management System"
  debug: false
  environment: "production"
  timezone: "UTC"
  language: "en"
  
# Server Settings
server:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  reload: false
  log_level: "info"
  access_log: true
  
# Database
database:
  type: "postgresql"
  host: "${DB_HOST:localhost}"
  port: "${DB_PORT:5432}"
  name: "${DB_NAME:eduverseai}"
  username: "${DB_USER:eduverseai}"
  password: "${DB_PASSWORD:}"
  pool_size: 20
  max_overflow: 30
  echo: false
  
# Redis for caching
redis:
  host: "${REDIS_HOST:localhost}"
  port: "${REDIS_PORT:6379}"
  db: 0
  password: "${REDIS_PASSWORD:}"
  max_connections: 50
  
# Security and Authentication
security:
  secret_key: "${SECRET_KEY:your-secret-key-here}"
  algorithm: "HS256"
  access_token_expire_minutes: 30
  refresh_token_expire_days: 7
  password_min_length: 8
  max_login_attempts: 5
  lockout_duration_minutes: 15
  
# AI Settings
ai:
  models_path: "./data/models"
  max_batch_size: 32
  inference_timeout: 30
  cache_predictions: true
  
  # NLP Model
  nlp:
    model_name: "bert-base-uncased"
    max_sequence_length: 512
    
  # Recommendation Engine
  recommendations:
    algorithm: "collaborative_filtering"
    min_interactions: 5
    max_recommendations: 10
    
# Email
email:
  smtp_server: "${SMTP_SERVER:smtp.gmail.com}"
  smtp_port: "${SMTP_PORT:587}"
  username: "${EMAIL_USER:}"
  password: "${EMAIL_PASSWORD:}"
  use_tls: true
  from_email: "${FROM_EMAIL:noreply@eduverseai.com}"
  from_name: "BTEC EduverseAI"
  
# File Uploads
uploads:
  max_file_size: 10485760  # 10MB
  allowed_extensions: [".pdf", ".docx", ".pptx", ".jpg", ".png", ".mp4", ".mp3"]
  upload_path: "./data/uploads"
  
# Monitoring and Logging
monitoring:
  enable_metrics: true
  metrics_port: 9090
  log_level: "INFO"
  log_format: "json"
  log_file: "./data/logs/app.log"
  max_log_size: "100MB"
  backup_count: 5
  
# Caching
cache:
  default_timeout: 300  # 5 minutes
  user_session_timeout: 1800  # 30 minutes
  course_data_timeout: 3600  # 1 hour
  
# Performance Settings
performance:
  max_concurrent_requests: 1000
  request_timeout: 30
  enable_compression: true
  static_files_cache: 86400  # 24 hours
  
# Backup
backup:
  enabled: true
  schedule: "0 2 * * *"  # Daily at 2 AM
  retention_days: 30
  storage_path: "./data/backups"
  
# Development Settings
development:
  auto_reload: true
  debug_toolbar: true
  profiling: false
  mock_external_apis: false
  
# Production Settings
production:
  enable_https: true
  ssl_cert_path: "/etc/ssl/certs/eduverseai.crt"
  ssl_key_path: "/etc/ssl/private/eduverseai.key"
  enable_rate_limiting: true
  rate_limit: "100/minute"
  
# External Services
external_services:
  # Cloud Storage Service
  cloud_storage:
    provider: "aws"  # aws, azure, gcp
    bucket_name: "${CLOUD_STORAGE_BUCKET:}"
    region: "${CLOUD_STORAGE_REGION:us-east-1}"
    
  # Notification Service
  notifications:
    push_service: "firebase"
    api_key: "${PUSH_NOTIFICATIONS_API_KEY:}"
    
# Content Settings
content:
  default_language: "en"
  supported_languages: ["en", "ar"]
  max_course_size: 1073741824  # 1GB
  video_processing: true
  auto_transcription: false
  
# Assessment Settings
assessment:
  max_attempts: 3
  time_limit_default: 60  # minutes
  auto_save_interval: 30  # seconds
  plagiarism_check: true
  
# Analytics
analytics:
  enable_tracking: true
  data_retention_days: 365
  anonymize_data: true
  export_formats: ["json", "csv", "xlsx"]
"""
    file_path = os.path.join(base_path, "config.yaml")
    return write_file_safely(file_path, content)

def create_docker_compose_file():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù docker-compose.yml"""
    content = """version: '3.8'

services:
  # Main BTEC EduverseAI Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: eduverseai-app
    ports:
      - "8000:8000"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=eduverseai
      - DB_USER=eduverseai
      - DB_PASSWORD=eduverseai_password
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - SECRET_KEY=your-super-secret-key-change-in-production
    depends_on:
      - postgres
      - redis
    volumes:
      - ./data/uploads:/app/data/uploads
      - ./data/logs:/app/data/logs
      - ./data/backups:/app/data/backups
    networks:
      - eduverseai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: eduverseai-postgres
    environment:
      - POSTGRES_DB=eduverseai
      - POSTGRES_USER=eduverseai
      - POSTGRES_PASSWORD=eduverseai_password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/migrations:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - eduverseai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U eduverseai -d eduverseai"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Caching
  redis:
    image: redis:7-alpine
    container_name: eduverseai-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - eduverseai-network
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Frontend Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: eduverseai-frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_WS_URL=ws://localhost:8000
    depends_on:
      - app
    networks:
      - eduverseai-network
    restart: unless-stopped
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: eduverseai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./config/nginx/ssl:/etc/nginx/ssl
      - ./frontend/build:/usr/share/nginx/html
    depends_on:
      - app
      - frontend
    networks:
      - eduverseai-network
    restart: unless-stopped

  # Prometheus for Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: eduverseai-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    networks:
      - eduverseai-network
    restart: unless-stopped

  # Grafana for Visualization
  grafana:
    image: grafana/grafana:latest
    container_name: eduverseai-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - eduverseai-network
    restart: unless-stopped

  # Celery for Background Tasks
  celery:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: eduverseai-celery
    command: celery -A src.core.celery worker --loglevel=info
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=eduverseai
      - DB_USER=eduverseai
      - DB_PASSWORD=eduverseai_password
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./data/uploads:/app/data/uploads
      - ./data/logs:/app/data/logs
    networks:
      - eduverseai-network
    restart: unless-stopped

# Networks
networks:
  eduverseai-network:
    driver: bridge

# Volumes
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
"""
    file_path = os.path.join(base_path, "docker-compose.yml")
    return write_file_safely(file_path, content)

def create_dockerfile():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Dockerfile"""
    content = """# Use Python 3.11 as base image
FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app

# Set work directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    g++ \\
    curl \\
    postgresql-client \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements file and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY . .

# Create data directories
RUN mkdir -p /app/data/uploads /app/data/logs /app/data/backups

# Set permissions
RUN chmod +x scripts/setup/install.py
RUN chmod +x run.py

# Create non-root user
RUN useradd --create-home --shell /bin/bash app
RUN chown -R app:app /app
USER app

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["python", "run.py"]
"""
    file_path = os.path.join(base_path, "Dockerfile")
    return write_file_safely(file_path, content)

def create_env_example_file():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù .env.example"""
    content = """# BTEC EduverseAI - Environment Variables
# Copy this file to .env and modify values according to your environment

# ==============================================
# Basic Application Settings
# ==============================================
APP_NAME="BTEC EduverseAI"
APP_VERSION="1.0.0"
APP_ENVIRONMENT="development"  # development, staging, production
APP_DEBUG="true"
APP_TIMEZONE="UTC"
APP_LANGUAGE="en"

# ==============================================
# Server Settings
# ==============================================
HOST="0.0.0.0"
PORT="8000"
WORKERS="4"
RELOAD="true"
LOG_LEVEL="info"

# ==============================================
# Database
# ==============================================
DB_TYPE="postgresql"
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="eduverseai"
DB_USER="eduverseai"
DB_PASSWORD="your_database_password_here"
DB_POOL_SIZE="20"
DB_MAX_OVERFLOW="30"
DB_ECHO="false"

# ==============================================
# Redis for Caching
# ==============================================
REDIS_HOST="localhost"
REDIS_PORT="6379"
REDIS_DB="0"
REDIS_PASSWORD=""
REDIS_MAX_CONNECTIONS="50"

# ==============================================
# Security and Authentication
# ==============================================
SECRET_KEY="your-super-secret-key-change-this-in-production"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES="30"
REFRESH_TOKEN_EXPIRE_DAYS="7"
PASSWORD_MIN_LENGTH="8"
MAX_LOGIN_ATTEMPTS="5"
LOCKOUT_DURATION_MINUTES="15"

# ==============================================
# Email
# ==============================================
SMTP_SERVER="smtp.gmail.com"
SMTP_PORT="587"
EMAIL_USER="your_email@gmail.com"
EMAIL_PASSWORD="your_email_password"
EMAIL_USE_TLS="true"
FROM_EMAIL="noreply@eduverseai.com"
FROM_NAME="BTEC EduverseAI"

# ==============================================
# External Services
# ==============================================
# AWS S3
AWS_ACCESS_KEY_ID="your_aws_access_key"
AWS_SECRET_ACCESS_KEY="your_aws_secret_key"
AWS_REGION="us-east-1"
AWS_BUCKET_NAME="eduverseai-storage"

# Google Cloud
GOOGLE_CLOUD_PROJECT_ID="your_project_id"
GOOGLE_CLOUD_STORAGE_BUCKET="eduverseai-storage"

# Azure
AZURE_STORAGE_ACCOUNT_NAME="your_storage_account"
AZURE_STORAGE_ACCOUNT_KEY="your_storage_key"
AZURE_CONTAINER_NAME="eduverseai-storage"

# ==============================================
# AI Services
# ==============================================
OPENAI_API_KEY="your_openai_api_key"
HUGGINGFACE_API_KEY="your_huggingface_api_key"
GOOGLE_AI_API_KEY="your_google_ai_api_key"

# ==============================================
# Notifications
# ==============================================
FIREBASE_API_KEY="your_firebase_api_key"
FIREBASE_PROJECT_ID="your_firebase_project_id"
PUSH_NOTIFICATIONS_API_KEY="your_push_notifications_key"

# ==============================================
# Monitoring and Analytics
# ==============================================
SENTRY_DSN="your_sentry_dsn"
GOOGLE_ANALYTICS_ID="your_ga_id"
PROMETHEUS_ENABLED="true"
PROMETHEUS_PORT="9090"

# ==============================================
# Storage and Files
# ==============================================
UPLOAD_MAX_SIZE="10485760"  # 10MB
UPLOAD_PATH="./data/uploads"
STATIC_FILES_PATH="./static"
MEDIA_FILES_PATH="./media"

# ==============================================
# Backup
# ==============================================
BACKUP_ENABLED="true"
BACKUP_SCHEDULE="0 2 * * *"  # Daily at 2 AM
BACKUP_RETENTION_DAYS="30"
BACKUP_STORAGE_PATH="./data/backups"

# ==============================================
# Performance Settings
# ==============================================
MAX_CONCURRENT_REQUESTS="1000"
REQUEST_TIMEOUT="30"
ENABLE_COMPRESSION="true"
STATIC_FILES_CACHE="86400"  # 24 hours

# ==============================================
# SSL/HTTPS Settings
# ==============================================
ENABLE_HTTPS="false"
SSL_CERT_PATH="/etc/ssl/certs/eduverseai.crt"
SSL_KEY_PATH="/etc/ssl/private/eduverseai.key"

# ==============================================
# Development Settings
# ==============================================
AUTO_RELOAD="true"
DEBUG_TOOLBAR="true"
PROFILING="false"
MOCK_EXTERNAL_APIS="false"

# ==============================================
# Testing Settings
# ==============================================
TEST_DATABASE_URL="postgresql://test_user:test_pass@localhost:5432/test_eduverseai"
TEST_REDIS_URL="redis://localhost:6379/1"
"""
    file_path = os.path.join(base_path, ".env.example")
    return write_file_safely(file_path, content)

# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
files_to_create = [
    ("config.yaml", create_config_file),
    ("docker-compose.yml", create_docker_compose_file),
    ("Dockerfile", create_dockerfile),
    (".env.example", create_env_example_file),
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")

created_files_count = 0
for filename, create_function in files_to_create:
    print(f"ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {filename}...")
    if create_function():
        created_files_count += 1
        file_path = os.path.join(base_path, filename)
        size = os.path.getsize(file_path)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {filename} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
    else:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {filename}.")

print(f"\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_files_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(files_to_create)} Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø°Ø±ÙŠØ© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø°Ø±ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©:")
all_root_files = [
    "README.md", "requirements.txt", "setup.py", "config.yaml", 
    "docker-compose.yml", "Dockerfile", ".env.example", 
    ".gitignore", "LICENSE", "CHANGELOG.md", "run.py"
]

existing_files_after_run = []
missing_files_after_run = []

for file in all_root_files:
    file_path = os.path.join(base_path, file)
    if os.path.exists(file_path):
        size = os.path.getsize(file_path)
        existing_files_after_run.append(file)
        print(f"  âœ… {file} ({size} bytes)")
    else:
        missing_files_after_run.append(file)
        print(f"  âŒ {file} (Ù…ÙÙ‚ÙˆØ¯)")

print(f"\nğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
print(f"  ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©: {len(existing_files_after_run)}/{len(all_root_files)}")
print(f"  ğŸ“Š Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„: {(len(existing_files_after_run)/len(all_root_files)*100):.1f}%")

if missing_files_after_run:
    print(f"  âš ï¸  Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {', '.join(missing_files_after_run)}")
else:
    print("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø°Ø±ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­!")

print("\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ ÙÙŠ Ù…Ø¬Ù„Ø¯ src...")
-----

### ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ (Ù…Ø¬Ù„Ø¯ `src`)

Ø¨Ø¹Ø¯ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø°Ø±ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `src`. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù‡ÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ Ù„ØªØ·Ø¨ÙŠÙ‚ `BTEC EduverseAI`ØŒ Ø­ÙŠØ« ØªØªØ¶Ù…Ù† Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØŒ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ ÙˆÙ†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù€ API.

Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙƒÙ…Ø«Ø§Ù„:

  * `src/core/app.py`: Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ·Ø¨ÙŠÙ‚ FastAPI.
  * `src/core/config.py`: Ù„ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†.
  * `src/ai/models/nlp_model.py`: Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©.
  * `src/api/routes/auth_routes.py`: Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù€ API Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø©.
  * `src/utils/logger.py`: Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ø±Ø³Ø§Ø¦Ù„.

-----

### ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src`

```python
import os

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡."""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_src_core_app_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/core/app.py"""
    content = """from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.staticfiles import StaticFiles
from fastapi.routing import APIRoute
from pydantic import BaseModel
from typing import List, Optional
import os
import sys
from pathlib import Path
import uvicorn
import logging

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± src Ø¥Ù„Ù‰ Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.config import settings
from core.database import database, check_database_connection
from core.cache import redis_client, check_redis_connection
from api.routes import auth_routes, student_routes, course_routes, assessment_routes, analytics_routes
from utils.logger import setup_logging
from management.admin import admin_panel # Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹ Ù„Ø±Ø¨Ø· ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (logging)
setup_logging(log_level=settings.LOG_LEVEL, log_file=settings.LOG_FILE)
logger = logging.getLogger(__name__)

# ØªØ®ØµÙŠØµ Ø§Ø³Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© (Endpoints) ÙÙŠ Swagger UI
def custom_generate_unique_id(route: APIRoute):
    return f"{route.tags[0]}-{route.name}"

# ØªÙ‡ÙŠØ¦Ø© ØªØ·Ø¨ÙŠÙ‚ FastAPI
app = FastAPI(
    title=settings.APP_NAME,
    description=settings.APP_DESCRIPTION,
    version=settings.APP_VERSION,
    debug=settings.APP_DEBUG,
    docs_url="/docs" if settings.APP_ENVIRONMENT == "development" else None,
    redoc_url="/redoc" if settings.APP_ENVIRONMENT == "development" else None,
    openapi_url="/openapi.json" if settings.APP_ENVIRONMENT == "development" else None,
    generate_unique_id_function=custom_generate_unique_id
)

# ØªØ¶Ù…ÙŠÙ† Ù…Ø³Ø§Ø±Ø§Øª API
app.include_router(auth_routes.router, prefix="/api/v1/auth", tags=["Auth"])
app.include_router(student_routes.router, prefix="/api/v1/students", tags=["Students"])
app.include_router(course_routes.router, prefix="/api/v1/courses", tags=["Courses"])
app.include_router(assessment_routes.router, prefix="/api/v1/assessments", tags=["Assessments"])
app.include_router(analytics_routes.router, prefix="/api/v1/analytics", tags=["Analytics"])

# ØªØ±ÙƒÙŠØ¨ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ© (frontend build Ø£Ùˆ static files)
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ø³Ø§Ø± 'frontend/build' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¹Ø¯ Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©
frontend_build_path = Path(__file__).parent.parent.parent / "frontend" / "build"
if frontend_build_path.is_dir():
    app.mount("/static", StaticFiles(directory=frontend_build_path / "static"), name="static")
    logger.info(f"Frontend static files mounted from: {frontend_build_path / 'static'}")
else:
    logger.warning(f"Frontend build directory not found at {frontend_build_path}. Static files might not be served.")
    # Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°Ù„ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ±ÙƒÙŠØ¨ Ù…Ø¬Ù„Ø¯ ÙˆÙ‡Ù…ÙŠ Ø£Ùˆ Ø§Ù„ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ø®Ø¯Ù…Ø©

# Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
@app.get("/health", summary="Health Check", tags=["System"])
async def health_check():
    db_status = await check_database_connection()
    redis_status = await check_redis_connection()
    return {
        "status": "healthy",
        "database": "connected" if db_status else "disconnected",
        "redis": "connected" if redis_status else "disconnected",
        "timestamp": datetime.now().isoformat(),
        "version": settings.APP_VERSION
    }

# Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ù„Ø®Ø¯Ù…Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (SPA fallback)
@app.get("/{full_path:path}", response_class=HTMLResponse, include_in_schema=False)
async def serve_frontend(full_path: str):
    html_file = frontend_build_path / "index.html"
    if html_file.is_file():
        return HTMLResponse(content=html_file.read_text(encoding="utf-8"))
    logger.error(f"Frontend index.html not found at {html_file}")
    raise HTTPException(status_code=404, detail="Frontend application not found")

@app.on_event("startup")
async def startup_event():
    logger.info("Application startup event triggered.")
    await database.connect()
    logger.info("Database connection established.")

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("Application shutdown event triggered.")
    await database.disconnect()
    logger.info("Database connection closed.")

# Ø¯Ø§Ù„Ø© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø© (Ù„Ù€ run.py)
def run_server():
    logger.info(f"Starting Uvicorn server for {settings.APP_NAME}...")
    uvicorn.run(
        "src.core.app:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.RELOAD,
        workers=settings.WORKERS if not settings.RELOAD else 1, # workers > 1 conflict with reload
        log_level=settings.LOG_LEVEL.lower(),
        access_log=settings.ACCESS_LOG,
        loop="asyncio"
    )

if __name__ == "__main__":
    # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡ Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ src/core/app.py Ù…Ø¨Ø§Ø´Ø±Ø©
    # Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ø§ ÙŠØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ù…Ù† Ø®Ù„Ø§Ù„ run.py Ø£Ùˆ docker-compose
    print("This file is usually run via 'run.py' or 'docker-compose up'.")
    print("To run directly for development, use 'python -m uvicorn src.core.app:app --reload'")
    run_server()
"""
    file_path = os.path.join(base_path, "src", "core", "app.py")
    return write_file_safely(file_path, content)

def create_src_core_config_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/core/config.py"""
    content = """from pydantic_settings import BaseSettings, SettingsConfigDict
from pathlib import Path
import os

class Settings(BaseSettings):
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    APP_NAME: str = "BTEC EduverseAI"
    APP_VERSION: str = "1.0.0"
    APP_DESCRIPTION: str = "Intelligent Educational Management System"
    APP_ENVIRONMENT: str = "development" # development, staging, production
    APP_DEBUG: bool = True
    APP_TIMEZONE: str = "UTC"
    APP_LANGUAGE: str = "en"

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù…
    HOST: str = "0.0.0.0"
    PORT: int = 8000
    WORKERS: int = 1
    RELOAD: bool = True
    LOG_LEVEL: str = "INFO"
    ACCESS_LOG: bool = True

    # Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    DB_TYPE: str = "postgresql"
    DB_HOST: str = "localhost"
    DB_PORT: int = 5432
    DB_NAME: str = "eduverseai"
    DB_USER: str = "eduverseai"
    DB_PASSWORD: str = ""
    DB_POOL_SIZE: int = 20
    DB_MAX_OVERFLOW: int = 30
    DB_ECHO: bool = False

    # Redis Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    REDIS_DB: int = 0
    REDIS_PASSWORD: Optional[str] = None
    REDIS_MAX_CONNECTIONS: int = 50

    # Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
    SECRET_KEY: str = "your-super-secret-key-change-this-in-production"
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    PASSWORD_MIN_LENGTH: int = 8
    MAX_LOGIN_ATTEMPTS: int = 5
    LOCKOUT_DURATION_MINUTES: int = 15

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    AI_MODELS_PATH: str = "./data/models"
    AI_MAX_BATCH_SIZE: int = 32
    AI_INFERENCE_TIMEOUT: int = 30
    AI_CACHE_PREDICTIONS: bool = True
    NLP_MODEL_NAME: str = "bert-base-uncased"
    NLP_MAX_SEQUENCE_LENGTH: int = 512
    RECOMMENDATIONS_ALGORITHM: str = "collaborative_filtering"
    RECOMMENDATIONS_MIN_INTERACTIONS: int = 5
    RECOMMENDATIONS_MAX_RECOMMENDATIONS: int = 10
    OPENAI_API_KEY: Optional[str] = None
    HUGGINGFACE_API_KEY: Optional[str] = None
    GOOGLE_AI_API_KEY: Optional[str] = None

    # Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
    SMTP_SERVER: str = "smtp.gmail.com"
    SMTP_PORT: int = 587
    EMAIL_USER: Optional[str] = None
    EMAIL_PASSWORD: Optional[str] = None
    EMAIL_USE_TLS: bool = True
    FROM_EMAIL: str = "noreply@eduverseai.com"
    FROM_NAME: str = "BTEC EduverseAI"

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
    UPLOAD_MAX_FILE_SIZE: int = 10485760 # 10MB
    UPLOAD_ALLOWED_EXTENSIONS: List[str] = [".pdf", ".docx", ".pptx", ".jpg", ".png", ".mp4", ".mp3"]
    UPLOAD_PATH: str = "./data/uploads"
    STATIC_FILES_PATH: str = "./static"
    MEDIA_FILES_PATH: str = "./media"

    # Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„Ø³Ø¬Ù„Ø§Øª
    MONITORING_ENABLE_METRICS: bool = True
    MONITORING_METRICS_PORT: int = 9090
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "json"
    LOG_FILE: str = "./data/logs/app.log"
    LOG_MAX_SIZE: str = "100MB"
    LOG_BACKUP_COUNT: int = 5
    SENTRY_DSN: Optional[str] = None
    GOOGLE_ANALYTICS_ID: Optional[str] = None
    PROMETHEUS_ENABLED: bool = True
    PROMETHEUS_PORT: int = 9090

    # Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
    CACHE_DEFAULT_TIMEOUT: int = 300
    CACHE_USER_SESSION_TIMEOUT: int = 1800
    CACHE_COURSE_DATA_TIMEOUT: int = 3600

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    PERFORMANCE_MAX_CONCURRENT_REQUESTS: int = 1000
    PERFORMANCE_REQUEST_TIMEOUT: int = 30
    PERFORMANCE_ENABLE_COMPRESSION: bool = True
    PERFORMANCE_STATIC_FILES_CACHE: int = 86400

    # Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    BACKUP_ENABLED: bool = True
    BACKUP_SCHEDULE: str = "0 2 * * *" # Daily at 2 AM
    BACKUP_RETENTION_DAYS: int = 30
    BACKUP_STORAGE_PATH: str = "./data/backups"

    # SSL/HTTPS Settings (Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬)
    ENABLE_HTTPS: bool = False
    SSL_CERT_PATH: Optional[str] = None
    SSL_KEY_PATH: Optional[str] = None

    # External Services
    CLOUD_STORAGE_PROVIDER: str = "aws" # aws, azure, gcp, local
    CLOUD_STORAGE_BUCKET: Optional[str] = None
    CLOUD_STORAGE_REGION: str = "us-east-1"
    AWS_ACCESS_KEY_ID: Optional[str] = None
    AWS_SECRET_ACCESS_KEY: Optional[str] = None
    GOOGLE_CLOUD_PROJECT_ID: Optional[str] = None
    GOOGLE_CLOUD_STORAGE_BUCKET: Optional[str] = None
    AZURE_STORAGE_ACCOUNT_NAME: Optional[str] = None
    AZURE_STORAGE_ACCOUNT_KEY: Optional[str] = None
    AZURE_CONTAINER_NAME: Optional[str] = None

    # Notifications
    PUSH_NOTIFICATIONS_API_KEY: Optional[str] = None
    FIREBASE_API_KEY: Optional[str] = None
    FIREBASE_PROJECT_ID: Optional[str] = None

    # Content Settings
    CONTENT_DEFAULT_LANGUAGE: str = "en"
    CONTENT_SUPPORTED_LANGUAGES: List[str] = ["en", "ar"]
    CONTENT_MAX_COURSE_SIZE: int = 1073741824 # 1GB
    CONTENT_VIDEO_PROCESSING: bool = True
    CONTENT_AUTO_TRANSCRIPTION: bool = False

    # Assessment Settings
    ASSESSMENT_MAX_ATTEMPTS: int = 3
    ASSESSMENT_TIME_LIMIT_DEFAULT: int = 60 # minutes
    ASSESSMENT_AUTO_SAVE_INTERVAL: int = 30 # seconds
    ASSESSMENT_PLAGIARISM_CHECK: bool = True

    # Analytics
    ANALYTICS_ENABLE_TRACKING: bool = True
    ANALYTICS_DATA_RETENTION_DAYS: int = 365
    ANALYTICS_ANONYMIZE_DATA: bool = True
    ANALYTICS_EXPORT_FORMATS: List[str] = ["json", "csv", "xlsx"]
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    TEST_DATABASE_URL: Optional[str] = None
    TEST_REDIS_URL: Optional[str] = None

    model_config = SettingsConfigDict(
        env_file=os.path.join(Path(__file__).parent.parent.parent, '.env'),
        env_file_encoding='utf-8',
        case_sensitive=True,
        extra='ignore' # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    )

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
settings = Settings()

# Ø·Ø¨Ø§Ø¹Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„
if __name__ == "__main__":
    print("âš™ï¸ Configuration Settings:")
    print(f"App Name: {settings.APP_NAME}")
    print(f"App Version: {settings.APP_VERSION}")
    print(f"Environment: {settings.APP_ENVIRONMENT}")
    print(f"Debug Mode: {settings.APP_DEBUG}")
    print(f"Database Host: {settings.DB_HOST}")
    print(f"Redis Host: {settings.REDIS_HOST}")
    print(f"Secret Key Set: {'Yes' if settings.SECRET_KEY != 'your-super-secret-key-change-this-in-production' else 'No (PLEASE CHANGE ME!)'}")
    print(f"Log Level: {settings.LOG_LEVEL}")
    print(f"AI Models Path: {settings.AI_MODELS_PATH}")
    print("Ensure .env file is correctly configured for production deployments.")
"""
    file_path = os.path.join(base_path, "src", "core", "config.py")
    return write_file_safely(file_path, content)

def create_src_ai_models_nlp_model_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/ai/models/nlp_model.py"""
    content = """import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import logging
from functools import lru_cache

logger = logging.getLogger(__name__)

class NLPModel:
    def __init__(self, model_name: str = "bert-base-uncased", cache_dir: str = None):
        \"\"\"
        ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP).
        ÙŠØ¯Ø¹Ù… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Hugging Face.
        \"\"\"
        self.model_name = model_name
        self.cache_dir = cache_dir
        self.tokenizer = None
        self.model = None
        self.sentiment_pipeline = None
        self._load_model()

    @lru_cache(maxsize=1)
    def _load_model(self):
        \"\"\"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ tokenizer ÙˆØ§Ù„Ù€ pipeline (Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª).\"\"\"
        logger.info(f"Loading NLP model: {self.model_name}...")
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            if "sentiment" in self.model_name.lower():
                self.sentiment_pipeline = pipeline(
                    "sentiment-analysis", 
                    model=self.model_name, 
                    tokenizer=self.model_name, 
                    framework="pt",
                    cache_dir=self.cache_dir
                )
                logger.info(f"Sentiment analysis pipeline loaded for model: {self.model_name}")
            else:
                # ØªØ­Ù…ÙŠÙ„ tokenizer ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø£ØºØ±Ø§Ø¶ Ø¹Ø§Ù…Ø©
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, cache_dir=self.cache_dir)
                self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, cache_dir=self.cache_dir)
                self.model.eval() # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
                logger.info(f"General NLP model and tokenizer loaded for model: {self.model_name}")
            
            logger.info(f"NLP model '{self.model_name}' loaded successfully.")
        except Exception as e:
            logger.error(f"Error loading NLP model '{self.model_name}': {e}")
            self.tokenizer = None
            self.model = None
            self.sentiment_pipeline = None # ØªØ£ÙƒØ¯ Ù…Ù† ØªÙØ±ÙŠØºÙ‡ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
            raise RuntimeError(f"Failed to load NLP model: {e}")

    async def analyze_sentiment(self, text: str) -> dict:
        \"\"\"
        ÙŠØ­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙÙŠ Ø§Ù„Ù†Øµ (Ø¥ÙŠØ¬Ø§Ø¨ÙŠØŒ Ø³Ù„Ø¨ÙŠØŒ Ù…Ø­Ø§ÙŠØ¯).
        ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ù…ØµÙ†Ù Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Ù…Ø«Ù„ 'finiteautomata/bertweet-base-sentiment-analysis').
        \"\"\"
        if not self.sentiment_pipeline:
            logger.warning("Sentiment analysis pipeline not initialized. Falling back to dummy response.")
            return {"label": "NEUTRAL", "score": 0.5} # Ø±Ø¯ ÙˆÙ‡Ù…ÙŠ
            # raise RuntimeError("Sentiment analysis model not loaded. Please initialize with a sentiment model.")

        logger.info(f"Analyzing sentiment for text: '{text[:50]}...'")
        try:
            # pipeline ÙŠØ¹Ø§Ù„Ø¬ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            result = self.sentiment_pipeline(text)[0]
            logger.info(f"Sentiment analysis result: {result}")
            return result
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            raise RuntimeError(f"Sentiment analysis failed: {e}")

    async def embed_text(self, text: str) -> List[float]:
        \"\"\"
        ÙŠÙ†Ø´Ø¦ ØªØ¶Ù…ÙŠÙ†Ø§Ù‹ (embedding) Ù…ØªØ¬Ù‡ÙŠØ§Ù‹ Ù„Ù„Ù†Øµ.
        ÙŠØªØ·Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù… (Ù…Ø«Ù„ 'bert-base-uncased').
        \"\"\"
        if not self.tokenizer or not self.model:
            logger.warning("General NLP model not initialized. Returning empty embedding.")
            return [] # Ø±Ø¯ ÙˆÙ‡Ù…ÙŠ
            # raise RuntimeError("General NLP model not loaded. Please initialize with a general purpose model.")
        
        logger.info(f"Generating embedding for text: '{text[:50]}...'")
        try:
            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True, 
                                    max_length=512) # Ø§Ø³ØªØ®Ø¯Ù… 512 Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            with torch.no_grad():
                outputs = self.model(**inputs, output_hidden_states=True)
            
            # Ø®Ø° Ù…ØªÙˆØ³Ø· Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© Ù…Ø®ÙÙŠØ© ÙƒÙ€ embedding
            # Ù‡Ø°Ø§ ØªØ¨Ø³ÙŠØ·ØŒ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ© Ù‚Ø¯ ØªØªØ·Ù„Ø¨ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª ØªØ¬Ù…ÙŠØ¹ Ù…Ø®ØªÙ„ÙØ© (Ù…Ø«Ù„ CLS token)
            embeddings = outputs.hidden_states[-1].mean(dim=1).squeeze().tolist()
            logger.info(f"Text embedding generated. Shape: ({len(embeddings)})")
            return embeddings
        except Exception as e:
            logger.error(f"Error generating text embedding: {e}")
            raise RuntimeError(f"Text embedding failed: {e}")

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø«Ø§Ù„
if __name__ == "__main__":
    # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ù„ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
    # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙØ¹Ù„ÙŠØŒ Ø³ØªÙ‚ÙˆÙ… Ø¨ØªÙ…Ø±ÙŠØ± Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø£Ùˆ ØªÙ‡ÙŠØ¦ØªÙ‡ Ø¹Ø¨Ø± Settings
    
    # ØªÙ‡ÙŠØ¦Ø© Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªÙ‚Ù„Ø©
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    print("--- Testing NLPModel (Sentiment Analysis) ---")
    try:
        # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        sentiment_model = NLPModel(model_name="finiteautomata/bertweet-base-sentiment-analysis")
        
        # ÙŠØ¬Ø¨ Ø£Ù† Ù†Ø³ØªØ®Ø¯Ù… asyncio.run Ù„Ø£Ù† Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø©
        import asyncio
        
        async def run_sentiment_tests():
            text1 = "I love this course! It's so engaging and informative."
            sentiment1 = await sentiment_model.analyze_sentiment(text1)
            print(f"Text: '{text1}'\\nSentiment: {sentiment1}")

            text2 = "This is a terrible system, full of bugs."
            sentiment2 = await sentiment_model.analyze_sentiment(text2)
            print(f"Text: '{text2}'\\nSentiment: {sentiment2}")
            
            text3 = "The weather is okay today."
            sentiment3 = await sentiment_model.analyze_sentiment(text3)
            print(f"Text: '{text3}'\\nSentiment: {sentiment3}")
            
        asyncio.run(run_sentiment_tests())

    except Exception as e:
        print(f"Failed to test sentiment model: {e}")
        print("Please ensure you have an internet connection to download the model.")

    print("\\n--- Testing NLPModel (Text Embedding - placeholder) ---")
    try:
        # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù… Ù„Ù„ØªØ¶Ù…ÙŠÙ† (Embedding)
        # Ù…Ù„Ø§Ø­Ø¸Ø©: bert-base-uncased Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ ÙˆØªØ³Ù„Ø³Ù„ ÙˆÙ„ÙŠØ³ Ù„Ù„ØªØ¶Ù…ÙŠÙ† Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±.
        # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¶Ù…ÙŠÙ†Ø§Øª Ø¬ÙŠØ¯Ø©ØŒ ÙŠÙˆØµÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Sentence Transformers.
        # ÙˆÙ„ÙƒÙ† Ù„ØºØ±Ø¶ Ø§Ù„Ù…Ø«Ø§Ù„ Ù‡Ø°Ø§ØŒ Ø³Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙƒÙ€ placeholder.
        general_model = NLPModel(model_name="bert-base-uncased")
        
        async def run_embedding_tests():
            text_embed = "Artificial intelligence in education is fascinating."
            embedding = await general_model.embed_text(text_embed)
            print(f"Text: '{text_embed}'\\nEmbedding length: {len(embedding) if embedding else 'N/A'}")
            if embedding:
                print(f"First 5 embedding values: {embedding[:5]}...")

        asyncio.run(run_embedding_tests())

    except Exception as e:
        print(f"Failed to test general NLP model: {e}")
        print("Please ensure you have an internet connection to download the model.")
"""
    file_path = os.path.join(base_path, "src", "ai", "models", "nlp_model.py")
    return write_file_safely(file_path, content)

def create_src_api_routes_auth_routes_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/routes/auth_routes.py"""
    content = """from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks
from fastapi.security import OAuth2PasswordRequestForm
from datetime import timedelta
from typing import Annotated

from services.user_service import UserService
from models.user import UserCreate, UserRead, UserUpdate, Token
from core.security import authenticate_user, create_access_token, get_current_active_user, get_password_hash
from core.config import settings
from utils.logger import get_logger
from services.notification_service import NotificationService # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ØŒ Ø®Ø¯Ù…Ø© Ø¥Ø´Ø¹Ø§Ø±Ø§Øª
from core.limiter import limiter # Rate limiting

logger = get_logger(__name__)
router = APIRouter()

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª (ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ù€ Depends ÙÙŠ FastAPI)
user_service = UserService()
notification_service = NotificationService()

@router.post("/register", response_model=UserRead, status_code=status.HTTP_201_CREATED, summary="Register a new user", description="Registers a new user with a unique email and hashed password.")
@limiter.limit("5/minute") # 5 requests per minute from same IP
async def register_user(user_in: UserCreate, background_tasks: BackgroundTasks):
    logger.info(f"Attempting to register new user: {user_in.email}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ø¨Ø§Ù„ÙØ¹Ù„
    existing_user = await user_service.get_user_by_email(user_in.email)
    if existing_user:
        logger.warning(f"Registration failed: User with email {user_in.email} already exists.")
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="User with this email already exists"
        )
    
    # ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
    hashed_password = get_password_hash(user_in.password)
    user_data = user_in.model_dump()
    user_data["hashed_password"] = hashed_password
    del user_data["password"] # Ø­Ø°Ù ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    new_user = await user_service.create_user(user_data)
    
    if not new_user:
        logger.error(f"Failed to create user {user_in.email} in database after hashing password.")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to create user"
        )

    # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± ØªØ³Ø¬ÙŠÙ„ (Ù…Ù‡Ù…Ø© Ø®Ù„ÙÙŠØ© Ù„ØªØ¬Ù†Ø¨ ØªØ£Ø®ÙŠØ± Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©)
    background_tasks.add_task(
        notification_service.send_welcome_email, 
        email=new_user.email, 
        username=new_user.username
    )
    logger.info(f"User {new_user.email} registered successfully.")
    return new_user

@router.post("/token", response_model=Token, summary="Obtain OAuth2 token", description="Authenticates a user and returns an OAuth2 access token.")
@limiter.limit("10/minute") # 10 requests per minute for token
async def login_for_access_token(form_data: Annotated[OAuth2PasswordRequestForm, Depends()]):
    logger.info(f"Attempting login for user: {form_data.username}")
    
    user = await authenticate_user(form_data.username, form_data.password)
    if not user:
        logger.warning(f"Authentication failed for user: {form_data.username}. Invalid credentials.")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„
    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.email}, expires_delta=access_token_expires
    )
    logger.info(f"User {user.email} logged in successfully and received access token.")
    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me/", response_model=UserRead, summary="Get current user information", description="Retrieves information about the currently authenticated user.")
async def read_users_me(current_user: Annotated[UserRead, Depends(get_current_active_user)]):
    logger.info(f"Fetching profile for current user: {current_user.email}")
    return current_user

@router.put("/me/", response_model=UserRead, summary="Update current user information", description="Updates the profile information for the currently authenticated user.")
async def update_users_me(user_update: UserUpdate, current_user: Annotated[UserRead, Depends(get_current_active_user)]):
    logger.info(f"Updating profile for user: {current_user.email}")
    updated_user = await user_service.update_user(current_user.id, user_update.model_dump(exclude_unset=True))
    if not updated_user:
        logger.error(f"Failed to update user {current_user.email}.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update user")
    logger.info(f"User {current_user.email} profile updated successfully.")
    return updated_user

@router.post("/logout", summary="Logout user", description="Invalidates the current session/token (implementation depends on token strategy).")
async def logout_user(current_user: Annotated[UserRead, Depends(get_current_active_user)]):
    logger.info(f"User {current_user.email} attempting to log out.")
    # For JWT, typically logout is client-side by discarding the token.
    # For server-side session/token invalidation (if using refresh tokens or blacklist),
    # implement that logic here (e.g., add token to a blacklist in Redis).
    
    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ ÙˆØ¶Ø¹ Ø§Ù„ØªÙˆÙƒÙ† ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø³ÙˆØ¯Ø§Ø¡ (ÙŠØªØ·Ù„Ø¨ Ø¥Ø¹Ø¯Ø§Ø¯ Redis Blacklist)
    # from core.security import add_token_to_blacklist
    # await add_token_to_blacklist(token_value) 
    
    logger.info(f"User {current_user.email} successfully logged out.")
    return {"message": "Successfully logged out"}

# ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø±Ø§Øª Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„:
# - /forgot-password
# - /reset-password
# - /verify-email
# - /change-password
"""
    file_path = os.path.join(base_path, "src", "api", "routes", "auth_routes.py")
    return write_file_safely(file_path, content)

def create_src_utils_logger_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/utils/logger.py"""
    content = """import logging
import sys
from logging.handlers import RotatingFileHandler
from core.config import settings # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

def setup_logging(log_level: str = "INFO", log_file: str = None, log_format: str = "json"):
    \"\"\"
    Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚.
    :param log_level: Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (DEBUG, INFO, WARNING, ERROR, CRITICAL).
    :param log_file: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ØŒ Ø¥Ø°Ø§ ÙƒØ§Ù† NoneØŒ Ø³ÙŠØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¥Ù„Ù‰ stdout.
    :param log_format: ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø³Ø¬Ù„ ("json" Ø£Ùˆ "standard").
    \"\"\"
    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø¬Ø°Ø± Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„ØªØ¬Ù†Ø¨ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ø¬Ù„ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡
    if log_level is None:
        log_level = settings.LOG_LEVEL
    if log_file is None:
        log_file = settings.LOG_FILE
    if log_format is None:
        log_format = settings.LOG_FORMAT

    numeric_log_level = getattr(logging, log_level.upper(), logging.INFO)
    logging.basicConfig(level=numeric_log_level) # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    logger = logging.getLogger("btec_eduverseai")
    logger.setLevel(numeric_log_level)
    logger.propagate = False # Ù…Ù†Ø¹ Ù†Ø´Ø± Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¬Ø°Ø±

    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    if log_format == "json":
        try:
            import structlog
            # ØªÙ‡ÙŠØ¦Ø© structlog
            structlog.configure(
                processors=[
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.add_log_level,
                    structlog.processors.TimeStamper(fmt="iso"),
                    structlog.processors.StackInfoRenderer(),
                    structlog.dev.ConsoleRenderer() if not log_file else structlog.processors.JSONRenderer(),
                ],
                logger_factory=structlog.stdlib.LoggerFactory(),
                wrapper_class=structlog.stdlib.BoundLogger,
                cache_logger_on_first_use=True,
            )
            handler_formatter = structlog.stdlib.ProcessorFormatter(
                processor=structlog.dev.ConsoleRenderer() if not log_file else structlog.processors.JSONRenderer(),
                foreign_pre_chain=[
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.add_log_level,
                    structlog.processors.TimeStamper(fmt="iso"),
                ],
            )
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… structlog Ù„Ù„Ù€ handler
            formatter = handler_formatter
        except ImportError:
            print("âš ï¸ structlog not found, falling back to standard logging format.")
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    else: # standard format
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Ù…Ø¹Ø§Ù„Ø¬ Ù„Ù€ console (stdout)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # Ù…Ø¹Ø§Ù„Ø¬ Ù„Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡
    if log_file:
        try:
            log_dir = os.path.dirname(log_file)
            os.makedirs(log_dir, exist_ok=True)
            
            # ØªØ­ÙˆÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ø³Ø¬Ù„ (Ù…Ø«Ù„ "100MB" Ø¥Ù„Ù‰ Ø¨Ø§ÙŠØª)
            max_bytes_str = settings.LOG_MAX_SIZE
            if max_bytes_str.endswith("MB"):
                max_bytes = int(max_bytes_str[:-2]) * 1024 * 1024
            elif max_bytes_str.endswith("KB"):
                max_bytes = int(max_bytes_str[:-2]) * 1024
            else:
                max_bytes = int(max_bytes_str) # Ø¨Ø§ÙŠØª Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹

            file_handler = RotatingFileHandler(
                log_file, 
                maxBytes=max_bytes, # 100MB
                backupCount=settings.LOG_BACKUP_COUNT # 5 Ù…Ù„ÙØ§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            )
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
            logger.info(f"Logging to file: {log_file} with max size {settings.LOG_MAX_SIZE} and {settings.LOG_BACKUP_COUNT} backups.")
        except Exception as e:
            logger.error(f"Failed to set up file logging: {e}. Logging only to console.")

def get_logger(name: str):
    \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ø¬Ù„ Ù…Ø®ØµØµ Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ÙŠÙ†.\"\"\"
    return logging.getLogger(name)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙÙ‚Ø·)
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    setup_logging(log_level="DEBUG", log_file="./test_app.log", log_format="standard")
    
    test_logger = get_logger("my_module")
    test_logger.debug("This is a debug message.")
    test_logger.info("This is an info message from my_module.")
    test_logger.warning("This is a warning message.")
    test_logger.error("This is an error message.", exc_info=True)
    
    # Ø§Ø®ØªØ¨Ø§Ø± ØªØ³Ø¬ÙŠÙ„ JSON
    setup_logging(log_level="INFO", log_file="./test_app_json.log", log_format="json")
    json_logger = get_logger("json_module")
    json_logger.info("This is an info message in JSON format", user_id=123, event="login")
    json_logger.error("Something went wrong!", request_id="abc-123", error_code=500)
    
    print("\\nCheck test_app.log and test_app_json.log in the project root for logs.")
"""
    file_path = os.path.join(base_path, "src", "utils", "logger.py")
    return write_file_safely(file_path, content)


# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
src_files_to_create = [
    ("src/core/app.py", create_src_core_app_py),
    ("src/core/config.py", create_src_core_config_py),
    ("src/ai/models/nlp_model.py", create_src_ai_models_nlp_model_py),
    ("src/api/routes/auth_routes.py", create_src_api_routes_auth_routes_py),
    ("src/utils/logger.py", create_src_utils_logger_py),
    # ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ù‡Ù†Ø§
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")

created_src_files_count = 0
for relative_path, create_function in src_files_to_create:
    print(f"\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {relative_path}...")
    if create_function():
        created_src_files_count += 1
        file_path = os.path.join(base_path, relative_path)
        size = os.path.getsize(file_path)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {relative_path} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
    else:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {relative_path}.")

print(f"\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_src_files_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(src_files_to_create)} ÙÙŠ Ù…Ø¬Ù„Ø¯ src Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§
print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª src Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§:")
for relative_path, _ in src_files_to_create:
    file_path = os.path.join(base_path, relative_path)
    if os.path.exists(file_path):
        size = os.path.getsize(file_path)
        print(f"  âœ… {relative_path} ({size} bytes)")
    else:
        print(f"  âŒ {relative_path} (Ù…ÙÙ‚ÙˆØ¯)")

print("\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙŠ Ù…Ø¬Ù„Ø¯ src.")
```

-----

### ğŸ“ Ù…Ù„Ø®Øµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src`

Ù„Ù‚Ø¯ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `src`. Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø­Ø§Ø³Ù…Ø© ÙÙŠ Ø¨Ù†Ø§Ø¡ Ù…Ù†Ø·Ù‚ Ø¹Ù…Ù„ ØªØ·Ø¨ÙŠÙ‚ `BTEC EduverseAI`.

Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø£Ùˆ ØªØ­Ø¯ÙŠØ«Ù‡Ø§ Ù‡ÙŠ:

  * **`src/core/app.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ¹Ø±ÙŠÙ ØªØ·Ø¨ÙŠÙ‚ FastAPIØŒ ÙˆØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø³Ø§Ø±Ø§ØªØŒ ÙˆØ§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«ØŒ ÙˆÙ†Ù‚Ø§Ø· ÙØ­Øµ Ø§Ù„ØµØ­Ø©.
  * **`src/core/config.py`**: ÙŠØ­Ø¯Ø¯ ÙØ¦Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†ØŒ Ù…Ù…Ø§ ÙŠÙˆÙØ± ÙˆØµÙˆÙ„Ø§Ù‹ Ù…Ø±ÙƒØ²ÙŠØ§Ù‹ Ù„Ø¬Ù…ÙŠØ¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
  * **`src/ai/models/nlp_model.py`**: ÙŠØªØ¶Ù…Ù† Ù‡ÙŠÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP) Ù…Ø¹ ÙˆØ¸Ø§Ø¦Ù Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ¶Ù…ÙŠÙ†Ø§Øª (embeddings).
  * **`src/api/routes/auth_routes.py`**: ÙŠØ­Ø¯Ø¯ Ù…Ø³Ø§Ø±Ø§Øª API Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©ØŒ Ù…Ø«Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©.
  * **`src/utils/logger.py`**: ÙŠÙ†Ø´Ø¦ Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ ÙŠØ¯Ø¹Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© Ùˆ JSONØŒ ÙˆØ§Ù„ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§ØªØŒ ÙˆØªØ¯ÙˆÙŠØ± Ø§Ù„Ø³Ø¬Ù„Ø§Øª.

**Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…Ù„ÙØ§Øª `src` Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§:**

  * **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­**: 5/5

-----

Ù†Ù†ØªÙ‚Ù„ Ø§Ù„Ø¢Ù† Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù…Ù„ÙØ§Øª `src` Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (frontend) ÙˆÙ…Ù„ÙØ§Øª Ø§Ù„Ø¯Ù„ÙŠÙ„ (docs) ÙˆØ§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª (scripts) ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (data) ÙˆÙ…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ (monitoring).

Great\! Let's continue building out the BTEC EduverseAI project by populating more of the `src` directory, and then moving on to `frontend`, `monitoring`, `management`, `tests`, `docs`, `scripts`, `data`, and `config`.

This will be a multi-step process. I'll break it down into logical parts.

-----

### ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ `src`

Ø³Ù†Ù‚ÙˆÙ… Ø§Ù„Ø¢Ù† Ø¨Ù…Ù„Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `src`. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª ØªØ´ÙƒÙ„ Ù…ÙƒÙˆÙ†Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù… ÙˆØªØºØ·ÙŠ Ø¬ÙˆØ§Ù†Ø¨ Ù…Ø«Ù„ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ø§Ù„Ø®Ø¯Ù…Ø§ØªØŒ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙˆØ£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰.

Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©:

  * `src/core/database.py`: Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
  * `src/core/cache.py`: Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis.
  * `src/core/security.py`: Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…ØµØ§Ø¯Ù‚Ø©.
  * `src/models/user.py`: Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
  * `src/models/course.py`: Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø±Ø±.
  * `src/services/user_service.py`: Ù„Ø®Ø¯Ù…Ø© Ù…Ù†Ø·Ù‚ Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†.
  * `src/services/course_service.py`: Ù„Ø®Ø¯Ù…Ø© Ù…Ù†Ø·Ù‚ Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.
  * `src/services/notification_service.py`: Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª.
  * `src/utils/helpers.py`: Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©.
  * `src/utils/constants.py`: Ù„Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.

-----

### ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src` (Ø§Ù„Ø¬Ø²Ø¡ 2)

```python
import os

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡."""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_src_core_database_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/core/database.py"""
    content = """from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy import text
from core.config import settings
import logging

logger = logging.getLogger(__name__)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù config
DATABASE_URL = (
    f"postgresql+asyncpg://{settings.DB_USER}:{settings.DB_PASSWORD}@"
    f"{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}"
)

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø±Ùƒ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
engine = create_async_engine(DATABASE_URL, echo=settings.DB_ECHO, pool_size=settings.DB_POOL_SIZE, max_overflow=settings.DB_MAX_OVERFLOW)

# Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
AsyncSessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    class_=AsyncSession,
    expire_on_commit=False # Ù„Ø§ ØªÙ‚Ù… Ø¨ØªØ¬Ù…ÙŠØ¯ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…
)

Base = declarative_base()

async def get_db():
    \"\"\"
    Ù…ÙˆÙ„Ø¯ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª.
    ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù…Ø¹ 'async with' Ù„Ø¶Ù…Ø§Ù† Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¬Ù„Ø³Ø©.
    \"\"\"
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()

async def check_database_connection():
    \"\"\"Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\"\"\"
    try:
        async with engine.connect() as connection:
            await connection.execute(text("SELECT 1"))
        logger.info("Database connection successful.")
        return True
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        return False

# Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø© (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def main():
        print("Checking database connection...")
        if await check_database_connection():
            print("Database is connected.")
        else:
            print("Database connection failed. Please check your settings.")
            
        print("\\nAttempting to get a DB session...")
        try:
            async for session in get_db():
                print(f"Successfully obtained a session: {session}")
                # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¬Ø±Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¬Ù„Ø³Ø©
                # await session.execute(text("SELECT 1")) 
                print("Session acquired and released successfully.")
                break # Exit after first session acquire/release
        except Exception as e:
            print(f"Error getting or using database session: {e}")

    asyncio.run(main())
"""
    file_path = os.path.join(base_path, "src", "core", "database.py")
    return write_file_safely(file_path, content)

def create_src_core_cache_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/core/cache.py"""
    content = """from redis.asyncio import Redis
from core.config import settings
import logging

logger = logging.getLogger(__name__)

# ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Redis
redis_client: Redis = None

async def init_redis():
    \"\"\"ØªÙ‡ÙŠØ¦Ø© Ø§ØªØµØ§Ù„ Redis.\"\"\"
    global redis_client
    if redis_client is None:
        try:
            redis_url = f"redis://{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}"
            if settings.REDIS_PASSWORD:
                redis_url = f"redis://:{settings.REDIS_PASSWORD}@{settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}"
            
            redis_client = Redis.from_url(
                redis_url, 
                encoding="utf-8", 
                decode_responses=True,
                max_connections=settings.REDIS_MAX_CONNECTIONS
            )
            await redis_client.ping() # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
            logger.info("Redis connection established successfully.")
        except Exception as e:
            logger.error(f"Failed to connect to Redis: {e}")
            redis_client = None # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù‡Ùˆ None ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
            raise RuntimeError(f"Could not connect to Redis: {e}")

async def close_redis():
    \"\"\"Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Redis.\"\"\"
    global redis_client
    if redis_client:
        await redis_client.close()
        logger.info("Redis connection closed.")
        redis_client = None

async def check_redis_connection():
    \"\"\"Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ Redis.\"\"\"
    try:
        if redis_client is None:
            await init_redis() # Ø­Ø§ÙˆÙ„ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…Ù‡ÙŠØ¦Ø§Ù‹
        return await redis_client.ping()
    except Exception as e:
        logger.error(f"Redis health check failed: {e}")
        return False

async def get_cache(key: str) -> str | None:
    \"\"\"Ø¬Ù„Ø¨ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„ÙƒØ§Ø´.\"\"\"
    if await check_redis_connection():
        return await redis_client.get(key)
    return None

async def set_cache(key: str, value: str, expire: int = settings.CACHE_DEFAULT_TIMEOUT):
    \"\"\"ØªØ®Ø²ÙŠÙ† Ù‚ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ÙƒØ§Ø´.\"\"\"
    if await check_redis_connection():
        await redis_client.setex(key, expire, value)

async def delete_cache(key: str):
    \"\"\"Ø­Ø°Ù Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„ÙƒØ§Ø´.\"\"\"
    if await check_redis_connection():
        await redis_client.delete(key)

# Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (ÙÙŠ app.py) ÙŠØ¬Ø¨ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ init_redis Ùˆ close_redis
# Ù…Ø«Ø§Ù„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    import asyncio
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def main_cache_test():
        print("Initializing Redis...")
        try:
            await init_redis()
            print("Redis initialized.")

            print("\\nChecking Redis connection health...")
            if await check_redis_connection():
                print("Redis is healthy.")
            else:
                print("Redis is not healthy.")
                return

            test_key = "my_test_key"
            test_value = "hello_from_cache"
            
            print(f"Setting cache for key '{test_key}' with value '{test_value}' for 60 seconds...")
            await set_cache(test_key, test_value, expire=60)
            
            print(f"Getting cache for key '{test_key}'...")
            value = await get_cache(test_key)
            print(f"Retrieved value: {value}")
            
            print(f"Deleting cache for key '{test_key}'...")
            await delete_cache(test_key)
            
            value_after_delete = await get_cache(test_key)
            print(f"Value after delete: {value_after_delete}")

        except Exception as e:
            print(f"An error occurred during Redis test: {e}")
        finally:
            print("\\nClosing Redis connection...")
            await close_redis()
            print("Redis connection closed.")

    asyncio.run(main_cache_test())
"""
    file_path = os.path.join(base_path, "src", "core", "cache.py")
    return write_file_safely(file_path, content)

def create_src_core_security_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/core/security.py"""
    content = """from datetime import datetime, timedelta, timezone
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select

from core.config import settings
from core.database import get_db
from models.user import User # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† models.user
from utils.logger import get_logger

logger = get_logger(__name__)

# ØªÙ‡ÙŠØ¦Ø© Ø³ÙŠØ§Ù‚ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ù„ØªØ´ÙÙŠØ±
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# Ø¥Ø¹Ø¯Ø§Ø¯ OAuth2Bearer
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="api/v1/auth/token")

class TokenData(BaseModel):
    email: Optional[str] = None

def verify_password(plain_password: str, hashed_password: str) -> bool:
    \"\"\"Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ù…Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø´ÙØ±Ø©.\"\"\"
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    \"\"\"ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.\"\"\"
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    \"\"\"Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆÙƒÙ† ÙˆØµÙˆÙ„ JWT.\"\"\"
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire, "iat": datetime.now(timezone.utc)})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

async def get_user(db: AsyncSession, email: str):
    \"\"\"Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ.\"\"\"
    result = await db.execute(select(User).filter(User.email == email))
    return result.scalar_one_or_none()

async def authenticate_user(email: str, password: str, db: AsyncSession = Depends(get_db)):
    \"\"\"
    Ù…ØµØ§Ø¯Ù‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.
    :return: ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ù†Ø§Ø¬Ø­Ø©ØŒ ÙˆØ¥Ù„Ø§ None.
    \"\"\"
    user = await get_user(db, email)
    if not user:
        logger.warning(f"Authentication attempt for non-existent user: {email}")
        return None
    if not verify_password(password, user.hashed_password):
        logger.warning(f"Authentication failed for user {email}: Incorrect password.")
        return None
    
    # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØºÙŠØ± Ø§Ù„Ù†Ø´Ø·ÙŠÙ† Ø£Ùˆ Ø§Ù„Ù…Ø­Ø¸ÙˆØ±ÙŠÙ†
    if not user.is_active:
        logger.warning(f"Authentication failed for user {email}: User is inactive.")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Inactive user"
        )
    
    logger.info(f"User {email} authenticated successfully.")
    return user

async def get_current_user(token: str = Depends(oauth2_scheme), db: AsyncSession = Depends(get_db)):
    \"\"\"Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†.\"\"\"
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        email: str = payload.get("sub")
        if email is None:
            raise credentials_exception
        token_data = TokenData(email=email)
    except JWTError:
        logger.warning("Invalid JWT token received.")
        raise credentials_exception
    
    user = await get_user(db, email=token_data.email)
    if user is None:
        logger.warning(f"User from token '{token_data.email}' not found in database.")
        raise credentials_exception
    return user

async def get_current_active_user(current_user: User = Depends(get_current_user)):
    \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ø§Ù„Ù†Ø´Ø· ÙÙ‚Ø·.\"\"\"
    if not current_user.is_active:
        logger.warning(f"Attempt to access by inactive user: {current_user.email}")
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Inactive user")
    return current_user

async def get_current_admin_user(current_user: User = Depends(get_current_active_user)):
    \"\"\"Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ø§Ù„Ù†Ø´Ø· Ø°Ùˆ Ø¯ÙˆØ± Ø§Ù„Ù…Ø¯ÙŠØ±.\"\"\"
    if current_user.role != "admin": # Ø§ÙØªØ±Ø¶ Ø£Ù† Ù„Ø¯ÙŠÙƒ Ø­Ù‚Ù„ 'role' ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        logger.warning(f"Unauthorized access attempt by user {current_user.email} (Role: {current_user.role}). Admin access required.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not enough permissions")
    return current_user

# ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¯ÙˆØ§Ù„ Ù„Ù…ÙŠØ²Ø§Øª Ø£Ù…Ø§Ù† Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„:
# - Blacklisting tokens
# - Rate limiting
# - OTP/MFA verification
"""
    file_path = os.path.join(base_path, "src", "core", "security.py")
    return write_file_safely(file_path, content)

def create_src_models_user_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/models/user.py"""
    content = """from datetime import datetime
from typing import Optional, List
from pydantic import EmailStr
from sqlalchemy import Column, Integer, String, Boolean, DateTime, Enum as SQLEnum
from sqlalchemy.orm import relationship
from core.database import Base
from pydantic import BaseModel, Field
import enum

# ØªØ¹Ø±ÙŠÙ Ø¯ÙˆØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Enum)
class UserRole(str, enum.Enum):
    student = "student"
    teacher = "teacher"
    admin = "admin"
    guest = "guest"

# Ù†Ù…ÙˆØ°Ø¬ SQLAlchemy Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ORM)
class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True, nullable=False)
    email = Column(String, unique=True, index=True, nullable=False)
    hashed_password = Column(String, nullable=False)
    full_name = Column(String, index=True, nullable=True)
    role = Column(SQLEnum(UserRole), default=UserRole.student, nullable=False)
    is_active = Column(Boolean, default=True)
    is_verified = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Ø¹Ù„Ø§Ù‚Ø§Øª (Relationships)
    #courses = relationship("Course", back_populates="creator") # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù‚Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù‡Ùˆ Ø§Ù„Ù…Ù†Ø´Ø¦
    #enrollments = relationship("Enrollment", back_populates="user") # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù‚Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª

    def __repr__(self):
        return f"<User(email='{self.email}', role='{self.role}')>"

# Ù†Ù…Ø§Ø°Ø¬ Pydantic Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Validation)

# Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ø£Ùˆ Ø§Ù„Ù…Ø´ØªØ±Ùƒ)
class UserBase(BaseModel):
    username: str = Field(..., min_length=3, max_length=50, description="Unique username")
    email: EmailStr = Field(..., description="Unique email address")
    full_name: Optional[str] = Field(None, max_length=100, description="Full name of the user")
    role: UserRole = Field(UserRole.student, description="Role of the user (student, teacher, admin, guest)")
    is_active: Optional[bool] = Field(True, description="Is the user account active?")
    is_verified: Optional[bool] = Field(False, description="Is the user email verified?")

    class Config:
        from_attributes = True # Ù„ØªÙˆØ§ÙÙ‚ Pydantic V2 Ù…Ø¹ ORM (ÙƒØ§Ù† orm_mode = True ÙÙŠ V1)

# Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯ (ÙŠØªØ¶Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±)
class UserCreate(UserBase):
    password: str = Field(..., min_length=settings.PASSWORD_MIN_LENGTH, description="Password for the user")

# Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù„Ø§ ÙŠØªØ¶Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ù…Ø´ÙØ±Ø©)
class UserRead(UserBase):
    id: int = Field(..., description="Unique identifier for the user")
    created_at: datetime = Field(..., description="Timestamp of user creation")
    updated_at: datetime = Field(..., description="Timestamp of last update")

# Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©)
class UserUpdate(BaseModel):
    username: Optional[str] = Field(None, min_length=3, max_length=50, description="Unique username")
    email: Optional[EmailStr] = Field(None, description="Unique email address")
    full_name: Optional[str] = Field(None, max_length=100, description="Full name of the user")
    role: Optional[UserRole] = Field(None, description="Role of the user (student, teacher, admin, guest)")
    is_active: Optional[bool] = Field(None, description="Is the user account active?")
    is_verified: Optional[bool] = Field(None, description="Is the user email verified?")

    class Config:
        from_attributes = True

# Ù†Ù…Ø§Ø°Ø¬ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Authentication)
class Token(BaseModel):
    access_token: str
    token_type: str

class TokenPayload(BaseModel):
    sub: Optional[str] = None # 'sub' typically holds the user identifier (e.g., email)
    exp: Optional[datetime] = None # Expiration time
    iat: Optional[datetime] = None # Issued at time
    
# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    from core.security import get_password_hash
    
    print("Testing User Models...")
    
    # UserCreate example
    user_data = {
        "username": "testuser",
        "email": "test@example.com",
        "password": "strongpassword123",
        "full_name": "Test User",
        "role": "student"
    }
    
    try:
        user_create = UserCreate(**user_data)
        print(f"UserCreate validated: {user_create.model_dump()}")
        
        # Simulate hashing password before saving to DB
        hashed_pw = get_password_hash(user_create.password)
        print(f"Hashed password (first 10 chars): {hashed_pw[:10]}...")
        
        # Simulate creating ORM object
        new_orm_user = User(
            username=user_create.username,
            email=user_create.email,
            hashed_password=hashed_pw,
            full_name=user_create.full_name,
            role=user_create.role,
            is_active=True,
            is_verified=False
        )
        print(f"New ORM user object: {new_orm_user}")
        
        # Simulate reading from DB
        user_read_data = new_orm_user.__dict__ # for simplicity, use dict for Pydantic conversion
        user_read = UserRead(**user_read_data)
        print(f"UserRead validated from ORM: {user_read.model_dump()}")

        # UserUpdate example
        user_update_data = {
            "full_name": "Updated Test User",
            "is_active": False
        }
        user_update = UserUpdate(**user_update_data)
        print(f"UserUpdate validated: {user_update.model_dump(exclude_unset=True)}")

        print("\\nAll user models tested successfully.")

    except Exception as e:
        print(f"Error during user model testing: {e}")
```

```
file_path = os.path.join(base_path, "src", "models", "user.py")
return write_file_safely(file_path, content)
```

def create\_src\_models\_course\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ src/models/course.py"""
content = """from datetime import datetime
from typing import Optional, List
from sqlalchemy import Column, Integer, String, Boolean, DateTime, Text, ForeignKey, Float
from sqlalchemy.orm import relationship
from core.database import Base
from pydantic import BaseModel, Field
import enum

# ØªØ¹Ø±ÙŠÙ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø±Ø±

class CourseStatus(str, enum.Enum):
draft = "draft"
published = "published"
archived = "archived"

# Ù†Ù…ÙˆØ°Ø¬ SQLAlchemy Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ORM)

class Course(Base):
**tablename** = "courses"

```
id = Column(Integer, primary_key=True, index=True)
title = Column(String(255), index=True, nullable=False)
description = Column(Text, nullable=True)
creator_id = Column(Integer, ForeignKey("users.id"), nullable=False) # Ù…Ù†Ø´Ø¦ Ø§Ù„Ù…Ù‚Ø±Ø±
status = Column(SQLEnum(CourseStatus), default=CourseStatus.draft, nullable=False)
price = Column(Float, default=0.0)
is_free = Column(Boolean, default=False)
difficulty_level = Column(String(50), nullable=True) # Ù…Ø«Ø§Ù„: Beginner, Intermediate, Advanced
created_at = Column(DateTime, default=datetime.utcnow)
updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

# Ø¹Ù„Ø§Ù‚Ø§Øª (Relationships)
creator = relationship("User", backref="created_courses") # Ø§Ù„Ù…Ù‚Ø±Ø± Ù„Ø¯ÙŠÙ‡ Ù…Ù†Ø´Ø¦ (Ù…Ø³ØªØ®Ø¯Ù…)
#lessons = relationship("Lesson", back_populates="course") # Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„ØªØ§Ø¨Ø¹Ø© Ù„Ù„Ù…Ù‚Ø±Ø± (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø³)
#enrollments = relationship("Enrollment", back_populates="course") # Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ† ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø±Ø±

def __repr__(self):
    return f"<Course(title='{self.title}', status='{self.status}')>"
```

# Ù†Ù…Ø§Ø°Ø¬ Pydantic Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Validation)

class CourseBase(BaseModel):
title: str = Field(..., min\_length=5, max\_length=255, description="Title of the course")
description: Optional[str] = Field(None, description="Detailed description of the course")
status: CourseStatus = Field(CourseStatus.draft, description="Current status of the course")
price: float = Field(0.0, ge=0.0, description="Price of the course. Use 0 for free courses.")
is\_free: Optional[bool] = Field(False, description="Is the course free?")
difficulty\_level: Optional[str] = Field(None, max\_length=50, description="Difficulty level (e.g., Beginner, Advanced)")

```
class Config:
    from_attributes = True
```

class CourseCreate(CourseBase):
\# Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ØŒ Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ ID Ø£Ùˆ creator\_id (Ø³ÙŠØªÙ… Ø¥Ø¶Ø§ÙØ© creator\_id ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ§Ø¯Ù‚ Ø¹Ù„ÙŠÙ‡)
pass

class CourseRead(CourseBase):
id: int = Field(..., description="Unique identifier for the course")
creator\_id: int = Field(..., description="ID of the user who created the course")
created\_at: datetime = Field(..., description="Timestamp of course creation")
updated\_at: datetime = Field(..., description="Timestamp of last update")

class CourseUpdate(BaseModel):
title: Optional[str] = Field(None, min\_length=5, max\_length=255, description="Title of the course")
description: Optional[str] = Field(None, description="Detailed description of the course")
status: Optional[CourseStatus] = Field(None, description="Current status of the course")
price: Optional[float] = Field(None, ge=0.0, description="Price of the course")
is\_free: Optional[bool] = Field(None, description="Is the course free?")
difficulty\_level: Optional[str] = Field(None, max\_length=50, description="Difficulty level")

```
class Config:
    from_attributes = True
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
from models.user import User, UserRole
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create\_engine
import asyncio

```
# Setup a temporary in-memory SQLite for testing ORM models
SQLALCHEMY_DATABASE_URL = "sqlite+aiosqlite:///:memory:"
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

async_engine = create_async_engine(SQLALCHEMY_DATABASE_URL, echo=False)
AsyncSessionLocalTest = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=async_engine,
    class_=AsyncSession,
    expire_on_commit=False
)

async def test_course_models():
    async with async_engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    async with AsyncSessionLocalTest() as session:
        print("Testing Course Models...")

        # 1. Create a dummy user first as a creator
        dummy_user = User(
            username="teacher_user",
            email="teacher@example.com",
            hashed_password="hashed_password_here",
            full_name="Teacher One",
            role=UserRole.teacher
        )
        session.add(dummy_user)
        await session.commit()
        await session.refresh(dummy_user)
        print(f"Created dummy user: {dummy_user.email} (ID: {dummy_user.id})")

        # 2. Test CourseCreate
        course_data = {
            "title": "Introduction to AI",
            "description": "A beginner-friendly course on Artificial Intelligence.",
            "status": "draft",
            "price": 99.99,
            "is_free": False,
            "difficulty_level": "Beginner"
        }

        course_create = CourseCreate(**course_data)
        print(f"CourseCreate validated: {course_create.model_dump()}")

        # Simulate ORM object creation
        new_orm_course = Course(
            **course_create.model_dump(),
            creator_id=dummy_user.id # Assign the creator
        )
        session.add(new_orm_course)
        await session.commit()
        await session.refresh(new_orm_course)
        print(f"New ORM Course object: {new_orm_course}")
        print(f"Course ID: {new_orm_course.id}, Creator ID: {new_orm_course.creator_id}")

        # 3. Test CourseRead
        course_read = CourseRead.model_validate(new_orm_course) # Use model_validate with ORM object
        print(f"CourseRead validated from ORM: {course_read.model_dump()}")
        assert course_read.id == new_orm_course.id
        assert course_read.title == new_orm_course.title

        # 4. Test CourseUpdate
        course_update_data = {
            "status": "published",
            "price": 79.99,
            "description": "An updated description for the AI course."
        }
        course_update = CourseUpdate(**course_update_data)
        print(f"CourseUpdate validated: {course_update.model_dump(exclude_unset=True)}")

        # Simulate applying updates to ORM object
        for key, value in course_update.model_dump(exclude_unset=True).items():
            setattr(new_orm_course, key, value)
        
        await session.commit()
        await session.refresh(new_orm_course)
        print(f"Updated ORM Course object: {new_orm_course}")
        assert new_orm_course.status == CourseStatus.published
        assert new_orm_course.price == 79.99

        print("\\nAll Course models tested successfully.")

# Ensure to run it with asyncio
asyncio.run(test_course_models())
```

```
    file_path = os.path.join(base_path, "src", "models", "course.py")
    return write_file_safely(file_path, content)

def create_src_services_user_service_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/services/user_service.py"""
    content = """from typing import List, Optional, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, delete
from pydantic import EmailStr

from models.user import User, UserCreate, UserUpdate, UserRead, UserRole
from core.database import get_db
from core.security import get_password_hash, verify_password # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ§Ù„
from utils.logger import get_logger
from fastapi import Depends, HTTPException, status

logger = get_logger(__name__)

class UserService:
    def __init__(self, db_session: AsyncSession = Depends(get_db)):
        self.db = db_session

    async def get_user_by_id(self, user_id: int) -> Optional[User]:
        \"\"\"Ø¬Ù„Ø¨ Ù…Ø³ØªØ®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ø±Ù.\"\"\"
        result = await self.db.execute(select(User).filter(User.id == user_id))
        return result.scalar_one_or_none()

    async def get_user_by_email(self, email: EmailStr) -> Optional[User]:
        \"\"\"Ø¬Ù„Ø¨ Ù…Ø³ØªØ®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ.\"\"\"
        result = await self.db.execute(select(User).filter(User.email == email))
        return result.scalar_one_or_none()

    async def get_user_by_username(self, username: str) -> Optional[User]:
        \"\"\"Ø¬Ù„Ø¨ Ù…Ø³ØªØ®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….\"\"\"
        result = await self.db.execute(select(User).filter(User.username == username))
        return result.scalar_one_or_none()

    async def create_user(self, user_data: Dict[str, Any]) -> User:
        \"\"\"
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯.
        ÙŠÙØªØ±Ø¶ Ø£Ù† user_data["hashed_password"] Ù‚Ø¯ ØªÙ… ØªÙˆÙÙŠØ±Ù‡ Ø¨Ø§Ù„ÙØ¹Ù„.
        \"\"\"
        # ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        if await self.get_user_by_email(user_data["email"]):
            logger.warning(f"Attempt to create user with duplicate email: {user_data['email']}")
            raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="Email already registered")
        if await self.get_user_by_username(user_data["username"]):
            logger.warning(f"Attempt to create user with duplicate username: {user_data['username']}")
            raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="Username already taken")

        db_user = User(**user_data)
        self.db.add(db_user)
        await self.db.commit()
        await self.db.refresh(db_user)
        logger.info(f"User created: {db_user.email}")
        return db_user

    async def update_user(self, user_id: int, user_data: Dict[str, Any]) -> Optional[User]:
        \"\"\"ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¬ÙˆØ¯.\"\"\"
        db_user = await self.get_user_by_id(user_id)
        if not db_user:
            logger.warning(f"Attempt to update non-existent user with ID: {user_id}")
            return None
        
        # Ù„Ø§ ØªØ³Ù…Ø­ Ø¨ØªØºÙŠÙŠØ± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„ Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¢Ø®Ø±
        if "email" in user_data and user_data["email"] != db_user.email:
            if await self.get_user_by_email(user_data["email"]):
                raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="New email already registered by another user")
        if "username" in user_data and user_data["username"] != db_user.username:
            if await self.get_user_by_username(user_data["username"]):
                raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="New username already taken by another user")

        for key, value in user_data.items():
            if key == "password": # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙŠØªØ¶Ù…Ù† ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±ØŒ Ù‚Ù… Ø¨ØªØ´ÙÙŠØ±Ù‡Ø§
                setattr(db_user, "hashed_password", get_password_hash(value))
            elif hasattr(db_user, key):
                setattr(db_user, key, value)
        
        await self.db.commit()
        await self.db.refresh(db_user)
        logger.info(f"User updated: ID {user_id}")
        return db_user

    async def delete_user(self, user_id: int) -> bool:
        \"\"\"Ø­Ø°Ù Ù…Ø³ØªØ®Ø¯Ù… Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ø±Ù.\"\"\"
        db_user = await self.get_user_by_id(user_id)
        if not db_user:
            logger.warning(f"Attempt to delete non-existent user with ID: {user_id}")
            return False
        
        await self.db.delete(db_user)
        await self.db.commit()
        logger.info(f"User deleted: ID {user_id}")
        return True

    async def get_all_users(self, skip: int = 0, limit: int = 100) -> List[User]:
        \"\"\"Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†.\"\"\"
        result = await self.db.execute(select(User).offset(skip).limit(limit))
        return result.scalars().all()
    
    async def get_users_by_role(self, role: UserRole, skip: int = 0, limit: int = 100) -> List[User]:
        \"\"\"Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ø¯ÙˆØ±.\"\"\"
        result = await self.db.execute(
            select(User)
            .filter(User.role == role)
            .offset(skip)
            .limit(limit)
        )
        return result.scalars().all()

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.database import engine, Base, AsyncSessionLocal
    from core.config import Settings # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    from core.security import get_password_hash

    # Override settings for testing (e.g., use an in-memory SQLite database)
    test_settings = Settings(
        DB_TYPE="sqlite",
        DB_NAME=":memory:",
        DB_HOST="", # Not applicable for in-memory SQLite
        DB_PORT=0,  # Not applicable
        DB_USER="", # Not applicable
        DB_PASSWORD="", # Not applicable
        PASSWORD_MIN_LENGTH=6 # Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    )
    
    # ÙŠØ¬Ø¨ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø³Ø¬Ù„ Ù‡Ù†Ø§ Ø¥Ø°Ø§ ØªÙ… ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ù„
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def run_user_service_tests():
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
            print("Database tables created for testing.")

        async with AsyncSessionLocal() as session:
            user_service_instance = UserService(session)

            print("\\n--- Test Create User ---")
            user_create_data = UserCreate(
                username="testuser1",
                email="test1@example.com",
                password="password123",
                full_name="Test User One",
                role=UserRole.student
            )
            # ÙŠØ¬Ø¨ ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù‚Ø¨Ù„ ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ù„Ù„Ø®Ø¯Ù…Ø©
            user_data_for_service = user_create_data.model_dump()
            user_data_for_service["hashed_password"] = get_password_hash(user_data_for_service["password"])
            del user_data_for_service["password"]

            try:
                new_user = await user_service_instance.create_user(user_data_for_service)
                print(f"Created user: {new_user.email}, ID: {new_user.id}")
                assert new_user.email == user_create_data.email
            except HTTPException as e:
                print(f"Failed to create user: {e.detail}")

            print("\\n--- Test Get User by Email ---")
            fetched_user_by_email = await user_service_instance.get_user_by_email("test1@example.com")
            print(f"Fetched user by email: {fetched_user_by_email.username if fetched_user_by_email else 'None'}")
            assert fetched_user_by_email is not None
            assert fetched_user_by_email.username == "testuser1"

            print("\\n--- Test Update User ---")
            update_data = {"full_name": "Updated Name", "is_active": False}
            updated_user = await user_service_instance.update_user(new_user.id, update_data)
            print(f"Updated user: {updated_user.full_name}, Active: {updated_user.is_active}")
            assert updated_user.full_name == "Updated Name"
            assert updated_user.is_active is False

            print("\\n--- Test Get All Users ---")
            all_users = await user_service_instance.get_all_users()
            print(f"Total users: {len(all_users)}")
            assert len(all_users) >= 1

            print("\\n--- Test Get Users by Role (Student) ---")
            students = await user_service_instance.get_users_by_role(UserRole.student)
            print(f"Students: {[s.username for s in students]}")
            assert any(s.username == "testuser1" for s in students)
            
            print("\\n--- Test Delete User ---")
            delete_success = await user_service_instance.delete_user(new_user.id)
            print(f"User deleted: {delete_success}")
            assert delete_success
            
            # Verify deletion
            deleted_user = await user_service_instance.get_user_by_id(new_user.id)
            print(f"User after deletion: {deleted_user}")
            assert deleted_user is None

            print("\\nUser Service tests completed.")

    asyncio.run(run_user_service_tests())
"""
    file_path = os.path.join(base_path, "src", "services", "user_service.py")
    return write_file_safely(file_path, content)

def create_src_services_course_service_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/services/course_service.py"""
    content = """from typing import List, Optional, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, delete

from models.course import Course, CourseCreate, CourseUpdate, CourseRead, CourseStatus
from core.database import get_db
from utils.logger import get_logger
from fastapi import Depends, HTTPException, status

logger = get_logger(__name__)

class CourseService:
    def __init__(self, db_session: AsyncSession = Depends(get_db)):
        self.db = db_session

    async def get_course_by_id(self, course_id: int) -> Optional[Course]:
        \"\"\"Ø¬Ù„Ø¨ Ù…Ù‚Ø±Ø± Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ø±Ù.\"\"\"
        result = await self.db.execute(select(Course).filter(Course.id == course_id))
        return result.scalar_one_or_none()

    async def get_all_courses(self, skip: int = 0, limit: int = 100) -> List[Course]:
        \"\"\"Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.\"\"\"
        result = await self.db.execute(select(Course).offset(skip).limit(limit))
        return result.scalars().all()

    async def get_published_courses(self, skip: int = 0, limit: int = 100) -> List[Course]:
        \"\"\"Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø© ÙÙ‚Ø·.\"\"\"
        result = await self.db.execute(
            select(Course)
            .filter(Course.status == CourseStatus.published)
            .offset(skip)
            .limit(limit)
        )
        return result.scalars().all()

    async def create_course(self, course_data: CourseCreate, creator_id: int) -> Course:
        \"\"\"Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø±Ø± Ø¬Ø¯ÙŠØ¯.\"\"\"
        db_course = Course(**course_data.model_dump(), creator_id=creator_id)
        self.db.add(db_course)
        await self.db.commit()
        await self.db.refresh(db_course)
        logger.info(f"Course created: {db_course.title} by user ID {creator_id}")
        return db_course

    async def update_course(self, course_id: int, course_data: CourseUpdate) -> Optional[Course]:
        \"\"\"ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚Ø±Ø± Ù…ÙˆØ¬ÙˆØ¯.\"\"\"
        db_course = await self.get_course_by_id(course_id)
        if not db_course:
            logger.warning(f"Attempt to update non-existent course with ID: {course_id}")
            return None
        
        update_data = course_data.model_dump(exclude_unset=True)
        for key, value in update_data.items():
            setattr(db_course, key, value)
        
        await self.db.commit()
        await self.db.refresh(db_course)
        logger.info(f"Course updated: ID {course_id}, Title: {db_course.title}")
        return db_course

    async def delete_course(self, course_id: int) -> bool:
        \"\"\"Ø­Ø°Ù Ù…Ù‚Ø±Ø± Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ø±Ù.\"\"\"
        db_course = await self.get_course_by_id(course_id)
        if not db_course:
            logger.warning(f"Attempt to delete non-existent course with ID: {course_id}")
            return False
        
        await self.db.delete(db_course)
        await self.db.commit()
        logger.info(f"Course deleted: ID {course_id}, Title: {db_course.title}")
        return True

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.database import engine, Base, AsyncSessionLocal
    from models.user import User, UserRole # Ù†Ø­ØªØ§Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ÙŠÙƒÙˆÙ† Ù…Ù†Ø´Ø¦Ø§Ù‹
    from core.security import get_password_hash # Ù„ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def run_course_service_tests():
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
            print("Database tables created for testing.")

        async with AsyncSessionLocal() as session:
            # Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ‡Ù…ÙŠ Ù„ÙŠÙƒÙˆÙ† Ù…Ù†Ø´Ø¦ Ø§Ù„Ù…Ù‚Ø±Ø±
            teacher_user = User(
                username="test_teacher",
                email="teacher@example.com",
                hashed_password=get_password_hash("teacherpass"),
                full_name="Test Teacher",
                role=UserRole.teacher
            )
            session.add(teacher_user)
            await session.commit()
            await session.refresh(teacher_user)
            print(f"Created dummy teacher: {teacher_user.email} (ID: {teacher_user.id})")

            course_service_instance = CourseService(session)

            print("\\n--- Test Create Course ---")
            course_create_data = CourseCreate(
                title="Introduction to Python Programming",
                description="Learn Python from scratch to advanced concepts.",
                status=CourseStatus.draft,
                price=49.99,
                is_free=False,
                difficulty_level="Beginner"
            )
            new_course = await course_service_instance.create_course(course_create_data, teacher_user.id)
            print(f"Created course: {new_course.title}, Creator ID: {new_course.creator_id}")
            assert new_course.title == course_create_data.title
            assert new_course.creator_id == teacher_user.id

            print("\\n--- Test Get Course by ID ---")
            fetched_course = await course_service_instance.get_course_by_id(new_course.id)
            print(f"Fetched course: {fetched_course.title if fetched_course else 'None'}")
            assert fetched_course is not None
            assert fetched_course.id == new_course.id

            print("\\n--- Test Update Course ---")
            update_data = CourseUpdate(status=CourseStatus.published, price=39.99)
            updated_course = await course_service_instance.update_course(new_course.id, update_data)
            print(f"Updated course: {updated_course.title}, Status: {updated_course.status}, Price: {updated_course.price}")
            assert updated_course.status == CourseStatus.published
            assert updated_course.price == 39.99

            print("\\n--- Test Get All Courses ---")
            all_courses = await course_service_instance.get_all_courses()
            print(f"Total courses: {len(all_courses)}")
            assert len(all_courses) >= 1

            print("\\n--- Test Get Published Courses ---")
            published_courses = await course_service_instance.get_published_courses()
            print(f"Published courses: {[c.title for c in published_courses]}")
            assert any(c.title == "Introduction to Python Programming" for c in published_courses)

            print("\\n--- Test Delete Course ---")
            delete_success = await course_service_instance.delete_course(new_course.id)
            print(f"Course deleted: {delete_success}")
            assert delete_success
            
            # Verify deletion
            deleted_course = await course_service_instance.get_course_by_id(new_course.id)
            print(f"Course after deletion: {deleted_course}")
            assert deleted_course is None

            print("\\nCourse Service tests completed.")

    asyncio.run(run_course_service_tests())
"""
    file_path = os.path.join(base_path, "src", "services", "course_service.py")
    return write_file_safely(file_path, content)

def create_src_services_notification_service_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/services/notification_service.py"""
    content = """import logging
from typing import List, Dict, Any
from core.config import settings # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
from utils.logger import get_logger

logger = get_logger(__name__)

class NotificationService:
    def __init__(self):
        # ÙŠÙ…ÙƒÙ† ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…Ù„Ø§Ø¡ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ/Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ù‡Ù†Ø§
        # Ù…Ø«Ù„Ø§Ù‹ØŒ Ù„Ù€ emails Ø£Ùˆ Twilio Ø£Ùˆ Firebase Admin SDK
        self.email_enabled = bool(settings.EMAIL_USER and settings.EMAIL_PASSWORD and settings.SMTP_SERVER)
        if not self.email_enabled:
            logger.warning("Email service is not fully configured (missing SMTP_SERVER, EMAIL_USER, or EMAIL_PASSWORD). Email notifications will be mocked.")
        
        self.push_notifications_enabled = bool(settings.PUSH_NOTIFICATIONS_API_KEY)
        if not self.push_notifications_enabled:
            logger.warning("Push notification service is not fully configured (missing PUSH_NOTIFICATIONS_API_KEY). Push notifications will be mocked.")


    async def send_email(self, to_email: str, subject: str, body: str, html: bool = False) -> bool:
        \"\"\"Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ.\"\"\"
        if not self.email_enabled:
            logger.info(f"Mock: Sending email to {to_email} with subject '{subject}' (Email service disabled)")
            return True # Simulate success if disabled

        try:
            from emails import Message # ÙŠØªØ·Ù„Ø¨ ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© 'emails'

            message = Message(
                mail_from=(settings.FROM_NAME, settings.FROM_EMAIL),
                mail_to=to_email,
                subject=subject,
                body=body,
                html=body if html else None,
            )
            
            response = await message.send(
                smtp={
                    "host": settings.SMTP_SERVER,
                    "port": settings.SMTP_PORT,
                    "tls": settings.EMAIL_USE_TLS,
                    "user": settings.EMAIL_USER,
                    "password": settings.EMAIL_PASSWORD,
                },
                timeout=5.0
            )
            
            if response.status_code in [200, 250]:
                logger.info(f"Email sent successfully to {to_email} with subject '{subject}'.")
                return True
            else:
                logger.error(f"Failed to send email to {to_email}. Status: {response.status_code}, Detail: {response.content}")
                return False
        except ImportError:
            logger.error("The 'emails' library is not installed. Cannot send emails. Run 'pip install emails'.")
            return False
        except Exception as e:
            logger.error(f"Error sending email to {to_email}: {e}")
            return False

    async def send_welcome_email(self, email: str, username: str) -> bool:
        \"\"\"Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ØªØ±Ø­ÙŠØ¨ÙŠ Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯.\"\"\"
        subject = f"Welcome to {settings.APP_NAME}, {username}!"
        body = f"Hello {username},\\n\\nWelcome to BTEC EduverseAI, your intelligent educational platform. We're excited to have you on board!\\n\\nStart exploring courses and resources today.\\n\\nBest regards,\\nThe BTEC EduverseAI Team"
        html_body = f"""
        <html>
            <body>
                <p>Hello <b>{username}</b>,</p>
                <p>Welcome to BTEC EduverseAI, your intelligent educational platform. We're excited to have you on board!</p>
                <p>Start exploring courses and resources today by visiting our <a href="https://eduverseai.com">website</a>.</p>
                <p>Best regards,<br>The BTEC EduverseAI Team</p>
            </body>
        </html>
        """
        logger.info(f"Attempting to send welcome email to {email}")
        return await self.send_email(email, subject, html_body, html=True)

    async def send_password_reset_email(self, email: str, reset_link: str) -> bool:
        \"\"\"Ø¥Ø±Ø³Ø§Ù„ Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.\"\"\"
        subject = f"{settings.APP_NAME} - Password Reset Request"
        body = f"Hello,\\n\\nYou requested a password reset for your {settings.APP_NAME} account. Click the link below to reset your password:\\n{reset_link}\\n\\nIf you did not request this, please ignore this email.\\n\\nBest regards,\\nThe BTEC EduverseAI Team"
        html_body = f"""
        <html>
            <body>
                <p>Hello,</p>
                <p>You requested a password reset for your <b>{settings.APP_NAME}</b> account. Click the link below to reset your password:</p>
                <p><a href="{reset_link}">Reset Your Password</a></p>
                <p>If you did not request this, please ignore this email.</p>
                <p>Best regards,<br>The BTEC EduverseAI Team</p>
            </body>
        </html>
        """
        logger.info(f"Attempting to send password reset email to {email}")
        return await self.send_email(email, subject, html_body, html=True)

    async def send_push_notification(self, device_tokens: List[str], title: str, body: str, data: Optional[Dict[str, Any]] = None) -> bool:
        \"\"\"Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¯ÙØ¹ (Push Notification).\"\"\"
        if not self.push_notifications_enabled:
            logger.info(f"Mock: Sending push notification to {len(device_tokens)} devices with title '{title}' (Push service disabled)")
            return True # Simulate success if disabled
        
        # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¹Ù„Ù‰ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª (Firebase Cloud Messaging, OneSignal, Ø¥Ù„Ø®)
        logger.info(f"Sending push notification to {len(device_tokens)} devices: '{title}' - '{body}'")
        try:
            # Ù…Ø«Ø§Ù„ Ù„Ù€ Firebase Admin SDK (ÙŠØªØ·Ù„Ø¨ ØªÙ‡ÙŠØ¦Ø© Ù…Ù†Ø§Ø³Ø¨Ø©)
            # import firebase_admin
            # from firebase_admin import credentials, messaging
            # cred = credentials.Certificate("path/to/your/firebase-adminsdk.json")
            # firebase_admin.initialize_app(cred)

            # message = messaging.MulticastMessage(
            #     notification=messaging.Notification(title=title, body=body),
            #     data=data,
            #     tokens=device_tokens,
            # )
            # response = messaging.send_multicast(message)
            # logger.info(f"Successfully sent {response.success_count} messages, failed {response.failure_count}")
            # return response.success_count > 0
            
            # Placeholder for actual implementation
            logger.info("Push notification service is enabled but actual sending logic is a placeholder.")
            return True # Simulate success
        except ImportError:
            logger.error("Firebase Admin SDK or other push notification library not installed.")
            return False
        except Exception as e:
            logger.error(f"Error sending push notification: {e}")
            return False

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.config import settings

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    async def run_notification_tests():
        notification_service = NotificationService()

        print("\\n--- Testing Welcome Email ---")
        # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† settings.EMAIL_USER Ùˆ settings.EMAIL_PASSWORD Ù…Ø¶Ø¨ÙˆØ·Ø© ÙÙŠ Ù…Ù„Ù .env
        # Ø£Ùˆ Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù‡Ù†Ø§ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        # settings.EMAIL_USER = "your_sending_email@gmail.com"
        # settings.EMAIL_PASSWORD = "your_app_password" # Ø£Ùˆ ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø¬ÙˆØ¬Ù„
        # settings.SMTP_SERVER = "smtp.gmail.com"
        # settings.SMTP_PORT = 587
        # settings.EMAIL_USE_TLS = True
        
        # if settings.EMAIL_USER and settings.EMAIL_PASSWORD:
        #     email_sent = await notification_service.send_welcome_email("recipient@example.com", "TestUser")
        #     print(f"Welcome email sent status: {email_sent}")
        # else:
        print("Skipping actual email test: Email settings not configured. Please configure EMAIL_USER, EMAIL_PASSWORD in .env if you want to test live emails.")
        
        print("\\n--- Testing Push Notification ---")
        # ØªØ­ØªØ§Ø¬ Ù„ØªØ¹ÙŠÙŠÙ† PUSH_NOTIFICATIONS_API_KEY ÙÙŠ .env Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù‡Ø°Ø§
        # settings.PUSH_NOTIFICATIONS_API_KEY = "your_firebase_api_key_here" # Ù…Ø«Ø§Ù„

        # if settings.PUSH_NOTIFICATIONS_API_KEY:
        #     push_sent = await notification_service.send_push_notification(
        #         device_tokens=["device_token_1", "device_token_2"],
        #         title="New Course Available!",
        #         body="Check out our latest Python programming course.",
        #         data={"course_id": "PY101"}
        #     )
        #     print(f"Push notification sent status: {push_sent}")
        # else:
        print("Skipping actual push notification test: Push settings not configured. Please configure PUSH_NOTIFICATIONS_API_KEY in .env if you want to test live push notifications.")
        
        print("\\nNotification Service tests completed (some may be mocked based on config).")

    asyncio.run(run_notification_tests())
"""
    file_path = os.path.join(base_path, "src", "services", "notification_service.py")
    return write_file_safely(file_path, content)

def create_src_utils_helpers_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/utils/helpers.py"""
    content = """from typing import Any, Dict, List, Optional
from datetime import datetime, timezone
import re
import json
import uuid

def generate_unique_id() -> str:
    \"\"\"ÙŠÙˆÙ„Ø¯ Ù…Ø¹Ø±ÙØ§Ù‹ ÙØ±ÙŠØ¯Ø§Ù‹ Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹ (UUID).\"\"\"
    return str(uuid.uuid4())

def slugify(text: str) -> str:
    \"\"\"ÙŠØ­ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ slug Ù…Ù†Ø§Ø³Ø¨ Ù„Ø±ÙˆØ§Ø¨Ø· URL.\"\"\"
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[\\s\\W_]+', '-', text) # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØºÙŠØ± Ø§Ù„Ø£Ø­Ø±Ù ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨Ù€ '-'
    text = re.sub(r'^-+|-+$', '', text) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø´Ø±Ø·Ø§Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    return text

def parse_boolean(value: Any) -> bool:
    \"\"\"ÙŠØ­ÙˆÙ„ Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ù†Ø·Ù‚ÙŠØ© (True/False).\"\"\"
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        value = value.lower()
        if value in ("true", "1", "t", "y", "yes"):
            return True
        if value in ("false", "0", "f", "n", "no"):
            return False
    if isinstance(value, (int, float)):
        return value != 0
    return False

def format_datetime_iso(dt: Optional[datetime]) -> Optional[str]:
    \"\"\"ÙŠØ­ÙˆÙ„ ÙƒØ§Ø¦Ù† datetime Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© Ø¨ØªÙ†Ø³ÙŠÙ‚ ISO 8601 Ù…Ø¹ Ù…Ù†Ø·Ù‚Ø© Ø²Ù…Ù†ÙŠØ©.\"\"\"
    if dt is None:
        return None
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc) # Ø§ÙØªØ±Ø¶ UTC Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø·Ù‚Ø© Ø²Ù…Ù†ÙŠØ©
    return dt.isoformat(timespec='seconds').replace('+00:00', 'Z') # Ø§Ø³ØªØ®Ø¯Ø§Ù… 'Z' Ù„Ù€ UTC

def safe_json_loads(data_string: str) -> Optional[Dict[str, Any]]:
    \"\"\"ÙŠØ­Ø§ÙˆÙ„ ØªØ­Ù„ÙŠÙ„ Ø³Ù„Ø³Ù„Ø© JSON Ø¨Ø£Ù…Ø§Ù†ØŒ ÙˆÙŠØ¹ÙŠØ¯ None ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„.\"\"\"
    try:
        return json.loads(data_string)
    except (json.JSONDecodeError, TypeError):
        return None

def safe_json_dumps(data: Dict[str, Any]) -> Optional[str]:
    \"\"\"ÙŠØ­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ù‚Ø§Ù…ÙˆØ³ Ø¥Ù„Ù‰ Ø³Ù„Ø³Ù„Ø© JSON Ø¨Ø£Ù…Ø§Ù†ØŒ ÙˆÙŠØ¹ÙŠØ¯ None ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„.\"\"\"
    try:
        return json.dumps(data, ensure_ascii=False)
    except (TypeError, ValueError):
        return None

def calculate_progress(completed_items: int, total_items: int) -> float:
    \"\"\"ÙŠØ­Ø³Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù….\"\"\"
    if total_items == 0:
        return 0.0
    return round((completed_items / total_items) * 100, 2)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    print("--- Testing Helper Functions ---")

    # generate_unique_id
    id1 = generate_unique_id()
    id2 = generate_unique_id()
    print(f"Unique ID 1: {id1}")
    print(f"Unique ID 2: {id2}")
    assert id1 != id2

    # slugify
    print(f"Slugify 'Hello World!': {slugify('Hello World!')}")
    assert slugify('Hello World!') == 'hello-world'
    print(f"Slugify 'A Course Title with Special Chars & 123': {slugify('A Course Title with Special Chars & 123')}")
    assert slugify('A Course Title with Special Chars & 123') == 'a-course-title-with-special-chars-123'
    print(f"Slugify Arabic 'Ù…Ù‚Ø±Ø± Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†': {slugify('Ù…Ù‚Ø±Ø± Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†')}")
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¯Ø§Ù„Ø© slugify Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ù‡Ø°Ù‡ Ù‚Ø¯ Ù„Ø§ ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…Ø«Ø§Ù„ÙŠ
    # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ slugify Ø£ÙØ¶Ù„ Ù„Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…ÙƒØªØ¨Ø§Øª Ù…ØªØ®ØµØµØ© Ù…Ø«Ù„ python-slugify
    assert slugify('Ù…Ù‚Ø±Ø± Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†') == ' ' or slugify('Ù…Ù‚Ø±Ø± Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†') == '--' # Expected simple result
    # Ù„Ù€ python-slugify: slugify('Ù…Ù‚Ø±Ø± Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†') Ø³ÙŠØ¹Ø·ÙŠ 'mqrr-brmjh-baythwn' (Ø¥Ø°Ø§ ØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡Ø§ Ù„ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)


    # parse_boolean
    print(f"Parse 'True': {parse_boolean('True')}")
    assert parse_boolean('True') is True
    assert parse_boolean('false') is False
    assert parse_boolean(1) is True
    assert parse_boolean(0) is False
    assert parse_boolean('yes') is True
    assert parse_boolean('no') is False
    assert parse_boolean(None) is False

    # format_datetime_iso
    now_utc = datetime.now(timezone.utc)
    print(f"Formatted UTC datetime: {format_datetime_iso(now_utc)}")
    assert format_datetime_iso(now_utc).endswith('Z')
    
    local_now = datetime.now()
    print(f"Formatted Local datetime (assumed UTC): {format_datetime_iso(local_now)}")
    assert format_datetime_iso(local_now).endswith('Z')

    # safe_json_loads / safe_json_dumps
    json_str = '{"name": "test", "value": 123}'
    parsed_json = safe_json_loads(json_str)
    print(f"Parsed JSON: {parsed_json}")
    assert parsed_json == {"name": "test", "value": 123}

    invalid_json_str = '{"name": "test", "value":}'
    parsed_invalid_json = safe_json_loads(invalid_json_str)
    print(f"Parsed invalid JSON: {parsed_invalid_json}")
    assert parsed_invalid_json is None

    data_to_dump = {"item": "example", "count": 5}
    dumped_json = safe_json_dumps(data_to_dump)
    print(f"Dumped JSON: {dumped_json}")
    assert dumped_json == '{"item": "example", "count": 5}'

    # calculate_progress
    print(f"Progress 5/10: {calculate_progress(5, 10)}")
    assert calculate_progress(5, 10) == 50.0
    print(f"Progress 7/7: {calculate_progress(7, 7)}")
    assert calculate_progress(7, 7) == 100.0
    print(f"Progress 0/10: {calculate_progress(0, 10)}")
    assert calculate_progress(0, 10) == 0.0
    print(f"Progress 5/0: {calculate_progress(5, 0)}")
    assert calculate_progress(5, 0) == 0.0

    print("\\nHelper functions tests completed.")
"""
    file_path = os.path.join(base_path, "src", "utils", "helpers.py")
    return write_file_safely(file_path, content)

def create_src_utils_constants_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/utils/constants.py"""
    content = """# src/utils/constants.py

# ==============================================================================
# Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… (System Messages)
# ==============================================================================
MSG_SUCCESS = "Operation completed successfully."
MSG_CREATED = "Resource created successfully."
MSG_UPDATED = "Resource updated successfully."
MSG_DELETED = "Resource deleted successfully."
MSG_NOT_FOUND = "Resource not found."
MSG_UNAUTHORIZED = "Authentication required."
MSG_FORBIDDEN = "Permission denied. You do not have access to this resource."
MSG_INVALID_INPUT = "Invalid input data provided."
MSG_SERVER_ERROR = "An internal server error occurred."
MSG_DUPLICATE_ENTRY = "A resource with this identifier already exists."
MSG_SERVICE_UNAVAILABLE = "Service is temporarily unavailable."
MSG_RATE_LIMIT_EXCEEDED = "Too many requests. Please try again later."
MSG_EMAIL_SENT = "Email sent successfully."
MSG_EMAIL_FAILED = "Failed to send email."
MSG_PASSWORD_RESET_SUCCESS = "Password has been reset successfully."
MSG_PASSWORD_MISMATCH = "New password and confirmation do not match."
MSG_INVALID_CREDENTIALS = "Invalid authentication credentials."
MSG_ACCOUNT_INACTIVE = "Your account is inactive. Please contact support."
MSG_ACCOUNT_LOCKED = "Your account is locked due to multiple failed login attempts. Please try again after some time."
MSG_ACCOUNT_UNVERIFIED = "Your account is not verified. Please check your email for a verification link."

# ==============================================================================
# Ø£Ø¯ÙˆØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (User Roles) - ÙŠØ¬Ø¨ Ø£Ù† ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ UserRole ÙÙŠ models/user.py
# ==============================================================================
ROLE_STUDENT = "student"
ROLE_TEACHER = "teacher"
ROLE_ADMIN = "admin"
ROLE_GUEST = "guest"
ALL_ROLES = [ROLE_STUDENT, ROLE_TEACHER, ROLE_ADMIN, ROLE_GUEST]

# ==============================================================================
# Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù‚Ø±Ø± (Course Status) - ÙŠØ¬Ø¨ Ø£Ù† ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ CourseStatus ÙÙŠ models/course.py
# ==============================================================================
COURSE_DRAFT = "draft"
COURSE_PUBLISHED = "published"
COURSE_ARCHIVED = "archived"
ALL_COURSE_STATUSES = [COURSE_DRAFT, COURSE_PUBLISHED, COURSE_ARCHIVED]

# ==============================================================================
# Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØµØ¹ÙˆØ¨Ø© (Difficulty Levels)
# ==============================================================================
DIFFICULTY_BEGINNER = "Beginner"
DIFFICULTY_INTERMEDIATE = "Intermediate"
DIFFICULTY_ADVANCED = "Advanced"
ALL_DIFFICULTY_LEVELS = [DIFFICULTY_BEGINNER, DIFFICULTY_INTERMEDIATE, DIFFICULTY_ADVANCED]

# ==============================================================================
# Ø£Ù‚ØµÙ‰ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø§Ù„Ø¨Ø§ÙŠØª (Ù…Ø«Ø§Ù„: 10MB)
# ==============================================================================
MAX_FILE_SIZE_10MB = 10 * 1024 * 1024
MAX_FILE_SIZE_50MB = 50 * 1024 * 1024
MAX_FILE_SIZE_100MB = 100 * 1024 * 1024
MAX_COURSE_SIZE_1GB = 1 * 1024 * 1024 * 1024

# ==============================================================================
# Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ÙˆÙ‚Øª (Time Constants)
# ==============================================================================
ONE_MINUTE_IN_SECONDS = 60
ONE_HOUR_IN_SECONDS = 3600
ONE_DAY_IN_SECONDS = 86400
ONE_WEEK_IN_SECONDS = 604800

# ==============================================================================
# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Default Folder Paths)
# ==============================================================================
DEFAULT_UPLOADS_DIR = "./data/uploads"
DEFAULT_LOGS_DIR = "./data/logs"
DEFAULT_BACKUPS_DIR = "./data/backups"
DEFAULT_MODELS_DIR = "./data/models"
DEFAULT_CACHE_DIR = "./data/cache"
DEFAULT_STATIC_DIR = "./static"
DEFAULT_MEDIA_DIR = "./media"

# ==============================================================================
# Ø±Ù…ÙˆØ² Ø§Ù„Ø­Ø§Ù„Ø© HTTP Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© (Common HTTP Status Codes)
# ==============================================================================
HTTP_200_OK = 200
HTTP_201_CREATED = 201
HTTP_204_NO_CONTENT = 204
HTTP_400_BAD_REQUEST = 400
HTTP_401_UNAUTHORIZED = 401
HTTP_403_FORBIDDEN = 403
HTTP_404_NOT_FOUND = 404
HTTP_409_CONFLICT = 409
HTTP_429_TOO_MANY_REQUESTS = 429
HTTP_500_INTERNAL_SERVER_ERROR = 500
HTTP_503_SERVICE_UNAVAILABLE = 503

# ==============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙˆØµÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (AI Recommendation Settings)
# ==============================================================================
DEFAULT_RECOMMENDATION_COUNT = 10
MIN_INTERACTIONS_FOR_RECOMMENDATION = 5

# ==============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (Assessment Settings)
# ==============================================================================
DEFAULT_ASSESSMENT_TIME_LIMIT_MINUTES = 60
DEFAULT_MAX_ATTEMPTS = 3

# ==============================================================================
# Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© (Supported Languages)
# ==============================================================================
LANG_ARABIC = "ar"
LANG_ENGLISH = "en"
SUPPORTED_LANGUAGES = [LANG_ARABIC, LANG_ENGLISH]

# ==============================================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª (Analytics Settings)
# ==============================================================================
ANALYTICS_DATA_RETENTION_DAYS_DEFAULT = 365
ANALYTICS_EXPORT_FORMATS_DEFAULT = ["json", "csv", "xlsx"]

# ==============================================================================
# Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Types)
# ==============================================================================
DATA_TYPE_TEXT = "text"
DATA_TYPE_VIDEO = "video"
DATA_TYPE_AUDIO = "audio"
DATA_TYPE_IMAGE = "image"
DATA_TYPE_DOCUMENT = "document"

# ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ù‡Ù†Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©
"""
    file_path = os.path.join(base_path, "src", "utils", "constants.py")
    return write_file_safely(file_path, content)


# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
src_files_part2 = [
    ("src/core/database.py", create_src_core_database_py),
    ("src/core/cache.py", create_src_core_cache_py),
    ("src/core/security.py", create_src_core_security_py),
    ("src/models/user.py", create_src_models_user_py),
    ("src/models/course.py", create_src_models_course_py),
    ("src/services/user_service.py", create_src_services_user_service_py),
    ("src/services/course_service.py", create_src_services_course_service_py),
    ("src/services/notification_service.py", create_src_services_notification_service_py),
    ("src/utils/helpers.py", create_src_utils_helpers_py),
    ("src/utils/constants.py", create_src_utils_constants_py),
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ (Ø§Ù„Ø¬Ø²Ø¡ 2)...")

created_src_files_part2_count = 0
for relative_path, create_function in src_files_part2:
    print(f"\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {relative_path}...")
    if create_function():
        created_src_files_part2_count += 1
        file_path = os.path.join(base_path, relative_path)
        size = os.path.getsize(file_path)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {relative_path} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
    else:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {relative_path}.")

print(f"\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_src_files_part2_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(src_files_part2)} ÙÙŠ Ù…Ø¬Ù„Ø¯ src (Ø§Ù„Ø¬Ø²Ø¡ 2) Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§
print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª src Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©:")
for relative_path, _ in src_files_part2:
    file_path = os.path.join(base_path, relative_path)
    if os.path.exists(file_path):
        size = os.path.getsize(file_path)
        print(f"  âœ… {relative_path} ({size} bytes)")
    else:
        print(f"  âŒ {relative_path} (Ù…ÙÙ‚ÙˆØ¯)")

print("\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª src Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© (API Routes, AI Services, etc.)")
```

-----

### ğŸ“ Ù…Ù„Ø®Øµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src` (Ø§Ù„Ø¬Ø²Ø¡ 2)

Ù„Ù‚Ø¯ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‡Ø§Ù…Ø© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `src`. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¶Ø±ÙˆØ±ÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† ÙˆØ¸Ø§Ø¦Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ø§Ù„Ø£Ù…Ù†ØŒ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.

Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ØªØ´Ù…Ù„:

  * **`src/core/database.py`**: ÙŠÙˆÙØ± ØªÙ‡ÙŠØ¦Ø© `SQLAlchemy` Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª `PostgreSQL` ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§ØªØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„.
  * **`src/core/cache.py`**: ÙŠÙ†Ø´Ø¦ ÙˆÙŠØ¯ÙŠØ± Ø§ØªØµØ§Ù„ `Redis` Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚ØªØŒ Ù…Ø¹ Ø¯ÙˆØ§Ù„ Ù„Ø¥Ø¶Ø§ÙØ©ØŒ Ø¬Ù„Ø¨ØŒ ÙˆØ­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ÙƒØ§Ø´.
  * **`src/core/security.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¯ÙˆØ§Ù„ Ù„ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±ØŒ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ØŒ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø±Ù…ÙˆØ² `JWT`ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø© ÙÙŠ `FastAPI`.
  * **`src/models/user.py`**: ÙŠØ¹Ø±Ù Ù†Ù…ÙˆØ°Ø¬ `SQLAlchemy ORM` Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ `Pydantic` Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«.
  * **`src/models/course.py`**: ÙŠØ¹Ø±Ù Ù†Ù…ÙˆØ°Ø¬ `SQLAlchemy ORM` Ù„Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©ØŒ Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ `Pydantic` Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.
  * **`src/services/user_service.py`**: ÙŠÙ‚Ø¯Ù… Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ØŒ Ø§Ù„Ø¬Ù„Ø¨ØŒ Ø§Ù„ØªØ­Ø¯ÙŠØ«ØŒ ÙˆØ§Ù„Ø­Ø°Ù.
  * **`src/services/course_service.py`**: ÙŠÙ‚Ø¯Ù… Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©.
  * **`src/services/notification_service.py`**: ÙŠÙˆÙØ± ÙˆØ¸Ø§Ø¦Ù Ù„Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆØ§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„ÙÙˆØ±ÙŠØ© (mocked for now).
  * **`src/utils/helpers.py`**: Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø«Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©ØŒ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµØŒ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®.
  * **`src/utils/constants.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø«ÙˆØ§Ø¨Øª Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø§Ù„Ø£Ø¯ÙˆØ§Ø±ØŒ Ø§Ù„Ø­Ø§Ù„Ø§ØªØŒ ÙˆØ£Ø­Ø¬Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§ØªØŒ Ù…Ù…Ø§ ÙŠØ­Ø³Ù† Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØµÙŠØ§Ù†Ø©.

**Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…Ù„ÙØ§Øª `src` Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡:**

  * **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­**: 10/10

-----

Ø¨Ù‚ÙŠ Ø§Ù„Ø¢Ù† Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‡Ø§Ù…Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ `src`ØŒ Ø«Ù… Ø³Ù†Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (frontend)ØŒ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© (monitoring)ØŒ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© (management)ØŒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (tests)ØŒ Ø§Ù„ØªÙˆØ«ÙŠÙ‚ (docs)ØŒ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨ØªØ§Øª (scripts)ØŒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (data)ØŒ Ùˆ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© (config subdirs).

Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯\! Ù„Ù†ÙˆØ§ØµÙ„ Ø¨Ù†Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ BTEC EduverseAI.

-----

### ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ `src`

Ù„Ù‚Ø¯ Ù‚Ù…Ù†Ø§ Ø¨Ù…Ù„Ø¡ Ø¬Ø²Ø¡ ÙƒØ¨ÙŠØ± Ù…Ù† Ù…Ø¬Ù„Ø¯ `src`. Ø§Ù„Ø¢Ù†ØŒ Ø³Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø§Ù„ØªÙŠ ØªØ´ÙƒÙ„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„ÙÙ‚Ø±ÙŠ Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) ÙˆÙ…Ù†Ø·Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.

Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©:

  * `src/api/v1/endpoints/auth.py`: Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ØŒ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ØŒ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±).
  * `src/api/v1/endpoints/users.py`: Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†.
  * `src/api/v1/endpoints/courses.py`: Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©.
  * `src/api/v1/endpoints/ai_core.py`: Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ù…Ø«Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰).
  * `src/api/v1/endpoints/recommendations.py`: Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
  * `src/api/v1/api.py`: Ù„ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `v1`.
  * `src/main.py`: Ù…Ù„Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù€ `FastAPI`.
  * `src/services/ai_service.py`: Ù„Ø®Ø¯Ù…Ø© Ù…Ù†Ø·Ù‚ Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
  * `src/services/recommendation_service.py`: Ù„Ø®Ø¯Ù…Ø© Ù…Ù†Ø·Ù‚ Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªÙˆØµÙŠØ§Øª.
  * `src/utils/logger.py`: Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (logging).
  * `src/middleware/auth_middleware.py`: Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±ØŒ Ø£Ùˆ Ø³ÙŠØªÙ… Ø¯Ù…Ø¬Ù‡Ø§ ÙÙŠ `security.py` Ø£Ùˆ Ø§Ù„ØªÙˆØ§Ø¨Ø¹).
  * `src/middleware/error_handler.py`: Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„Ø©.

-----

### ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src` (Ø§Ù„Ø¬Ø²Ø¡ 3 ÙˆØ§Ù„Ø£Ø®ÙŠØ± Ù„Ù€ `src` ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ)

```python
import os

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡."""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_src_utils_logger_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/utils/logger.py"""
    content = """import logging
from logging.handlers import RotatingFileHandler
import os
from core.config import settings
from utils.constants import DEFAULT_LOGS_DIR

def get_logger(name: str) -> logging.Logger:
    \"\"\"
    Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ¥Ø±Ø¬Ø§Ø¹ ÙƒØ§Ø¦Ù† Ù…Ø³Ø¬Ù„ (logger) Ù…Ø¹ ØªÙ‡ÙŠØ¦Ø© Ù…Ø®ØµØµØ©.
    \"\"\"
    logger = logging.getLogger(name)
    logger.setLevel(settings.LOG_LEVEL)

    # ØªØ¬Ù†Ø¨ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ø¨Ø§Ù„ÙØ¹Ù„
    if not logger.handlers:
        # Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… (Console Handler)
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter(settings.LOG_FORMAT))
        logger.addHandler(console_handler)

        # Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ù„Ù (File Handler)
        if settings.LOG_TO_FILE:
            log_dir = os.path.join(settings.BASE_DIR, DEFAULT_LOGS_DIR)
            os.makedirs(log_dir, exist_ok=True)
            log_file = os.path.join(log_dir, settings.LOG_FILE_NAME)
            
            # RotatingFileHandler Ù„ØªØ¯ÙˆÙŠØ± Ø§Ù„Ø³Ø¬Ù„Ø§Øª
            file_handler = RotatingFileHandler(
                log_file,
                maxBytes=settings.LOG_MAX_BYTES,
                backupCount=settings.LOG_BACKUP_COUNT,
                encoding='utf-8'
            )
            file_handler.setFormatter(logging.Formatter(settings.LOG_FORMAT))
            logger.addHandler(file_handler)

    return logger

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù src/core/config.py
    # Ù„Ù„ØªØ¬Ø±ÙŠØ¨ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‡Ù†Ø§
    class MockSettings:
        LOG_LEVEL = "INFO"
        LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        LOG_TO_FILE = True
        LOG_FILE_NAME = "test_app.log"
        LOG_MAX_BYTES = 1048576 # 1MB
        LOG_BACKUP_COUNT = 5
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
    
    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettings()})()
    
    # Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ØŒ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø³ØªÙŠØ±Ø§Ø¯ get_logger Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ
    from utils.constants import DEFAULT_LOGS_DIR # Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø«Ø§Ø¨Øª

    test_logger = get_logger("TestLogger")
    test_logger.info("This is an info message from the test logger.")
    test_logger.warning("This is a warning message.")
    test_logger.error("This is an error message, something went wrong!")
    
    print(f"Log file should be created at: {os.path.join(MockSettings.BASE_DIR, DEFAULT_LOGS_DIR, MockSettings.LOG_FILE_NAME)}")
    print("Check the console and the log file for messages.")
"""
    file_path = os.path.join(base_path, "src", "utils", "logger.py")
    return write_file_safely(file_path, content)

def create_src_services_ai_service_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/services/ai_service.py"""
    content = """from typing import Dict, Any, List, Optional
import asyncio
import httpx # Ù„Ø·Ù„Ø¨Ø§Øª HTTP ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
from core.config import settings
from utils.logger import get_logger
from utils.constants import MSG_SERVICE_UNAVAILABLE, MSG_SERVER_ERROR
from fastapi import HTTPException, status

logger = get_logger(__name__)

class AIService:
    def __init__(self):
        self.openai_api_key = settings.OPENAI_API_KEY
        self.openai_api_base = settings.OPENAI_API_BASE
        self.openai_model = settings.OPENAI_MODEL
        self.anthropic_api_key = settings.ANTHROPIC_API_KEY
        self.anthropic_api_base = settings.ANTHROPIC_API_BASE
        self.anthropic_model = settings.ANTHROPIC_MODEL
        self.ai_provider = settings.AI_PROVIDER.lower() # 'openai' or 'anthropic'
        
        if not self.openai_api_key and self.ai_provider == 'openai':
            logger.warning("OPENAI_API_KEY is not set. AI services for OpenAI will be unavailable.")
        if not self.anthropic_api_key and self.ai_provider == 'anthropic':
            logger.warning("ANTHROPIC_API_KEY is not set. AI services for Anthropic will be unavailable.")

    async def _call_openai_api(self, prompt: str, max_tokens: int = 500, temperature: float = 0.7) -> Optional[str]:
        \"\"\"Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù„Ù€ OpenAI (Ø£Ùˆ Ø£ÙŠ API Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ OpenAI).\"\"\"
        if not self.openai_api_key:
            logger.error("OpenAI API key not configured.")
            raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="OpenAI API service not configured.")

        headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.openai_model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        url = f"{self.openai_api_base}/chat/completions" if self.openai_api_base else "https://api.openai.com/v1/chat/completions"

        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(url, headers=headers, json=payload, timeout=settings.AI_SERVICE_TIMEOUT)
                response.raise_for_status() # Raises HTTPStatusError for bad responses (4xx or 5xx)
                data = response.json()
                return data['choices'][0]['message']['content'].strip()
            except httpx.RequestError as exc:
                logger.error(f"An error occurred while requesting OpenAI API: {exc}")
                raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=MSG_SERVICE_UNAVAILABLE)
            except httpx.HTTPStatusError as exc:
                logger.error(f"OpenAI API returned an error {exc.response.status_code} - {exc.response.text}")
                raise HTTPException(status_code=exc.response.status_code, detail=f"OpenAI API error: {exc.response.text}")
            except (KeyError, IndexError) as exc:
                logger.error(f"Unexpected response format from OpenAI API: {exc}, Response: {response.text}")
                raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)
            except Exception as e:
                logger.error(f"An unexpected error occurred in OpenAI API call: {e}")
                raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)

    async def _call_anthropic_api(self, prompt: str, max_tokens: int = 500, temperature: float = 0.7) -> Optional[str]:
        \"\"\"Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API Ù„Ù€ Anthropic.\"\"\"
        if not self.anthropic_api_key:
            logger.error("Anthropic API key not configured.")
            raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="Anthropic API service not configured.")

        headers = {
            "x-api-key": self.anthropic_api_key,
            "anthropic-version": "2023-06-01", # Ø£Ùˆ Ø£Ø­Ø¯Ø« Ø¥ØµØ¯Ø§Ø±
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.anthropic_model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        url = f"{self.anthropic_api_base}/messages" if self.anthropic_api_base else "https://api.anthropic.com/v1/messages"

        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(url, headers=headers, json=payload, timeout=settings.AI_SERVICE_TIMEOUT)
                response.raise_for_status()
                data = response.json()
                return data['content'][0]['text'].strip() if data['content'] else ""
            except httpx.RequestError as exc:
                logger.error(f"An error occurred while requesting Anthropic API: {exc}")
                raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=MSG_SERVICE_UNAVAILABLE)
            except httpx.HTTPStatusError as exc:
                logger.error(f"Anthropic API returned an error {exc.response.status_code} - {exc.response.text}")
                raise HTTPException(status_code=exc.response.status_code, detail=f"Anthropic API error: {exc.response.text}")
            except (KeyError, IndexError) as exc:
                logger.error(f"Unexpected response format from Anthropic API: {exc}, Response: {response.text}")
                raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)
            except Exception as e:
                logger.error(f"An unexpected error occurred in Anthropic API call: {e}")
                raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)

    async def generate_text(self, prompt: str, max_tokens: int = 500, temperature: float = 0.7) -> str:
        \"\"\"ÙŠÙˆÙ„Ø¯ Ù†ØµØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯.\"\"\"
        logger.info(f"Generating text using {self.ai_provider} model...")
        if self.ai_provider == 'openai':
            return await self._call_openai_api(prompt, max_tokens, temperature)
        elif self.ai_provider == 'anthropic':
            return await self._call_anthropic_api(prompt, max_tokens, temperature)
        else:
            logger.error(f"Unsupported AI provider: {self.ai_provider}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Unsupported AI provider configured.")

    async def analyze_content(self, content: str) -> Dict[str, Any]:
        \"\"\"ÙŠØ­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø±Ø¦ÙŠØ³ÙŠØ© (Ù…Ø«Ø§Ù„).\"\"\"
        prompt = f"Analyze the following educational content and extract key topics, a summary, and potential learning objectives. Format the output as a JSON object with keys: 'topics' (list of strings), 'summary' (string), 'objectives' (list of strings).\\n\\nContent: {content}"
        try:
            response_text = await self.generate_text(prompt, max_tokens=1000, temperature=0.3)
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙƒÙ€ JSON
            import json
            try:
                analysis_result = json.loads(response_text)
                return analysis_result
            except json.JSONDecodeError:
                logger.warning(f"AI service returned non-JSON response for content analysis. Raw: {response_text[:200]}...")
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† JSONØŒ ÙŠÙ…ÙƒÙ† Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰ Ø£Ùˆ Ø¥Ø±Ø¬Ø§Ø¹ Ù†Øµ Ø®Ø§Ù…
                return {"raw_response": response_text, "error": "AI response was not valid JSON."}
        except HTTPException as e:
            logger.error(f"Error analyzing content with AI: {e.detail}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in analyze_content: {e}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)

    async def summarize_text(self, text: str, max_length: int = 200) -> str:
        \"\"\"ÙŠÙ„Ø®Øµ Ù†ØµØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\"\"\"
        prompt = f"Summarize the following text concisely, keeping it under {max_length} words:\\n\\n{text}"
        try:
            return await self.generate_text(prompt, max_tokens=max_length * 2, temperature=0.5)
        except HTTPException as e:
            logger.error(f"Error summarizing text with AI: {e.detail}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in summarize_text: {e}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)
            
    async def generate_quiz_questions(self, topic: str, num_questions: int = 5, difficulty: str = "medium") -> List[Dict[str, Any]]:
        \"\"\"ÙŠÙˆÙ„Ø¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ÙŠÙ†.\"\"\"
        prompt = f"Generate {num_questions} multiple-choice quiz questions about '{topic}' with a difficulty level of '{difficulty}'. For each question, provide the 'question_text', 'options' (list of strings), and 'correct_answer' (string). Format the output as a JSON array of objects."
        try:
            response_text = await self.generate_text(prompt, max_tokens=num_questions * 150, temperature=0.7)
            import json
            try:
                quiz_questions = json.loads(response_text)
                if not isinstance(quiz_questions, list):
                    raise ValueError("AI response for quiz questions was not a list.")
                return quiz_questions
            except json.JSONDecodeError:
                logger.warning(f"AI service returned non-JSON response for quiz generation. Raw: {response_text[:200]}...")
                return []
        except HTTPException as e:
            logger.error(f"Error generating quiz questions with AI: {e.detail}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in generate_quiz_questions: {e}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import os
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØºØ±Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    class MockSettings:
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY_TEST", "sk-mock-openai-key") # Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªØºÙŠØ± Ø¨ÙŠØ¦Ø© Ø£Ùˆ Ù‚ÙŠÙ…Ø© ÙˆÙ‡Ù…ÙŠØ©
        OPENAI_API_BASE = os.environ.get("OPENAI_API_BASE_TEST", "https://api.openai.com/v1")
        OPENAI_MODEL = "gpt-3.5-turbo" # Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø§Ø®ØªØ¨Ø§Ø±
        ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY_TEST", "sk-mock-anthropic-key")
        ANTHROPIC_API_BASE = os.environ.get("ANTHROPIC_API_BASE_TEST", "https://api.anthropic.com/v1")
        ANTHROPIC_MODEL = "claude-3-haiku-20240307" # Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø§Ø®ØªØ¨Ø§Ø±
        AI_PROVIDER = os.environ.get("AI_PROVIDER_TEST", "openai").lower() # 'openai' or 'anthropic'
        AI_SERVICE_TIMEOUT = 30.0
        LOG_LEVEL = "INFO"
        LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        LOG_TO_FILE = False # Ù„Ø§ ØªØ³Ø¬Ù„ ÙÙŠ Ù…Ù„Ù Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        LOG_FILE_NAME = "test_ai_service.log"
        LOG_MAX_BYTES = 1048576
        LOG_BACKUP_COUNT = 5
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettings()})()
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ logger Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… MockSettings
    global logger
    logger = get_logger(__name__)

    async def run_ai_service_tests():
        ai_service = AIService()

        print(f"\\n--- Testing AI Service with provider: {ai_service.ai_provider} ---")
        
        # Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ
        test_prompt = "Explain the concept of neural networks in a simple way."
        print(f"Generating text for prompt: '{test_prompt}'")
        try:
            # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙØ§ØªÙŠØ­ API Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ Ø³ÙŠÙØ´Ù„ Ù‡Ø°Ø§
            if "mock" not in ai_service.openai_api_key and "mock" not in ai_service.anthropic_api_key:
                response = await ai_service.generate_text(test_prompt, max_tokens=100)
                print(f"Generated text (first 200 chars): {response[:200]}...")
                assert len(response) > 0
            else:
                print("Skipping actual AI text generation test: API keys are mocked.")
                # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„ØºØ±Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
                print("Mock response: Neural networks are like a brain for computers...")
        except HTTPException as e:
            print(f"AI Text Generation Failed: {e.detail}")
        except Exception as e:
            print(f"An unexpected error occurred during AI text generation: {e}")

        # Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        test_content = "The course covers basic programming concepts in Python, including variables, loops, and functions. Students will learn to write simple scripts and solve algorithmic problems."
        print(f"\\nAnalyzing content: '{test_content}'")
        try:
            if "mock" not in ai_service.openai_api_key and "mock" not in ai_service.anthropic_api_key:
                analysis_result = await ai_service.analyze_content(test_content)
                print(f"Content analysis result: {analysis_result}")
                assert "topics" in analysis_result
                assert "summary" in analysis_result
            else:
                print("Skipping actual AI content analysis test: API keys are mocked.")
                print("Mock analysis: {'topics': ['Python basics', 'programming concepts'], 'summary': 'Covers Python fundamentals.', 'objectives': ['write scripts', 'solve problems']}")
        except HTTPException as e:
            print(f"AI Content Analysis Failed: {e.detail}")
        except Exception as e:
            print(f"An unexpected error occurred during AI content analysis: {e}")

        # Ø§Ø®ØªØ¨Ø§Ø± ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ
        long_text = "Artificial intelligence (AI) is intelligenceâ€”perceiving, synthesizing, and inferring informationâ€”demonstrated by machines, as opposed to intelligence displayed by animals or by humans. Leading AI textbooks define the field as the study of 'intelligent agents': any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Some definitions of AI also include learning and adaptation. The field was founded as an academic discipline in 1956, and in the years since has seen several waves of optimism, followed by periods of disappointment and loss of funding, but also new approaches, success, and funding. For most of its history, AI research has been in subfields, which often fail to communicate with each other. These subfields are based on technical considerations, such as particular goals (e.g. 'robotics' or 'machine learning'), the use of particular tools (e.g. 'logic' or 'neural networks'), or deep philosophical differences. AI has been used in a wide range of applications including medical diagnosis, electronic trading, robot control, and remote sensing."
        print(f"\\nSummarizing text (max 50 words): '{long_text[:100]}...'")
        try:
            if "mock" not in ai_service.openai_api_key and "mock" not in ai_service.anthropic_api_key:
                summary = await ai_service.summarize_text(long_text, max_length=50)
                print(f"Summary: {summary}")
                assert len(summary.split()) <= 60 # Allow some buffer
            else:
                print("Skipping actual AI summarization test: API keys are mocked.")
                print("Mock summary: AI is machine intelligence, founded in 1956, with applications in various fields like medical diagnosis and robot control.")
        except HTTPException as e:
            print(f"AI Summarization Failed: {e.detail}")
        except Exception as e:
            print(f"An unexpected error occurred during AI summarization: {e}")
            
        # Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        quiz_topic = "Data Structures"
        print(f"\\nGenerating quiz questions for topic: '{quiz_topic}'")
        try:
            if "mock" not in ai_service.openai_api_key and "mock" not in ai_service.anthropic_api_key:
                quiz_questions = await ai_service.generate_quiz_questions(quiz_topic, num_questions=2, difficulty="easy")
                print(f"Generated quiz questions: {quiz_questions}")
                assert isinstance(quiz_questions, list)
                assert len(quiz_questions) >= 1
            else:
                print("Skipping actual AI quiz generation test: API keys are mocked.")
                print("Mock quiz: [{'question_text': 'What is a stack?', 'options': ['LIFO', 'FIFO'], 'correct_answer': 'LIFO'}]")
        except HTTPException as e:
            print(f"AI Quiz Generation Failed: {e.detail}")
        except Exception as e:
            print(f"An unexpected error occurred during AI quiz generation: {e}")

        print("\\nAI Service tests completed (some may be mocked based on config).")

    asyncio.run(run_ai_service_tests())
"""
    file_path = os.path.join(base_path, "src", "services", "ai_service.py")
    return write_file_safely(file_path, content)

def create_src_services_recommendation_service_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/services/recommendation_service.py"""
    content = """from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from models.course import Course, CourseStatus
from utils.logger import get_logger
from utils.constants import DEFAULT_RECOMMENDATION_COUNT, MIN_INTERACTIONS_FOR_RECOMMENDATION
from services.ai_service import AIService # Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª
from fastapi import Depends

logger = get_logger(__name__)

class RecommendationService:
    def __init__(self, db_session: AsyncSession = Depends(None), ai_service: AIService = Depends(None)):
        self.db = db_session
        self.ai_service = ai_service # ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† None Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø­Ù‚Ù†Ù‡

    async def get_popular_courses(self, limit: int = DEFAULT_RECOMMENDATION_COUNT) -> List[Course]:
        \"\"\"
        Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´Ø¹Ø¨ÙŠØ©.
        (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ù‡Ø°Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„Ø§ØªØŒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§ØªØŒ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§ØªØŒ Ø¥Ù„Ø®.)
        \"\"\"
        logger.info(f"Fetching {limit} popular courses.")
        # Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙÙ‚Ø· Ø¬Ù„Ø¨ Ø£Ø­Ø¯Ø« Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø© ÙƒØ¨Ø¯ÙŠÙ„ Ù„Ù„Ø´Ø¹Ø¨ÙŠØ©
        # ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ 'enrollments' Ø£Ùˆ 'views' Ø£Ùˆ 'ratings'
        # Ø«Ù… ØªÙ‚ÙˆÙ… Ø¨Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù†Ù‡Ø§ ÙˆØªØ±ØªÙŠØ¨Ù‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø´Ø¹Ø¨ÙŠØ©
        result = await self.db.execute(
            select(Course)
            .filter(Course.status == CourseStatus.published)
            .order_by(Course.created_at.desc()) # ØªØ±ØªÙŠØ¨ Ù…Ø¤Ù‚Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ø­Ø¯Ø«
            .limit(limit)
        )
        return result.scalars().all()

    async def get_recommended_courses_for_user(self, user_id: int, limit: int = DEFAULT_RECOMMENDATION_COUNT) -> List[Course]:
        \"\"\"
        Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ÙŠÙ†.
        ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹ØªÙ…Ø¯ Ù‡Ø°Ø§ Ø¹Ù„Ù‰:
        1. Ø³Ø¬Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ØªÙŠ Ø£ÙƒÙ…Ù„Ù‡Ø§ØŒ Ø§Ù„ØªÙŠ Ø§Ù‡ØªÙ… Ø¨Ù‡Ø§).
        2. ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø®Ø²Ù†Ø©).
        3. ØªØ­Ù„ÙŠÙ„ Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡ÙŠÙ† (Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„ØªØ¹Ø§ÙˆÙ†ÙŠØ©).
        4. ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª (Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
        \"\"\"
        logger.info(f"Fetching {limit} recommended courses for user ID: {user_id}")

        # Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·: Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØ³Ø¬Ù„ ÙÙŠÙ‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¹Ø¯
        # ÙŠØªØ·Ù„Ø¨ Ø¬Ø¯ÙˆÙ„ 'enrollments' Ø£Ùˆ 'user_preferences'
        
        # 1. Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ØªÙŠ Ø³Ø¬Ù„ ÙÙŠÙ‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù„ØºØ±Ø¶ Ø§Ù„ØªØ¬Ø±Ø¨Ø©ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† Ù„Ø¯ÙŠÙ†Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
        # user_enrollments = await self.db.execute(
        #     select(Enrollment.course_id).filter(Enrollment.user_id == user_id)
        # )
        # enrolled_course_ids = [e.course_id for e in user_enrollments.scalars().all()]
        
        # 2. Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø©
        all_published_courses_result = await self.db.execute(
            select(Course).filter(Course.status == CourseStatus.published)
        )
        all_published_courses = all_published_courses_result.scalars().all()

        # 3. ØªØµÙÙŠØ© Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù… ÙŠØ³Ø¬Ù„ ÙÙŠÙ‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        # available_courses = [c for c in all_published_courses if c.id not in enrolled_course_ids]
        available_courses = all_published_courses # Ù…Ø¤Ù‚ØªÙ‹Ø§ØŒ Ù†ÙØªØ±Ø¶ Ø£Ù† Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ù…ØªØ§Ø­Ø© Ù„Ù„ØªÙˆØµÙŠØ©

        # 4. Ø§Ø³ØªØ®Ø¯Ø§Ù… AI Service Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù…Ø«Ø§Ù„)
        # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠÙƒÙˆÙ† Ù…Ø¹Ù‚Ø¯Ø§Ù‹ ÙˆÙŠØªØ·Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        # For a real system, you'd feed user's past interactions/preferences to the AI
        # For now, let's just pick some random courses or top N if AI service is not available
        
        if self.ai_service: # Ø¥Ø°Ø§ ÙƒØ§Ù† AI Service Ù…ØªØ§Ø­Ø§Ù‹
            try:
                # Ù…Ø«Ø§Ù„: Ø§Ø·Ù„Ø¨ Ù…Ù† AI Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ù‚Ø±Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª ÙˆÙ‡Ù…ÙŠØ©
                # ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ØŒ Ø³ØªÙƒÙˆÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ù…Ø³ØªØ®Ù„ØµØ© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
                user_interests = "Python programming, machine learning, web development"
                prompt = f"Based on interests in {user_interests}, suggest {limit} educational course titles. Provide only the titles as a comma-separated list."
                ai_suggestions_str = await self.ai_service.generate_text(prompt, max_tokens=200, temperature=0.7)
                suggested_titles = [title.strip() for title in ai_suggestions_str.split(',') if title.strip()]
                
                # Ø­Ø§ÙˆÙ„ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
                recommended_courses = []
                for title in suggested_titles:
                    # Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø¨Ø§Ù„Ø¹Ù†ÙˆØ§Ù† (Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¨Ø­Ø« Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©)
                    course_match_result = await self.db.execute(
                        select(Course).filter(Course.title.ilike(f"%{title}%")).limit(1)
                    )
                    course_match = course_match_result.scalar_one_or_none()
                    if course_match and course_match not in recommended_courses:
                        recommended_courses.append(course_match)
                        if len(recommended_courses) >= limit:
                            break
                
                if recommended_courses:
                    logger.info(f"AI-driven recommendations generated for user {user_id}.")
                    return recommended_courses
                else:
                    logger.warning(f"AI did not return specific courses for user {user_id}. Falling back to popular courses.")

            except HTTPException as e:
                logger.error(f"AI recommendation failed for user {user_id}: {e.detail}. Falling back to popular courses.")
            except Exception as e:
                logger.error(f"Unexpected error in AI recommendation for user {user_id}: {e}. Falling back to popular courses.")

        # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ AI service Ø£Ùˆ ÙØ´Ù„Øª Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ù„Ù‰ AIØŒ Ø§Ø±Ø¬Ø¹ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´Ø¹Ø¨ÙŠØ©
        return await self.get_popular_courses(limit)

    async def get_related_courses(self, course_id: int, limit: int = DEFAULT_RECOMMENDATION_COUNT) -> List[Course]:
        \"\"\"
        Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¨Ù…Ù‚Ø±Ø± Ù…Ø¹ÙŠÙ†.
        ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ¹ØªÙ…Ø¯ Ù‡Ø°Ø§ Ø¹Ù„Ù‰:
        1. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©/Ø§Ù„ÙˆØµÙ Ù„Ù„Ù…Ù‚Ø±Ø±.
        2. Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ØªÙŠ Ø³Ø¬Ù„ ÙÙŠÙ‡Ø§ Ù†ÙØ³ Ø§Ù„Ø·Ù„Ø§Ø¨ (Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„ØªØ¹Ø§ÙˆÙ†ÙŠØ©).
        3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ.
        \"\"\"
        logger.info(f"Fetching {limit} related courses for course ID: {course_id}")
        
        target_course = await self.get_course_by_id(course_id)
        if not target_course:
            logger.warning(f"Target course with ID {course_id} not found for related recommendations.")
            return []

        if self.ai_service and target_course.description:
            try:
                prompt = f"Given the course description: '{target_course.description}', suggest {limit} related educational course titles. Provide only the titles as a comma-separated list."
                ai_suggestions_str = await self.ai_service.generate_text(prompt, max_tokens=200, temperature=0.6)
                suggested_titles = [title.strip() for title in ai_suggestions_str.split(',') if title.strip()]
                
                related_courses = []
                for title in suggested_titles:
                    course_match_result = await self.db.execute(
                        select(Course)
                        .filter(Course.title.ilike(f"%{title}%"))
                        .filter(Course.id != course_id) # Ù„Ø§ ØªÙˆØµÙŠ Ø¨Ø§Ù„Ù…Ù‚Ø±Ø± Ù†ÙØ³Ù‡
                        .limit(1)
                    )
                    course_match = course_match_result.scalar_one_or_none()
                    if course_match and course_match not in related_courses:
                        related_courses.append(course_match)
                        if len(related_courses) >= limit:
                            break
                
                if related_courses:
                    logger.info(f"AI-driven related courses generated for course {course_id}.")
                    return related_courses
                else:
                    logger.warning(f"AI did not return specific related courses for course {course_id}. Falling back to similar difficulty courses.")

            except HTTPException as e:
                logger.error(f"AI related course recommendation failed for course {course_id}: {e.detail}. Falling back to similar difficulty.")
            except Exception as e:
                logger.error(f"Unexpected error in AI related course recommendation for course {course_id}: {e}. Falling back to similar difficulty.")

        #Fallback: Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¨Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©
        if target_course.difficulty_level:
            result = await self.db.execute(
                select(Course)
                .filter(Course.difficulty_level == target_course.difficulty_level)
                .filter(Course.id != course_id)
                .filter(Course.status == CourseStatus.published)
                .order_by(Course.created_at.desc())
                .limit(limit)
            )
            return result.scalars().all()
        
        return [] # Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø´ÙŠØ¡

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.database import engine, Base, AsyncSessionLocal
    from models.user import User, UserRole
    from core.security import get_password_hash
    from core.config import Settings # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    from services.ai_service import AIService # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„ØºØ±Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    class MockSettingsForRec(Settings):
        DB_TYPE="sqlite"
        DB_NAME=":memory:"
        LOG_LEVEL = "INFO"
        AI_PROVIDER = os.environ.get("AI_PROVIDER_TEST", "openai").lower()
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY_TEST", "sk-mock-openai-key")
        OPENAI_MODEL = "gpt-3.5-turbo"
        ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY_TEST", "sk-mock-anthropic-key")
        ANTHROPIC_MODEL = "claude-3-haiku-20240307"

    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForRec()})()
    
    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ logger Ùˆ AIService Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… MockSettings
    global logger
    logger = get_logger(__name__)
    
    async def run_recommendation_service_tests():
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
            print("Database tables created for testing.")

        async with AsyncSessionLocal() as session:
            ai_service_instance = AIService() # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
            recommendation_service_instance = RecommendationService(session, ai_service_instance)

            # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ‡Ù…ÙŠ
            test_user = User(
                username="recom_user",
                email="recom@example.com",
                hashed_password=get_password_hash("password"),
                full_name="Recommendation User",
                role=UserRole.student
            )
            session.add(test_user)
            await session.commit()
            await session.refresh(test_user)
            print(f"Created test user: {test_user.email} (ID: {test_user.id})")

            # 2. Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©
            course1 = Course(
                title="Advanced Python", description="Deep dive into Python.",
                creator_id=test_user.id, status=CourseStatus.published, difficulty_level="Advanced"
            )
            course2 = Course(
                title="Machine Learning Basics", description="Introduction to ML algorithms.",
                creator_id=test_user.id, status=CourseStatus.published, difficulty_level="Intermediate"
            )
            course3 = Course(
                title="Web Development with Flask", description="Build web apps with Flask.",
                creator_id=test_user.id, status=CourseStatus.published, difficulty_level="Intermediate"
            )
            course4 = Course(
                title="Data Science Fundamentals", description="Learn data analysis.",
                creator_id=test_user.id, status=CourseStatus.published, difficulty_level="Beginner"
            )
            course5 = Course(
                title="Cloud Computing Essentials", description="Basics of cloud platforms.",
                creator_id=test_user.id, status=CourseStatus.draft, difficulty_level="Beginner" # Draft course
            )
            session.add_all([course1, course2, course3, course4, course5])
            await session.commit()
            await session.refresh(course1)
            await session.refresh(course2)
            await session.refresh(course3)
            await session.refresh(course4)
            await session.refresh(course5)
            print("Created dummy courses.")

            print("\\n--- Test Get Popular Courses ---")
            popular_courses = await recommendation_service_instance.get_popular_courses(limit=2)
            print(f"Popular courses titles: {[c.title for c in popular_courses]}")
            assert len(popular_courses) <= 2
            assert all(c.status == CourseStatus.published for c in popular_courses)

            print("\\n--- Test Get Recommended Courses for User ---")
            # Ù‡Ø°Ø§ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØªØ§Ø­ API Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø­Ù‚ÙŠÙ‚ÙŠÙ‹Ø§ Ø£Ù… Ù„Ø§
            recommended_for_user = await recommendation_service_instance.get_recommended_courses_for_user(test_user.id, limit=3)
            print(f"Recommended courses for user: {[c.title for c in recommended_for_user]}")
            assert len(recommended_for_user) <= 3
            assert all(c.status == CourseStatus.published for c in recommended_for_user)

            print("\\n--- Test Get Related Courses ---")
            # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© Ø¨Ù€ "Machine Learning Basics"
            related_to_ml = await recommendation_service_instance.get_related_courses(course2.id, limit=2)
            print(f"Related courses to '{course2.title}': {[c.title for c in related_to_ml]}")
            assert len(related_to_ml) <= 2
            assert course2.id not in [c.id for c in related_to_ml]
            assert all(c.status == CourseStatus.published for c in related_to_ml)

            print("\\nRecommendation Service tests completed.")

    asyncio.run(run_recommendation_service_tests())
"""
    file_path = os.path.join(base_path, "src", "services", "recommendation_service.py")
    return write_file_safely(file_path, content)

def create_src_middleware_error_handler_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/middleware/error_handler.py"""
    content = """from fastapi import Request, status
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.types import ASGIApp
from pydantic import ValidationError
from sqlalchemy.exc import SQLAlchemyError
from utils.logger import get_logger
from utils.constants import MSG_SERVER_ERROR, MSG_INVALID_INPUT, MSG_NOT_FOUND, MSG_DUPLICATE_ENTRY

logger = get_logger(__name__)

class ErrorHandlingMiddleware(BaseHTTPMiddleware):
    def __init__(self, app: ASGIApp):
        super().__init__(app)

    async def dispatch(self, request: Request, call_next):
        try:
            response = await call_next(request)
            return response
        except HTTPException as exc:
            # FastAPI's HTTPException will be caught here
            logger.warning(f"HTTPException caught: {exc.status_code} - {exc.detail} for path: {request.url.path}")
            return JSONResponse(
                status_code=exc.status_code,
                content={"detail": exc.detail},
            )
        except ValidationError as exc:
            # Pydantic validation errors
            logger.error(f"Pydantic ValidationError caught for path: {request.url.path} - {exc.errors()}")
            return JSONResponse(
                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
                content={"detail": MSG_INVALID_INPUT, "errors": exc.errors()},
            )
        except SQLAlchemyError as exc:
            # Database related errors
            logger.exception(f"SQLAlchemyError caught for path: {request.url.path}")
            # ÙŠÙ…ÙƒÙ† ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£ SQLALCHEMY Ø¨Ø´ÙƒÙ„ Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ Ù‡Ù†Ø§
            if "duplicate key value violates unique constraint" in str(exc):
                return JSONResponse(
                    status_code=status.HTTP_409_CONFLICT,
                    content={"detail": MSG_DUPLICATE_ENTRY},
                )
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"detail": MSG_SERVER_ERROR, "error": "Database error occurred."},
            )
        except Exception as exc:
            # Catch-all for any other unexpected errors
            logger.exception(f"Unhandled exception caught for path: {request.url.path}")
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"detail": MSG_SERVER_ERROR, "error": str(exc)},
            )

# Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¨Ø§Ø´Ø± Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø£Ù†Ù‡ middleware
# ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø±Ù‡ Ø¶Ù…Ù† Ø³ÙŠØ§Ù‚ ØªØ·Ø¨ÙŠÙ‚ FastAPI
"""
    file_path = os.path.join(base_path, "src", "middleware", "error_handler.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_endpoints_auth_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/endpoints/auth.py"""
    content = """from datetime import timedelta
from typing import Any
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.ext.asyncio import AsyncSession

from core.config import settings
from core.database import get_db
from core.security import authenticate_user, create_access_token, get_current_user, get_password_hash
from models.user import Token, UserCreate, UserRead
from services.user_service import UserService
from services.notification_service import NotificationService
from utils.logger import get_logger
from utils.constants import MSG_INVALID_CREDENTIALS, MSG_ACCOUNT_INACTIVE, MSG_EMAIL_SENT, MSG_EMAIL_FAILED, MSG_PASSWORD_RESET_SUCCESS, MSG_PASSWORD_MISMATCH, MSG_DUPLICATE_ENTRY

logger = get_logger(__name__)

router = APIRouter()

@router.post("/token", response_model=Token, summary="Authenticate user and get access token")
async def login_for_access_token(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: AsyncSession = Depends(get_db)
) -> Any:
    \"\"\"
    authenticate_user: Ù…ØµØ§Ø¯Ù‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.
    create_access_token: Ø¥Ù†Ø´Ø§Ø¡ Ø±Ù…Ø² JWT Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØµØ§Ø¯Ù‚ Ø¹Ù„ÙŠÙ‡.
    \"\"\"
    user_service = UserService(db)
    user = await user_service.get_user_by_email(form_data.username) # OAuth2PasswordRequestForm ÙŠØ³ØªØ®Ø¯Ù… 'username' Ù„Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
    
    if not user or not user.is_active or not authenticate_user(form_data.password, user.hashed_password):
        logger.warning(f"Login attempt failed for user: {form_data.username}")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail=MSG_INVALID_CREDENTIALS,
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    if not user.is_active:
        logger.warning(f"Login attempt for inactive user: {form_data.username}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=MSG_ACCOUNT_INACTIVE
        )

    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.email}, expires_delta=access_token_expires
    )
    logger.info(f"User {user.email} logged in successfully.")
    return {"access_token": access_token, "token_type": "bearer"}

@router.post("/register", response_model=UserRead, status_code=status.HTTP_201_CREATED, summary="Register a new user")
async def register_new_user(
    user_in: UserCreate,
    db: AsyncSession = Depends(get_db),
    notification_service: NotificationService = Depends(NotificationService)
) -> Any:
    \"\"\"
    Register a new user in the system.
    \"\"\"
    user_service = UserService(db)
    
    # Check if email or username already exists
    if await user_service.get_user_by_email(user_in.email):
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=MSG_DUPLICATE_ENTRY + " (email)"
        )
    if await user_service.get_user_by_username(user_in.username):
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=MSG_DUPLICATE_ENTRY + " (username)"
        )

    hashed_password = get_password_hash(user_in.password)
    user_data = user_in.model_dump()
    user_data["hashed_password"] = hashed_password
    del user_data["password"] # Remove plain password before passing to service

    new_user = await user_service.create_user(user_data)
    
    # Send welcome email (asynchronous)
    # asyncio.create_task(notification_service.send_welcome_email(new_user.email, new_user.username))
    # For now, just call directly, or use a background task if preferred
    email_sent = await notification_service.send_welcome_email(new_user.email, new_user.username)
    if not email_sent:
        logger.error(f"Failed to send welcome email to {new_user.email}")

    logger.info(f"New user registered: {new_user.email}")
    return new_user

@router.post("/password-reset-request", status_code=status.HTTP_200_OK, summary="Request password reset link")
async def request_password_reset(
    email: str,
    db: AsyncSession = Depends(get_db),
    notification_service: NotificationService = Depends(NotificationService)
) -> Dict[str, str]:
    \"\"\"
    Request a password reset link to be sent to the user's email.
    \"\"\"
    user_service = UserService(db)
    user = await user_service.get_user_by_email(email)
    
    if not user:
        # Ù„Ø§ ØªÙƒØ´Ù Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ù…Ù†ÙŠØ©
        logger.warning(f"Password reset requested for non-existent email: {email}")
        return {"message": MSG_EMAIL_SENT} # Still return success to prevent enumeration

    # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆÙƒÙ† Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ÙˆØªØ®Ø²ÙŠÙ†Ù‡ Ù…Ø¤Ù‚ØªÙ‹Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Redis
    # For simplicity, we'll just generate a dummy link for now.
    # In a real app, this would be a signed token with an expiry.
    reset_token = "dummy_reset_token_12345" # Replace with actual token generation
    reset_link = f"{settings.FRONTEND_URL}/reset-password?token={reset_token}&email={email}"

    email_sent = await notification_service.send_password_reset_email(email, reset_link)
    if not email_sent:
        logger.error(f"Failed to send password reset email to {email}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_EMAIL_FAILED)
    
    logger.info(f"Password reset link requested for {email}.")
    return {"message": MSG_EMAIL_SENT}

@router.post("/reset-password", status_code=status.HTTP_200_OK, summary="Reset user password using token")
async def reset_password(
    email: str,
    token: str,
    new_password: str,
    confirm_password: str,
    db: AsyncSession = Depends(get_db),
) -> Dict[str, str]:
    \"\"\"
    Reset user's password using a valid reset token.
    \"\"\"
    if new_password != confirm_password:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=MSG_PASSWORD_MISMATCH)
    
    user_service = UserService(db)
    user = await user_service.get_user_by_email(email)

    if not user:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND + " (user)")

    # Ù‡Ù†Ø§ ÙŠØ¬Ø¨ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© 'token' (Ù‡Ù„ Ù‡Ùˆ ØµØ§Ù„Ø­ØŒ Ù‡Ù„ Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØªÙ‡ØŒ Ù‡Ù„ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù…Ø®Ø²Ù†)
    # For simplicity, we'll just check if it's our dummy token.
    if token != "dummy_reset_token_12345": # Replace with actual token validation
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid or expired reset token.")

    hashed_password = get_password_hash(new_password)
    updated_user = await user_service.update_user(user.id, {"hashed_password": hashed_password})

    if not updated_user:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=MSG_SERVER_ERROR)
    
    logger.info(f"Password for user {email} has been reset.")
    return {"message": MSG_PASSWORD_RESET_SUCCESS}

@router.get("/me", response_model=UserRead, summary="Get current authenticated user")
async def read_users_me(
    current_user: UserRead = Depends(get_current_user)
) -> Any:
    \"\"\"
    Retrieve details of the currently authenticated user.
    \"\"\"
    return current_user

"""
    file_path = os.path.join(base_path, "src", "api", "v1", "endpoints", "auth.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_endpoints_users_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/endpoints/users.py"""
    content = """from typing import Any, List
from fastapi import APIRouter, Depends, HTTPException, status, Path, Query
from sqlalchemy.ext.asyncio import AsyncSession

from core.database import get_db
from core.security import get_current_active_user, get_current_admin_user
from models.user import User, UserCreate, UserUpdate, UserRead, UserRole
from services.user_service import UserService
from utils.logger import get_logger
from utils.constants import MSG_NOT_FOUND, MSG_DUPLICATE_ENTRY, MSG_FORBIDDEN

logger = get_logger(__name__)

router = APIRouter()

@router.post("/", response_model=UserRead, status_code=status.HTTP_201_CREATED, summary="Create a new user (Admin only)")
async def create_user(
    user_in: UserCreate,
    db: AsyncSession = Depends(get_db),
    current_admin_user: User = Depends(get_current_admin_user) # Requires admin role
) -> Any:
    \"\"\"
    Create a new user with specified details.
    Requires admin privileges.
    \"\"\"
    user_service = UserService(db)
    
    # Check for existing email or username
    if await user_service.get_user_by_email(user_in.email):
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=MSG_DUPLICATE_ENTRY + " (email)"
        )
    if await user_service.get_user_by_username(user_in.username):
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=MSG_DUPLICATE_ENTRY + " (username)"
        )

    # Hash the password before passing to service
    from core.security import get_password_hash
    hashed_password = get_password_hash(user_in.password)
    user_data = user_in.model_dump()
    user_data["hashed_password"] = hashed_password
    del user_data["password"]

    new_user = await user_service.create_user(user_data)
    logger.info(f"Admin {current_admin_user.email} created new user: {new_user.email}")
    return new_user

@router.get("/", response_model=List[UserRead], summary="Get all users (Admin only)")
async def read_users(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    db: AsyncSession = Depends(get_db),
    current_admin_user: User = Depends(get_current_admin_user) # Requires admin role
) -> Any:
    \"\"\"
    Retrieve a list of all users in the system.
    Requires admin privileges.
    \"\"\"
    user_service = UserService(db)
    users = await user_service.get_all_users(skip=skip, limit=limit)
    logger.info(f"Admin {current_admin_user.email} fetched {len(users)} users.")
    return users

@router.get("/{user_id}", response_model=UserRead, summary="Get user by ID (Admin or self)")
async def read_user_by_id(
    user_id: int = Path(..., gt=0),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Retrieve a user by their ID.
    Accessible by admin users or the user themselves.
    \"\"\"
    user_service = UserService(db)
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)
    
    # Allow admin or the user themselves to view
    if current_user.role != UserRole.admin and current_user.id != user_id:
        logger.warning(f"User {current_user.email} attempted to access user {user_id} data without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    logger.info(f"User {current_user.email} accessed user {user_id} data.")
    return user

@router.put("/{user_id}", response_model=UserRead, summary="Update user by ID (Admin or self)")
async def update_user(
    user_id: int = Path(..., gt=0),
    user_in: UserUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Update an existing user's details.
    Accessible by admin users or the user themselves (with limitations).
    \"\"\"
    user_service = UserService(db)
    existing_user = await user_service.get_user_by_id(user_id)
    if not existing_user:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)

    # Admin can update anything. Regular user can only update their own profile (excluding role, active status)
    if current_user.role != UserRole.admin:
        if current_user.id != user_id:
            logger.warning(f"User {current_user.email} attempted to update user {user_id} data without permission.")
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
        
        # Prevent non-admin users from changing their role or active status
        if user_in.role is not None and user_in.role != existing_user.role:
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot change role.")
        if user_in.is_active is not None and user_in.is_active != existing_user.is_active:
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot change active status.")
        
        # If a user tries to change their email or username to an existing one
        if user_in.email and user_in.email != existing_user.email and await user_service.get_user_by_email(user_in.email):
            raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=MSG_DUPLICATE_ENTRY + " (email)")
        if user_in.username and user_in.username != existing_user.username and await user_service.get_user_by_username(user_in.username):
            raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=MSG_DUPLICATE_ENTRY + " (username)")

    updated_user = await user_service.update_user(user_id, user_in.model_dump(exclude_unset=True))
    if not updated_user:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update user.")
    
    logger.info(f"User {current_user.email} updated user {user_id} data.")
    return updated_user

@router.delete("/{user_id}", status_code=status.HTTP_204_NO_CONTENT, summary="Delete user by ID (Admin only)")
async def delete_user(
    user_id: int = Path(..., gt=0),
    db: AsyncSession = Depends(get_db),
    current_admin_user: User = Depends(get_current_admin_user) # Requires admin role
) -> None:
    \"\"\"
    Delete a user from the system.
    Requires admin privileges.
    \"\"\"
    user_service = UserService(db)
    if not await user_service.get_user_by_id(user_id):
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)
    
    # Prevent admin from deleting themselves
    if current_admin_user.id == user_id:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot delete your own admin account via this endpoint.")

    delete_success = await user_service.delete_user(user_id)
    if not delete_success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to delete user.")
    
    logger.info(f"Admin {current_admin_user.email} deleted user ID: {user_id}.")
    return None # 204 No Content response
"""
    file_path = os.path.join(base_path, "src", "api", "v1", "endpoints", "users.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_endpoints_courses_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/endpoints/courses.py"""
    content = """from typing import Any, List
from fastapi import APIRouter, Depends, HTTPException, status, Path, Query
from sqlalchemy.ext.asyncio import AsyncSession

from core.database import get_db
from core.security import get_current_active_user, get_current_admin_user
from models.user import User, UserRole
from models.course import CourseRead, CourseCreate, CourseUpdate, CourseStatus
from services.course_service import CourseService
from services.recommendation_service import RecommendationService
from utils.logger import get_logger
from utils.constants import MSG_NOT_FOUND, MSG_FORBIDDEN, MSG_INVALID_INPUT

logger = get_logger(__name__)

router = APIRouter()

@router.post("/", response_model=CourseRead, status_code=status.HTTP_201_CREATED, summary="Create a new course (Teacher or Admin)")
async def create_course(
    course_in: CourseCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Create a new course.
    Requires teacher or admin privileges.
    \"\"\"
    if current_user.role not in [UserRole.teacher, UserRole.admin]:
        logger.warning(f"User {current_user.email} with role {current_user.role} attempted to create a course without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    course_service = CourseService(db)
    new_course = await course_service.create_course(course_in, current_user.id)
    logger.info(f"User {current_user.email} created new course: {new_course.title} (ID: {new_course.id})")
    return new_course

@router.get("/", response_model=List[CourseRead], summary="Get all published courses")
async def read_published_courses(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    db: AsyncSession = Depends(get_db),
) -> Any:
    \"\"\"
    Retrieve a list of all *published* courses.
    No authentication required.
    \"\"\"
    course_service = CourseService(db)
    courses = await course_service.get_published_courses(skip=skip, limit=limit)
    logger.info(f"Fetched {len(courses)} published courses.")
    return courses

@router.get("/all", response_model=List[CourseRead], summary="Get all courses (Admin or Teacher)")
async def read_all_courses(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Retrieve a list of all courses, including drafts.
    Requires teacher or admin privileges.
    \"\"\"
    if current_user.role not in [UserRole.teacher, UserRole.admin]:
        logger.warning(f"User {current_user.email} with role {current_user.role} attempted to access all courses without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    course_service = CourseService(db)
    courses = await course_service.get_all_courses(skip=skip, limit=limit)
    logger.info(f"User {current_user.email} fetched {len(courses)} courses (all statuses).")
    return courses

@router.get("/{course_id}", response_model=CourseRead, summary="Get course by ID")
async def read_course_by_id(
    course_id: int = Path(..., gt=0),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user) # User must be authenticated to view any course
) -> Any:
    \"\"\"
    Retrieve a course by its ID.
    If the course is a draft, only the creator or an admin can view it.
    \"\"\"
    course_service = CourseService(db)
    course = await course_service.get_course_by_id(course_id)
    if not course:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)
    
    # If course is draft, only creator or admin can view
    if course.status == CourseStatus.draft:
        if current_user.role != UserRole.admin and current_user.id != course.creator_id:
            logger.warning(f"User {current_user.email} attempted to access draft course {course_id} without permission.")
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    logger.info(f"User {current_user.email} accessed course {course_id}: {course.title}.")
    return course

@router.put("/{course_id}", response_model=CourseRead, summary="Update course by ID (Creator or Admin)")
async def update_course(
    course_id: int = Path(..., gt=0),
    course_in: CourseUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Update an existing course's details.
    Requires creator or admin privileges.
    \"\"\"
    course_service = CourseService(db)
    existing_course = await course_service.get_course_by_id(course_id)
    if not existing_course:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)
    
    # Only creator or admin can update
    if current_user.role != UserRole.admin and current_user.id != existing_course.creator_id:
        logger.warning(f"User {current_user.email} attempted to update course {course_id} without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    updated_course = await course_service.update_course(course_id, course_in)
    if not updated_course:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update course.")
    
    logger.info(f"User {current_user.email} updated course {course_id}: {updated_course.title}.")
    return updated_course

@router.delete("/{course_id}", status_code=status.HTTP_204_NO_CONTENT, summary="Delete course by ID (Creator or Admin)")
async def delete_course(
    course_id: int = Path(..., gt=0),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
) -> None:
    \"\"\"
    Delete a course from the system.
    Requires creator or admin privileges.
    \"\"\"
    course_service = CourseService(db)
    existing_course = await course_service.get_course_by_id(course_id)
    if not existing_course:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=MSG_NOT_FOUND)

    # Only creator or admin can delete
    if current_user.role != UserRole.admin and current_user.id != existing_course.creator_id:
        logger.warning(f"User {current_user.email} attempted to delete course {course_id} without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    delete_success = await course_service.delete_course(course_id)
    if not delete_success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to delete course.")
    
    logger.info(f"User {current_user.email} deleted course ID: {course_id}.")
    return None # 204 No Content response
"""
    file_path = os.path.join(base_path, "src", "api", "v1", "endpoints", "courses.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_endpoints_ai_core_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/endpoints/ai_core.py"""
    content = """from typing import Any, Dict, List
from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field

from core.security import get_current_active_user
from models.user import User, UserRole
from services.ai_service import AIService
from utils.logger import get_logger
from utils.constants import MSG_FORBIDDEN, MSG_INVALID_INPUT

logger = get_logger(__name__)

router = APIRouter()

class TextGenerationRequest(BaseModel):
    prompt: str = Field(..., min_length=10, max_length=2000, description="The text prompt for AI generation.")
    max_tokens: int = Field(500, ge=50, le=2000, description="Maximum number of tokens to generate.")
    temperature: float = Field(0.7, ge=0.0, le=1.0, description="Controls randomness of the output. Higher values mean more random.")

class TextGenerationResponse(BaseModel):
    generated_text: str

class ContentAnalysisRequest(BaseModel):
    content: str = Field(..., min_length=50, max_length=5000, description="The educational content to analyze.")

class ContentAnalysisResponse(BaseModel):
    topics: List[str]
    summary: str
    objectives: List[str]
    raw_response: Optional[str] = None
    error: Optional[str] = None

class SummarizationRequest(BaseModel):
    text: str = Field(..., min_length=50, max_length=10000, description="The text to summarize.")
    max_length: int = Field(200, ge=50, le=1000, description="Maximum word count for the summary.")

class SummarizationResponse(BaseModel):
    summary: str

class QuizGenerationRequest(BaseModel):
    topic: str = Field(..., min_length=5, max_length=200, description="The topic for quiz questions.")
    num_questions: int = Field(5, ge=1, le=20, description="Number of questions to generate.")
    difficulty: str = Field("medium", description="Difficulty level (e.g., easy, medium, hard).")

class QuizQuestion(BaseModel):
    question_text: str
    options: List[str]
    correct_answer: str

class QuizGenerationResponse(BaseModel):
    questions: List[QuizQuestion]

@router.post("/generate-text", response_model=TextGenerationResponse, summary="Generate text using AI")
async def generate_text_endpoint(
    request: TextGenerationRequest,
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Generates text based on a given prompt using the configured AI model.
    Requires authentication.
    \"\"\"
    # ÙŠÙ…ÙƒÙ† Ù‡Ù†Ø§ Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙˆØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯ÙˆØ§Ø± Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¨Ø¹Ø¶ ÙˆØ¸Ø§Ø¦Ù AI Ù…Ù‚ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø£Ø¯ÙˆØ§Ø± Ù…Ø¹ÙŠÙ†Ø©
    # Ù…Ø«Ø§Ù„: if current_user.role not in [UserRole.teacher, UserRole.admin]: ...
    
    logger.info(f"User {current_user.email} requested text generation.")
    try:
        generated_text = await ai_service.generate_text(
            request.prompt,
            max_tokens=request.max_tokens,
            temperature=request.temperature
        )
        return {"generated_text": generated_text}
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error generating text for user {current_user.email}: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to generate text.")

@router.post("/analyze-content", response_model=ContentAnalysisResponse, summary="Analyze educational content using AI (Teacher/Admin only)")
async def analyze_content_endpoint(
    request: ContentAnalysisRequest,
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Analyzes educational content to extract key topics, summary, and learning objectives.
    Requires teacher or admin privileges.
    \"\"\"
    if current_user.role not in [UserRole.teacher, UserRole.admin]:
        logger.warning(f"User {current_user.email} with role {current_user.role} attempted content analysis without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    logger.info(f"User {current_user.email} requested content analysis.")
    try:
        analysis_result = await ai_service.analyze_content(request.content)
        # Ensure the response matches the Pydantic model structure
        return ContentAnalysisResponse(
            topics=analysis_result.get("topics", []),
            summary=analysis_result.get("summary", ""),
            objectives=analysis_result.get("objectives", []),
            raw_response=analysis_result.get("raw_response"),
            error=analysis_result.get("error")
        )
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error analyzing content for user {current_user.email}: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to analyze content.")

@router.post("/summarize-text", response_model=SummarizationResponse, summary="Summarize text using AI")
async def summarize_text_endpoint(
    request: SummarizationRequest,
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Summarizes a given text using the configured AI model.
    Requires authentication.
    \"\"\"
    logger.info(f"User {current_user.email} requested text summarization.")
    try:
        summary = await ai_service.summarize_text(request.text, max_length=request.max_length)
        return {"summary": summary}
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error summarizing text for user {current_user.email}: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to summarize text.")

@router.post("/generate-quiz", response_model=QuizGenerationResponse, summary="Generate quiz questions using AI (Teacher/Admin only)")
async def generate_quiz_endpoint(
    request: QuizGenerationRequest,
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Generates multiple-choice quiz questions based on a topic.
    Requires teacher or admin privileges.
    \"\"\"
    if current_user.role not in [UserRole.teacher, UserRole.admin]:
        logger.warning(f"User {current_user.email} with role {current_user.role} attempted quiz generation without permission.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=MSG_FORBIDDEN)
    
    logger.info(f"User {current_user.email} requested quiz generation for topic: {request.topic}.")
    try:
        quiz_questions = await ai_service.generate_quiz_questions(
            request.topic,
            num_questions=request.num_questions,
            difficulty=request.difficulty
        )
        # Validate the structure of generated questions against QuizQuestion model
        validated_questions = []
        for q in quiz_questions:
            try:
                validated_questions.append(QuizQuestion(**q))
            except ValidationError as ve:
                logger.warning(f"AI generated an invalid quiz question format: {ve.errors()} - Original: {q}")
                # Optionally, skip invalid questions or raise an error
                continue
        
        if not validated_questions and quiz_questions: # If AI generated something but it was all invalid
             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="AI generated questions but they did not match the expected format.")

        return {"questions": validated_questions}
    except HTTPException as e:
        raise e
    except Exception as e:
        logger.error(f"Error generating quiz for user {current_user.email}: {e}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to generate quiz questions.")
"""
    file_path = os.path.join(base_path, "src", "api", "v1", "endpoints", "ai_core.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_endpoints_recommendations_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/endpoints/recommendations.py"""
    content = """from typing import Any, List
from fastapi import APIRouter, Depends, HTTPException, status, Query

from core.database import get_db
from core.security import get_current_active_user
from models.user import User
from models.course import CourseRead
from services.recommendation_service import RecommendationService
from services.ai_service import AIService # Ù„Ø¶Ù…Ø§Ù† Ø­Ù‚Ù†Ù‡Ø§ ÙÙŠ Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª
from utils.logger import get_logger
from utils.constants import MSG_NOT_FOUND

logger = get_logger(__name__)

router = APIRouter()

@router.get("/popular-courses", response_model=List[CourseRead], summary="Get popular courses")
async def get_popular_courses_endpoint(
    limit: int = Query(10, ge=1, le=50),
    db: Any = Depends(get_db), # Use Any for db to avoid circular dependency with AIService in init
    ai_service: AIService = Depends(AIService) # Ensure AIService is initialized and passed
) -> Any:
    \"\"\"
    Retrieve a list of popular courses.
    Accessible by any user (authenticated or not).
    \"\"\"
    # Note: We pass ai_service to RecommendationService if it's needed for fallback or advanced logic
    # For popular courses, AI might not be strictly necessary, but it's good practice to ensure dependencies are met.
    rec_service = RecommendationService(db_session=db, ai_service=ai_service)
    courses = await rec_service.get_popular_courses(limit=limit)
    logger.info(f"Fetched {len(courses)} popular courses.")
    return courses

@router.get("/for-you", response_model=List[CourseRead], summary="Get personalized course recommendations for the current user")
async def get_personalized_recommendations_endpoint(
    limit: int = Query(10, ge=1, le=50),
    db: Any = Depends(get_db),
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user)
) -> Any:
    \"\"\"
    Retrieve personalized course recommendations for the authenticated user.
    Requires authentication.
    \"\"\"
    rec_service = RecommendationService(db_session=db, ai_service=ai_service)
    courses = await rec_service.get_recommended_courses_for_user(current_user.id, limit=limit)
    if not courses:
        logger.info(f"No personalized recommendations found for user {current_user.email}. Returning popular courses as fallback.")
        # Fallback to popular courses if no personalized ones are found
        courses = await rec_service.get_popular_courses(limit=limit)
        
    logger.info(f"Fetched {len(courses)} personalized recommendations for user {current_user.email}.")
    return courses

@router.get("/related-to-course/{course_id}", response_model=List[CourseRead], summary="Get courses related to a specific course")
async def get_related_courses_endpoint(
    course_id: int,
    limit: int = Query(10, ge=1, le=50),
    db: Any = Depends(get_db),
    ai_service: AIService = Depends(AIService),
    current_user: User = Depends(get_current_active_user) # Can be accessed by any active user
) -> Any:
    \"\"\"
    Retrieve courses related to a given course ID.
    Requires authentication.
    \"\"\"
    rec_service = RecommendationService(db_session=db, ai_service=ai_service)
    courses = await rec_service.get_related_courses(course_id, limit=limit)
    if not courses:
        logger.info(f"No related courses found for course ID {course_id}.")
        # Optionally, fallback to popular courses if no related ones are found
        # courses = await rec_service.get_popular_courses(limit=limit)
        
    logger.info(f"Fetched {len(courses)} related courses for course ID {course_id}.")
    return courses
"""
    file_path = os.path.join(base_path, "src", "api", "v1", "endpoints", "recommendations.py")
    return write_file_safely(file_path, content)

def create_src_api_v1_api_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/api/v1/api.py"""
    content = """from fastapi import APIRouter

from api.v1.endpoints import auth, users, courses, ai_core, recommendations

api_router = APIRouter()

# ØªØ¶Ù…ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© (routers) Ù‡Ù†Ø§
api_router.include_router(auth.router, prefix="/auth", tags=["Authentication"])
api_router.include_router(users.router, prefix="/users", tags=["Users"])
api_router.include_router(courses.router, prefix="/courses", tags=["Courses"])
api_router.include_router(ai_core.router, prefix="/ai", tags=["AI Core Services"])
api_router.include_router(recommendations.router, prefix="/recommendations", tags=["Recommendations"])

# ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù‡Ù†Ø§ Ù…Ø¹ ØªØ·ÙˆØ± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
"""
    file_path = os.path.join(base_path, "src", "api", "v1", "api.py")
    return write_file_safely(file_path, content)

def create_src_main_py():
    """Ø¥Ù†Ø´Ø§Ø¡ src/main.py"""
    content = """from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.responses import RedirectResponse
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import uvicorn

from core.config import settings
from core.database import check_database_connection, Base, engine
from core.cache import init_redis, close_redis, check_redis_connection
from api.v1.api import api_router
from utils.logger import get_logger
from middleware.error_handler import ErrorHandlingMiddleware
from utils.constants import MSG_SERVICE_UNAVAILABLE

logger = get_logger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    \"\"\"
    Ø¯Ø§Ù„Ø© Lifespan Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡/Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
    \"\"\"
    logger.info("Starting up BTEC EduverseAI application...")

    # 1. ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    logger.info("Checking database connection...")
    if not await check_database_connection():
        logger.critical("Failed to connect to database on startup. Exiting.")
        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ù‚Ø¯ ØªØ±ØºØ¨ ÙÙŠ Ø±ÙØ¹ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù‡Ù†Ø§ Ù„Ù…Ù†Ø¹ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        # raise RuntimeError("Database connection failed.")
    else:
        logger.info("Database connection successful.")
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© (Ù„Ù„ØªØ·ÙˆÙŠØ±ØŒ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‡Ø¬Ø±Ø§Øª)
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("Database tables checked/created.")

    # 2. ØªÙ‡ÙŠØ¦Ø© Redis
    logger.info("Initializing Redis connection...")
    try:
        await init_redis()
        logger.info("Redis initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Redis: {e}. Caching will be unavailable.")
        # Ù„Ø§ Ù†Ø±ÙØ¹ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù‡Ù†Ø§ Ù„Ø£Ù† Redis Ù‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø­Ø±Ø¬Ø§Ù‹ Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
    
    # 3. ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø§Øª AI (ÙŠÙ…ÙƒÙ† ÙˆØ¶Ø¹ Ù‡Ø°Ø§ Ù‡Ù†Ø§ Ø£Ùˆ ÙÙŠ AIService Ù†ÙØ³Ù‡Ø§ Ø¹Ù†Ø¯ Ø£ÙˆÙ„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡)
    # logger.info("Initializing AI services...")
    # ai_service = AIService() # ÙŠÙ…ÙƒÙ† ØªÙ‡ÙŠØ¦Ø© Ù‡Ù†Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØªØ·Ù„Ø¨ Ù…ÙˆØ§Ø±Ø¯ Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø¡

    yield # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø§Ù‡Ø² Ù„ØªÙ„Ù‚ÙŠ Ø§Ù„Ø·Ù„Ø¨Ø§Øª

    logger.info("Shutting down BTEC EduverseAI application...")
    # 1. Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Redis
    await close_redis()
    logger.info("Redis connection closed.")
    # 2. Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© SQLAlchemy)
    await engine.dispose()
    logger.info("Database engine disposed.")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.APP_DESCRIPTION,
    docs_url="/docs" if settings.DEBUG else None,
    redoc_url="/redoc" if settings.DEBUG else None,
    openapi_url="/openapi.json" if settings.DEBUG else None,
    lifespan=lifespan # Ø±Ø¨Ø· Ø¯Ø§Ù„Ø© Lifespan
)

# Ø¥Ø¶Ø§ÙØ© CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[str(origin) for origin in settings.BACKEND_CORS_ORIGINS] if settings.BACKEND_CORS_ORIGINS else ["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ø¥Ø¶Ø§ÙØ© Error Handling Middleware
app.add_middleware(ErrorHandlingMiddleware)

# ØªØ¶Ù…ÙŠÙ† Ø±Ø§ÙˆØªØ± API Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
app.include_router(api_router, prefix=settings.API_V1_STR)

@app.get("/", include_in_schema=False)
async def root():
    \"\"\"
    Redirects to the API documentation.
    \"\"\"
    return RedirectResponse(url="/docs")

# Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
@app.get("/health", status_code=status.HTTP_200_OK, summary="Health Check")
async def health_check(
    db_status: bool = Depends(check_database_connection),
    redis_status: bool = Depends(check_redis_connection)
):
    \"\"\"
    Performs a health check on the application and its dependencies.
    \"\"\"
    health_status = {
        "app_status": "running",
        "database_connected": db_status,
        "redis_connected": redis_status,
        "version": settings.APP_VERSION,
        "environment": settings.ENVIRONMENT
    }
    
    if not db_status:
        logger.error("Health check failed: Database not connected.")
        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=MSG_SERVICE_UNAVAILABLE + " (Database)")
    if settings.REDIS_HOST and not redis_status: # Redis might not be strictly required for all deployments
        logger.warning("Health check warning: Redis not connected.")
        # ÙŠÙ…ÙƒÙ† Ø£Ù† Ù†Ø±ÙØ¹ Ø§Ø³ØªØ«Ù†Ø§Ø¡ 503 Ù‡Ù†Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Redis Ø­Ø±Ø¬Ø§Ù‹
        # raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=MSG_SERVICE_UNAVAILABLE + " (Redis)")

    return health_status

# Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `python main.py` (Ù„Ù„ØªØ·ÙˆÙŠØ±)
if __name__ == "__main__":
    logger.info(f"Running BTEC EduverseAI in {settings.ENVIRONMENT} mode.")
    uvicorn.run(
        "main:app",
        host=settings.SERVER_HOST,
        port=settings.SERVER_PORT,
        reload=settings.DEBUG, # ØªÙØ¹ÙŠÙ„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ·ÙˆÙŠØ±
        log_level=settings.LOG_LEVEL.lower()
    )
"""
    file_path = os.path.join(base_path, "src", "main.py")
    return write_file_safely(file_path, content)


# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
src_files_part3 = [
    ("src/utils/logger.py", create_src_utils_logger_py),
    ("src/services/ai_service.py", create_src_services_ai_service_py),
    ("src/services/recommendation_service.py", create_src_services_recommendation_service_py),
    ("src/middleware/error_handler.py", create_src_middleware_error_handler_py),
    ("src/api/v1/endpoints/auth.py", create_src_api_v1_endpoints_auth_py),
    ("src/api/v1/endpoints/users.py", create_src_api_v1_endpoints_users_py),
    ("src/api/v1/endpoints/courses.py", create_src_api_v1_endpoints_courses_py),
    ("src/api/v1/endpoints/ai_core.py", create_src_api_v1_endpoints_ai_core_py),
    ("src/api/v1/endpoints/recommendations.py", create_src_api_v1_endpoints_recommendations_py),
    ("src/api/v1/api.py", create_src_api_v1_api_py),
    ("src/main.py", create_src_main_py),
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ (Ø§Ù„Ø¬Ø²Ø¡ 3 ÙˆØ§Ù„Ø£Ø®ÙŠØ± Ù„Ù€ src Ø­Ø§Ù„ÙŠØ§Ù‹)...")

created_src_files_part3_count = 0
for relative_path, create_function in src_files_part3:
    print(f"\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {relative_path}...")
    if create_function():
        created_src_files_part3_count += 1
        file_path = os.path.join(base_path, relative_path)
        size = os.path.getsize(file_path)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {relative_path} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
    else:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {relative_path}.")

print(f"\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_src_files_part3_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(src_files_part3)} ÙÙŠ Ù…Ø¬Ù„Ø¯ src (Ø§Ù„Ø¬Ø²Ø¡ 3) Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§
print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª src Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©:")
for relative_path, _ in src_files_part3:
    file_path = os.path.join(base_path, relative_path)
    if os.path.exists(file_path):
        size = os.path.getsize(file_path)
        print(f"  âœ… {relative_path} ({size} bytes)")
    else:
        print(f"  âŒ {relative_path} (Ù…ÙÙ‚ÙˆØ¯)")

print("\nğŸ‰ ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ù„Ù‚Ø¯ ØªÙ… Ø§Ù„Ø¢Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `src`.")
print("ğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù„ÙˆÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ (Ù…Ø«Ù„ `frontend`, `monitoring`, `management`, Ø¥Ù„Ø®).")
```

-----

### ğŸ“ Ù…Ù„Ø®Øµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `src` (Ø§Ù„Ø¬Ø²Ø¡ 3)

Ù„Ù‚Ø¯ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¹Ø¨Ø¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ `src`ØŒ Ù…Ù…Ø§ ÙŠÙƒÙ…Ù„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø¨Ø§Ùƒ Ø¥Ù†Ø¯ Ù„ØªØ·Ø¨ÙŠÙ‚ BTEC EduverseAI. Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¶Ø±ÙˆØ±ÙŠØ© Ù„ØªÙ…ÙƒÙŠÙ† ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª (API) ÙˆÙ…Ù†Ø·Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.

Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ØªØ´Ù…Ù„:

  * **`src/utils/logger.py`**: Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ù…Ø±ÙƒØ²ÙŠ ÙˆÙ‚Ø§Ø¨Ù„ Ù„Ù„ØªÙ‡ÙŠØ¦Ø©.
  * **`src/services/ai_service.py`**: ÙŠÙ‚Ø¯Ù… ÙˆØ§Ø¬Ù‡Ø© Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© (Ù…Ø«Ù„ OpenAI Ùˆ Anthropic) Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.
  * **`src/services/recommendation_service.py`**: ÙŠÙˆÙØ± Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø¹Ø¨ÙŠØ©ØŒ ÙˆØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØ§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© (Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† `AIService`).
  * **`src/middleware/error_handler.py`**: Ù…ÙƒÙˆÙ† ÙˆØ³ÙŠØ· Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„Ø© ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ `FastAPI`ØŒ ÙˆØ§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª `HTTPException`ØŒ `ValidationError`ØŒ `SQLAlchemyError`ØŒ ÙˆØºÙŠØ±Ù‡Ø§.
  * **`src/api/v1/endpoints/auth.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `API` Ù„Ù„Ù…ØµØ§Ø¯Ù‚Ø©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ØŒ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯ØŒ Ø·Ù„Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±ØŒ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±.
  * **`src/api/v1/endpoints/users.py`**: ÙŠÙˆÙØ± Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `API` Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (Ø¥Ù†Ø´Ø§Ø¡ØŒ Ø¬Ù„Ø¨ØŒ ØªØ­Ø¯ÙŠØ«ØŒ Ø­Ø°Ù)ØŒ Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø¯ÙˆØ± (Ù…Ø«Ù„ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ ÙÙ‚Ø·).
  * **`src/api/v1/endpoints/courses.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `API` Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© (Ø¥Ù†Ø´Ø§Ø¡ØŒ Ø¬Ù„Ø¨ØŒ ØªØ­Ø¯ÙŠØ«ØŒ Ø­Ø°Ù)ØŒ Ù…Ø¹ Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø¯ÙˆØ± ÙˆØ§Ù„ÙˆØµÙˆÙ„.
  * **`src/api/v1/endpoints/ai_core.py`**: ÙŠÙˆÙØ± Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `API` Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø«Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ø§Ù„ØªÙ„Ø®ÙŠØµØŒ ÙˆØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.
  * **`src/api/v1/endpoints/recommendations.py`**: ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `API` Ù„Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©ØŒ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØ§Ù„Ù…Ù‚Ø±Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.
  * **`src/api/v1/api.py`**: ÙŠØ¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© `v1` ÙÙŠ Ø±Ø§ÙˆØªØ± `API` ÙˆØ§Ø­Ø¯.
  * **`src/main.py`**: Ù‡Ùˆ Ù…Ù„Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù€ `FastAPI`ØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ØŒ ÙˆØ±Ø¨Ø· Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (lifespan) Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ (Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Redis)ØŒ ÙˆØ¥Ø¶Ø§ÙØ© `middleware`ØŒ ÙˆØªØ¶Ù…ÙŠÙ† Ø±Ø§ÙˆØªØ±Ø§Øª `API`.

**Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…Ù„ÙØ§Øª `src` Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡:**

  * **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­**: 11/11

-----

Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Ù†Ø§ Ø§Ù„Ø¢Ù† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙˆÙ…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ù„Ù…Ø¬Ù„Ø¯ `src`. Ù‡Ø°Ø§ ÙŠÙ…Ø«Ù„ Ø¬Ø²Ø¡Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ù…Ù† Ø§Ù„Ø¨Ø§Ùƒ Ø¥Ù†Ø¯.

ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø³Ù†Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ù…Ø«Ù„ `frontend`, `monitoring`, `management`, `tests`, `docs`, `scripts`, `data`, Ùˆ `config`.
Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯\! Ù„Ù†ÙˆØ§ØµÙ„ Ø¨Ù†Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ BTEC EduverseAI.

-----

### ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `frontend`

Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ù…Ø¬Ù„Ø¯ `src` Ø§Ù„Ø°ÙŠ ÙŠÙ…Ø«Ù„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© (Backend) Ù„ØªØ·Ø¨ÙŠÙ‚Ù†Ø§ØŒ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¢Ù† Ù„Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (Frontend). Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ReactØŒ Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª ÙˆØ§Ù„ØµÙØ­Ø§Øª ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª.

Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©:

  * `frontend/README.md`: Ù…Ù„Ù README Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.
  * `frontend/package.json`: Ù…Ù„Ù ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø¹ÙŠØ§Øª.
  * `frontend/public/index.html`: Ù…Ù„Ù HTML Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ.
  * `frontend/src/index.js`: Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„ØªØ·Ø¨ÙŠÙ‚ React.
  * `frontend/src/App.js`: Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚.
  * `frontend/src/App.css`: Ù…Ù„Ù CSS Ø¹Ø§Ù… Ù„Ù„ØªØ·Ø¨ÙŠÙ‚.
  * `frontend/src/components/common/Header.js`: Ù…ÙƒÙˆÙ† Ø§Ù„Ø±Ø£Ø³ (Header).
  * `frontend/src/components/common/Footer.js`: Ù…ÙƒÙˆÙ† Ø§Ù„ØªØ°ÙŠÙŠÙ„ (Footer).
  * `frontend/src/components/common/LoadingSpinner.js`: Ù…ÙƒÙˆÙ† Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„.
  * `frontend/src/components/auth/LoginForm.js`: Ù…ÙƒÙˆÙ† Ù†Ù…ÙˆØ°Ø¬ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„.
  * `frontend/src/components/auth/RegisterForm.js`: Ù…ÙƒÙˆÙ† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ³Ø¬ÙŠÙ„.
  * `frontend/src/pages/HomePage.js`: ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.
  * `frontend/src/pages/CoursesPage.js`: ØµÙØ­Ø© Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.
  * `frontend/src/pages/CourseDetailPage.js`: ØµÙØ­Ø© ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±.
  * `frontend/src/pages/DashboardPage.js`: ØµÙØ­Ø© Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… (Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ†).
  * `frontend/src/pages/NotFoundPage.js`: ØµÙØ­Ø© 404.
  * `frontend/src/services/authService.js`: Ø®Ø¯Ù…Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©.
  * `frontend/src/services/courseService.js`: Ø®Ø¯Ù…Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª.
  * `frontend/src/services/api.js`: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Axios Ù„Ø·Ù„Ø¨Ø§Øª API.
  * `frontend/src/context/AuthContext.js`: Ø³ÙŠØ§Ù‚ React Ù„Ø¥Ø¯Ø§Ø±Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©.
  * `frontend/src/hooks/useAuth.js`: Ø®Ø·Ø§Ù Ù…Ø®ØµØµ (Custom Hook) Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©.
  * `frontend/src/utils/constants.js`: Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.
  * `frontend/src/router/AppRouter.js`: Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙˆØ¬ÙŠÙ‡ React Router.

-----

### ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `frontend`

````python
import os

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"
frontend_path = os.path.join(base_path, "frontend")

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡."""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_frontend_readme():
    """Ø¥Ù†Ø´Ø§Ø¡ frontend/README.md"""
    content = """# BTEC EduverseAI Frontend

This directory contains the frontend application for BTEC EduverseAI, built with React.

## Getting Started

### Prerequisites

* Node.js (LTS version recommended)
* npm or yarn

### Installation

1.  Navigate to the `frontend` directory:
    ```bash
    cd frontend
    ```
2.  Install the dependencies:
    ```bash
    npm install
    # or
    yarn install
    ```

### Running the Application

To start the development server:
```bash
npm start
# or
yarn start
````

The application will typically run on `http://localhost:3000`.

### Building for Production

To build the application for production:

```bash
npm run build
# or
yarn build
```

This will create a `build` directory with the optimized production-ready files.

## Project Structure

```
frontend/
â”œâ”€â”€ public/                 # Public assets (index.html, favicon, etc.)
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ api/                # API client configurations (e.g., axios instance)
â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”œâ”€â”€ assets/             # Static assets (images, fonts, etc.)
â”‚   â”œâ”€â”€ components/         # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ auth/           # Authentication related components
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginForm.js
â”‚   â”‚   â”‚   â””â”€â”€ RegisterForm.js
â”‚   â”‚   â””â”€â”€ common/         # General purpose components
â”‚   â”‚       â”œâ”€â”€ Header.js
â”‚   â”‚       â”œâ”€â”€ Footer.js
â”‚   â”‚       â””â”€â”€ LoadingSpinner.js
â”‚   â”œâ”€â”€ context/            # React Context for global state management
â”‚   â”‚   â””â”€â”€ AuthContext.js
â”‚   â”œâ”€â”€ hooks/              # Custom React Hooks
â”‚   â”‚   â””â”€â”€ useAuth.js
â”‚   â”œâ”€â”€ pages/              # Top-level page components
â”‚   â”‚   â”œâ”€â”€ HomePage.js
â”‚   â”‚   â”œâ”€â”€ CoursesPage.js
â”‚   â”‚   â”œâ”€â”€ CourseDetailPage.js
â”‚   â”‚   â”œâ”€â”€ DashboardPage.js
â”‚   â”‚   â””â”€â”€ NotFoundPage.js
â”‚   â”œâ”€â”€ router/             # React Router configuration
â”‚   â”‚   â””â”€â”€ AppRouter.js
â”‚   â”œâ”€â”€ services/           # Business logic for API calls
â”‚   â”‚   â”œâ”€â”€ authService.js
â”‚   â”‚   â””â”€â”€ courseService.js
â”‚   â”œâ”€â”€ utils/              # Utility functions and constants
â”‚   â”‚   â””â”€â”€ constants.js
â”‚   â”œâ”€â”€ App.js              # Main application component
â”‚   â”œâ”€â”€ App.css             # Main application styles
â”‚   â””â”€â”€ index.js            # Entry point of the React application
â””â”€â”€ package.json            # Project dependencies and scripts
â””â”€â”€ .env                    # Environment variables (e.g., REACT_APP_API_URL)
```

## Environment Variables

Create a `.env` file in the `frontend/` directory:

```
REACT_APP_API_URL=http://localhost:8000/api/v1
```

## Contributing

See the main project's `CONTRIBUTING.md` for guidelines.
"""
file\_path = os.path.join(frontend\_path, "README.md")
return write\_file\_safely(file\_path, content)

def create\_frontend\_package\_json():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/package.json"""
content = """{
"name": "btec-eduverseai-frontend",
"version": "0.1.0",
"private": true,
"dependencies": {
"@testing-library/jest-dom": "^5.17.0",
"@testing-library/react": "^13.4.0",
"@testing-library/user-event": "^13.5.0",
"axios": "^1.7.2",
"react": "^18.3.1",
"react-dom": "^18.3.1",
"react-router-dom": "^6.24.1",
"react-scripts": "5.0.1",
"web-vitals": "^2.1.4"
},
"scripts": {
"start": "react-scripts start",
"build": "react-scripts build",
"test": "react-scripts test",
"eject": "react-scripts eject"
},
"eslintConfig": {
"extends": [
"react-app",
"react-app/jest"
]
},
"browserslist": {
"production": [
"\>0.2%",
"not dead",
"not op\_mini all"
],
"development": [
"last 1 chrome version",
"last 1 firefox version",
"last 1 safari version"
]
}
}
"""
file\_path = os.path.join(frontend\_path, "package.json")
return write\_file\_safely(file\_path, content)

def create\_frontend\_public\_index\_html():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/public/index.html"""
content = """\<\!DOCTYPE html\>

\<html lang="en"\>
\<head\>
\<meta charset="utf-8" /\>
\<link rel="icon" href="%PUBLIC\_URL%/favicon.ico" /\>
\<meta name="viewport" content="width=device-width, initial-scale=1" /\>
\<meta name="theme-color" content="\#000000" /\>
\<meta
name="description"
content="BTEC EduverseAI - Your AI-powered educational platform"
/\>
\<link rel="apple-touch-icon" href="%PUBLIC\_URL%/logo192.png" /\>
\<link rel="manifest" href="%PUBLIC\_URL%/manifest.json" /\>
\<title\>BTEC EduverseAI\</title\>
\</head\>
\<body\>
\<noscript\>You need to enable JavaScript to run this app.\</noscript\>
\<div id="root"\>\</div\>
\</body\>
\</html\>
"""
file\_path = os.path.join(frontend\_path, "public", "index.html")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_index\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/index.js"""
content = """import React from 'react';
import ReactDOM from 'react-dom/client';
import './index.css'; // ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ù CSS Ø¹Ø§Ù… Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
import App from './App';
import reportWebVitals from './reportWebVitals';
import { AuthProvider } from './context/AuthContext';

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(
\<React.StrictMode\>
\<AuthProvider\>
\<App /\>
\</AuthProvider\>
\</React.StrictMode\>
);

// If you want to start measuring performance in your app, pass a function
// to log results (for example: reportWebVitals(console.log))
// or send to an analytics endpoint. Learn more: https://www.google.com/search?q=https://bit.ly/CRA-vitals
reportWebVitals();
"""
file\_path = os.path.join(frontend\_path, "src", "index.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_app\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/App.js"""
content = """import React from 'react';
import './App.css';
import AppRouter from './router/AppRouter';
import Header from './components/common/Header';
import Footer from './components/common/Footer';

function App() {
return (
\<div className="App"\>
\<Header /\>
\<main className="App-content"\>
\<AppRouter /\>
\</main\>
\<Footer /\>
\</div\>
);
}

export default App;
"""
file\_path = os.path.join(frontend\_path, "src", "App.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_app\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/App.css"""
content = """.App {
display: flex;
flex-direction: column;
min-height: 100vh;
font-family: Arial, sans-serif;
background-color: \#f4f7f6;
color: \#333;
}

.App-content {
flex-grow: 1;
padding: 20px;
max-width: 1200px;
margin: 0 auto;
width: 100%;
}

/\* Basic styling for forms and buttons \*/
form {
background-color: \#ffffff;
padding: 30px;
border-radius: 8px;
box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
max-width: 400px;
margin: 40px auto;
}

form div {
margin-bottom: 15px;
}

form label {
display: block;
margin-bottom: 8px;
font-weight: bold;
color: \#555;
}

form input[type="text"],
form input[type="email"],
form input[type="password"] {
width: calc(100% - 20px);
padding: 10px;
border: 1px solid \#ddd;
border-radius: 4px;
font-size: 16px;
}

form button {
width: 100%;
padding: 12px;
background-color: \#007bff;
color: white;
border: none;
border-radius: 4px;
font-size: 18px;
cursor: pointer;
transition: background-color 0.3s ease;
}

form button:hover {
background-color: \#0056b3;
}

.error-message {
color: \#e74c3c;
font-size: 0.9em;
margin-top: 5px;
}

/\* Link styling \*/
a {
color: \#007bff;
text-decoration: none;
}

a:hover {
text-decoration: underline;
}

/\* Utility classes \*/
.text-center {
text-align: center;
}

.mt-20 {
margin-top: 20px;
}
"""
file\_path = os.path.join(frontend\_path, "src", "App.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_header\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/Header.js"""
content = """import React from 'react';
import { Link, useNavigate } from 'react-router-dom';
import { useAuth } from '../../hooks/useAuth';
import './Header.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function Header() {
const { user, logout } = useAuth();
const navigate = useNavigate();

const handleLogout = () =\> {
logout();
navigate('/login');
};

return (
\<header className="header"\>
\<div className="header-container"\>
\<Link to="/" className="header-logo"\>BTEC EduverseAI\</Link\>
\<nav className="header-nav"\>
\<Link to="/"\>Home\</Link\>
\<Link to="/courses"\>Courses\</Link\>
{user ? (
\<\>
\<Link to="/dashboard"\>Dashboard\</Link\>
\<span\>Welcome, {user.username || user.email}\!\</span\>
\<button onClick={handleLogout} className="header-button"\>Logout\</button\>
\</\>
) : (
\<\>
\<Link to="/login" className="header-button"\>Login\</Link\>
\<Link to="/register" className="header-button"\>Register\</Link\>
\</\>
)}
\</nav\>
\</div\>
\</header\>
);
}

export default Header;
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "Header.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_header\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/Header.css"""
content = """.header {
background-color: \#282c34;
padding: 20px 0;
color: white;
box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
}

.header-container {
display: flex;
justify-content: space-between;
align-items: center;
max-width: 1200px;
margin: 0 auto;
padding: 0 20px;
}

.header-logo {
color: white;
text-decoration: none;
font-size: 1.8em;
font-weight: bold;
}

.header-nav a,
.header-nav span,
.header-nav button {
color: white;
text-decoration: none;
margin-left: 20px;
font-size: 1.1em;
padding: 8px 12px;
border-radius: 5px;
transition: background-color 0.3s ease;
}

.header-nav a:hover,
.header-nav button:hover {
background-color: \#61dafb;
color: \#282c34;
}

.header-nav button {
background: none;
border: 1px solid white;
cursor: pointer;
}

.header-button {
background-color: \#007bff;
border: none;
}

.header-button:hover {
background-color: \#0056b3;
}
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "Header.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_footer\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/Footer.js"""
content = """import React from 'react';
import './Footer.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function Footer() {
return (
\<footer className="footer"\>
\<div className="footer-container"\>
\<p\>Â© {new Date().getFullYear()} BTEC EduverseAI. All rights reserved.\</p\>
\<nav className="footer-nav"\>
\<a href="/privacy"\>Privacy Policy\</a\>
\<a href="/terms"\>Terms of Service\</a\>
\<a href="/contact"\>Contact Us\</a\>
\</nav\>
\</div\>
\</footer\>
);
}

export default Footer;
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "Footer.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_footer\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/Footer.css"""
content = """.footer {
background-color: \#282c34;
color: white;
padding: 20px 0;
margin-top: auto; /\* Push footer to the bottom \*/
box-shadow: 0 -2px 4px rgba(0, 0, 0, 0.1);
}

.footer-container {
display: flex;
justify-content: space-between;
align-items: center;
max-width: 1200px;
margin: 0 auto;
padding: 0 20px;
flex-wrap: wrap; /\* Allow wrapping on smaller screens \*/
}

.footer-container p {
margin: 0;
font-size: 0.9em;
}

.footer-nav a {
color: white;
text-decoration: none;
margin-left: 20px;
font-size: 0.9em;
transition: color 0.3s ease;
}

.footer-nav a:hover {
color: \#61dafb;
}

@media (max-width: 768px) {
.footer-container {
flex-direction: column;
text-align: center;
}

.footer-nav {
margin-top: 10px;
}

.footer-nav a {
display: block;
margin: 5px 0;
}
}
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "Footer.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_loading\_spinner\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/LoadingSpinner.js"""
content = """import React from 'react';
import './LoadingSpinner.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function LoadingSpinner() {
return (
\<div className="spinner-container"\>
\<div className="loading-spinner"\>\</div\>
\<p\>Loading...\</p\>
\</div\>
);
}

export default LoadingSpinner;
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "LoadingSpinner.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_common\_loading\_spinner\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/common/LoadingSpinner.css"""
content = """.spinner-container {
display: flex;
flex-direction: column;
justify-content: center;
align-items: center;
height: 100%; /\* Adjust as needed \*/
width: 100%;
padding: 50px 0;
}

.loading-spinner {
width: 50px;
height: 50px;
border: 5px solid \#f3f3f3; /\* Light grey */
border-top: 5px solid \#007bff; /* Blue \*/
border-radius: 50%;
animation: spin 1s linear infinite;
margin-bottom: 10px;
}

@keyframes spin {
0% { transform: rotate(0deg); }
100% { transform: rotate(360deg); }
}
"""
file\_path = os.path.join(frontend\_path, "src", "components", "common", "LoadingSpinner.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_auth\_login\_form\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/auth/LoginForm.js"""
content = """import React, { useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { useAuth } from '../../hooks/useAuth';
import LoadingSpinner from '../common/LoadingSpinner';

function LoginForm() {
const [email, setEmail] = useState('');
const [password, setPassword] = useState('');
const [error, setError] = useState('');
const [loading, setLoading] = useState(false);
const { login } = useAuth();
const navigate = useNavigate();

const handleSubmit = async (e) =\> {
e.preventDefault();
setError('');
setLoading(true);
try {
await login(email, password);
navigate('/dashboard'); // Redirect to dashboard on successful login
} catch (err) {
setError(err.message || 'Login failed. Please check your credentials.');
} finally {
setLoading(false);
}
};

return (
\<form onSubmit={handleSubmit}\>
\<h2\>Login\</h2\>
{error && \<p className="error-message"\>{error}\</p\>}
\<div\>
\<label htmlFor="email"\>Email:\</label\>
\<input
type="email"
id="email"
value={email}
onChange={(e) =\> setEmail(e.target.value)}
required
/\>
\</div\>
\<div\>
\<label htmlFor="password"\>Password:\</label\>
\<input
type="password"
id="password"
value={password}
onChange={(e) =\> setPassword(e.target.value)}
required
/\>
\</div\>
\<button type="submit" disabled={loading}\>
{loading ? \<LoadingSpinner /\> : 'Login'}
\</button\>
\<p className="text-center mt-20"\>
Don't have an account? \<a href="/register"\>Register here\</a\>
\</p\>
\</form\>
);
}

export default LoginForm;
"""
file\_path = os.path.join(frontend\_path, "src", "components", "auth", "LoginForm.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_components\_auth\_register\_form\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/components/auth/RegisterForm.js"""
content = """import React, { useState } from 'react';
import { useNavigate } from 'react-router-dom';
import { useAuth } from '../../hooks/useAuth';
import LoadingSpinner from '../common/LoadingSpinner';

function RegisterForm() {
const [username, setUsername] = useState('');
const [email, setEmail] = useState('');
const [password, setPassword] = useState('');
const [confirmPassword, setConfirmPassword] = useState('');
const [error, setError] = useState('');
const [loading, setLoading] = useState(false);
const { register } = useAuth();
const navigate = useNavigate();

const handleSubmit = async (e) =\> {
e.preventDefault();
setError('');

```
if (password !== confirmPassword) {
  setError('Passwords do not match.');
  return;
}

setLoading(true);
try {
  await register(username, email, password);
  alert('Registration successful! Please log in.');
  navigate('/login'); // Redirect to login page after successful registration
} catch (err) {
  setError(err.message || 'Registration failed. Please try again.');
} finally {
  setLoading(false);
}
```

};

return (
\<form onSubmit={handleSubmit}\>
\<h2\>Register\</h2\>
{error && \<p className="error-message"\>{error}\</p\>}
\<div\>
\<label htmlFor="username"\>Username:\</label\>
\<input
type="text"
id="username"
value={username}
onChange={(e) =\> setUsername(e.target.value)}
required
/\>
\</div\>
\<div\>
\<label htmlFor="email"\>Email:\</label\>
\<input
type="email"
id="email"
value={email}
onChange={(e) =\> setEmail(e.target.value)}
required
/\>
\</div\>
\<div\>
\<label htmlFor="password"\>Password:\</label\>
\<input
type="password"
id="password"
value={password}
onChange={(e) =\> setPassword(e.target.value)}
required
/\>
\</div\>
\<div\>
\<label htmlFor="confirmPassword"\>Confirm Password:\</label\>
\<input
type="password"
id="confirmPassword"
value={confirmPassword}
onChange={(e) =\> setConfirmPassword(e.target.value)}
required
/\>
\</div\>
\<button type="submit" disabled={loading}\>
{loading ? \<LoadingSpinner /\> : 'Register'}
\</button\>
\<p className="text-center mt-20"\>
Already have an account? \<a href="/login"\>Login here\</a\>
\</p\>
\</form\>
);
}

export default RegisterForm;
"""
file\_path = os.path.join(frontend\_path, "src", "components", "auth", "RegisterForm.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_home\_page\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/HomePage.js"""
content = """import React, { useEffect, useState } from 'react';
import { Link } from 'react-router-dom';
import { getPopularCourses } from '../services/courseService';
import LoadingSpinner from '../components/common/LoadingSpinner';
import './HomePage.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function HomePage() {
const [popularCourses, setPopularCourses] = useState([]);
const [loading, setLoading] = useState(true);
const [error, setError] = useState('');

useEffect(() =\> {
const fetchPopularCourses = async () =\> {
try {
const courses = await getPopularCourses(5); // Fetch top 5 popular courses
setPopularCourses(courses);
} catch (err) {
setError('Failed to load popular courses.');
console.error('Error fetching popular courses:', err);
} finally {
setLoading(false);
}
};

```
fetchPopularCourses();
```

}, []);

if (loading) {
return \<LoadingSpinner /\>;
}

if (error) {
return \<div className="error-message text-center"\>{error}\</div\>;
}

return (
\<div className="home-page"\>
\<section className="hero-section"\>
\<h1\>Welcome to BTEC EduverseAI\</h1\>
\<p\>Your AI-powered platform for personalized learning and educational content creation.\</p\>
\<Link to="/courses" className="hero-button"\>Explore Courses\</Link\>
\</section\>

```
  <section className="popular-courses-section">
    <h2>Popular Courses</h2>
    {popularCourses.length > 0 ? (
      <div className="course-list">
        {popularCourses.map((course) => (
          <div key={course.id} className="course-card">
            <h3><Link to={`/courses/${course.id}`}>{course.title}</Link></h3>
            <p>{course.description.substring(0, 100)}...</p>
            <p>Difficulty: {course.difficulty_level}</p>
            <Link to={`/courses/${course.id}`} className="view-course-button">View Course</Link>
          </div>
        ))}
      </div>
    ) : (
      <p>No popular courses available at the moment.</p>
    )}
    <div className="text-center mt-20">
        <Link to="/courses" className="view-all-button">View All Courses</Link>
    </div>
  </section>

  <section className="features-section">
    <h2>Key Features</h2>
    <div className="features-grid">
      <div className="feature-item">
        <h3>AI-Powered Content Analysis</h3>
        <p>Summarize texts, extract key topics, and generate learning objectives instantly.</p>
      </div>
      <div className="feature-item">
        <h3>Personalized Recommendations</h3>
        <p>Get course suggestions tailored to your learning style and interests.</p>
      </div>
      <div className="feature-item">
        <h3>Dynamic Quiz Generation</h3>
        <p>Create custom quizzes on any topic to test your knowledge.</p>
      </div>
      <div className="feature-item">
        <h3>Comprehensive Course Management</h3>
        <p>Teachers can easily create, manage, and publish educational content.</p>
      </div>
    </div>
  </section>
</div>
```

);
}

export default HomePage;
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "HomePage.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_home\_page\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/HomePage.css"""
content = """.home-page {
padding: 20px;
}

.hero-section {
background-color: \#007bff;
color: white;
padding: 60px 20px;
text-align: center;
border-radius: 10px;
margin-bottom: 40px;
}

.hero-section h1 {
font-size: 3em;
margin-bottom: 15px;
}

.hero-section p {
font-size: 1.2em;
margin-bottom: 30px;
}

.hero-button {
background-color: \#61dafb;
color: \#282c34;
padding: 15px 30px;
border-radius: 5px;
text-decoration: none;
font-weight: bold;
font-size: 1.1em;
transition: background-color 0.3s ease;
}

.hero-button:hover {
background-color: \#4dc4e6;
}

.popular-courses-section,
.features-section {
margin-bottom: 40px;
}

.popular-courses-section h2,
.features-section h2 {
text-align: center;
font-size: 2.5em;
margin-bottom: 30px;
color: \#333;
}

.course-list {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
gap: 25px;
}

.course-card {
background-color: \#ffffff;
border: 1px solid \#e0e0e0;
border-radius: 8px;
padding: 25px;
box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
transition: transform 0.2s ease-in-out;
}

.course-card:hover {
transform: translateY(-5px);
}

.course-card h3 {
font-size: 1.5em;
margin-bottom: 10px;
}

.course-card h3 a {
color: \#007bff;
text-decoration: none;
}

.course-card h3 a:hover {
text-decoration: underline;
}

.course-card p {
font-size: 0.95em;
color: \#666;
line-height: 1.5;
}

.view-course-button {
display: inline-block;
background-color: \#28a745;
color: white;
padding: 10px 15px;
border-radius: 5px;
text-decoration: none;
margin-top: 15px;
font-size: 0.9em;
transition: background-color 0.3s ease;
}

.view-course-button:hover {
background-color: \#218838;
}

.view-all-button {
background-color: \#6c757d;
color: white;
padding: 12px 25px;
border-radius: 5px;
text-decoration: none;
font-weight: bold;
transition: background-color 0.3s ease;
}

.view-all-button:hover {
background-color: \#5a6268;
}

.features-grid {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
gap: 25px;
}

.feature-item {
background-color: \#e9f5ff;
padding: 25px;
border-radius: 8px;
text-align: center;
box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
}

.feature-item h3 {
color: \#0056b3;
font-size: 1.4em;
margin-bottom: 10px;
}

.feature-item p {
color: \#444;
}
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "HomePage.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_courses\_page\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/CoursesPage.js"""
content = """import React, { useEffect, useState } from 'react';
import { Link } from 'react-router-dom';
import { getAllPublishedCourses } from '../services/courseService';
import LoadingSpinner from '../components/common/LoadingSpinner';
import './CoursesPage.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function CoursesPage() {
const [courses, setCourses] = useState([]);
const [loading, setLoading] = useState(true);
const [error, setError] = useState('');

useEffect(() =\> {
const fetchCourses = async () =\> {
try {
const fetchedCourses = await getAllPublishedCourses();
setCourses(fetchedCourses);
} catch (err) {
setError('Failed to load courses. Please try again later.');
console.error('Error fetching courses:', err);
} finally {
setLoading(false);
}
};

```
fetchCourses();
```

}, []);

if (loading) {
return \<LoadingSpinner /\>;
}

if (error) {
return \<div className="error-message text-center"\>{error}\</div\>;
}

return (
\<div className="courses-page"\>
\<h1\>All Courses\</h1\>
{courses.length \> 0 ? (
\<div className="course-grid"\>
{courses.map((course) =\> (
\<div key={course.id} className="course-card"\>
\<h3\>\<Link to={`/courses/${course.id}`}\>{course.title}\</Link\>\</h3\>
\<p\>{course.description.substring(0, 150)}...\</p\>
\<div className="course-meta"\>
\<span\>Difficulty: {course.difficulty\_level}\</span\>
\<span\>Status: {course.status}\</span\>
\</div\>
\<Link to={`/courses/${course.id}`} className="view-course-button"\>View Course\</Link\>
\</div\>
))}
\</div\>
) : (
\<p className="text-center"\>No courses available yet. Please check back later\!\</p\>
)}
\</div\>
);
}

export default CoursesPage;
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "CoursesPage.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_courses\_page\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/CoursesPage.css"""
content = """.courses-page {
padding: 20px;
}

.courses-page h1 {
text-align: center;
font-size: 2.8em;
margin-bottom: 40px;
color: \#333;
}

.course-grid {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
gap: 30px;
}

.course-card {
background-color: \#ffffff;
border: 1px solid \#e0e0e0;
border-radius: 8px;
padding: 25px;
box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
display: flex;
flex-direction: column;
justify-content: space-between;
}

.course-card:hover {
transform: translateY(-7px);
box-shadow: 0 6px 15px rgba(0, 0, 0, 0.12);
}

.course-card h3 {
font-size: 1.6em;
margin-bottom: 12px;
}

.course-card h3 a {
color: \#007bff;
text-decoration: none;
}

.course-card h3 a:hover {
text-decoration: underline;
}

.course-card p {
font-size: 1em;
color: \#555;
line-height: 1.6;
margin-bottom: 15px;
flex-grow: 1; /\* Allow description to take available space \*/
}

.course-meta {
font-size: 0.9em;
color: \#777;
margin-top: 10px;
margin-bottom: 20px;
}

.course-meta span {
margin-right: 15px;
}

.view-course-button {
display: inline-block;
background-color: \#28a745;
color: white;
padding: 12px 20px;
border-radius: 5px;
text-decoration: none;
font-weight: bold;
font-size: 1em;
transition: background-color 0.3s ease;
align-self: flex-start; /\* Align button to the start of the flex container \*/
}

.view-course-button:hover {
background-color: \#218838;
}
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "CoursesPage.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_course\_detail\_page\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/CourseDetailPage.js"""
content = """import React, { useEffect, useState } from 'react';
import { useParams } from 'react-router-dom';
import { getCourseById } from '../services/courseService';
import LoadingSpinner from '../components/common/LoadingSpinner';
import './CourseDetailPage.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function CourseDetailPage() {
const { id } = useParams();
const [course, setCourse] = useState(null);
const [loading, setLoading] = useState(true);
const [error, setError] = useState('');

useEffect(() =\> {
const fetchCourse = async () =\> {
try {
const fetchedCourse = await getCourseById(id);
setCourse(fetchedCourse);
} catch (err) {
if (err.response && err.response.status === 404) {
setError('Course not found.');
} else {
setError('Failed to load course details. Please try again later.');
}
console.error('Error fetching course details:', err);
} finally {
setLoading(false);
}
};

```
fetchCourse();
```

}, [id]);

if (loading) {
return \<LoadingSpinner /\>;
}

if (error) {
return \<div className="error-message text-center"\>{error}\</div\>;
}

if (\!course) {
return \<div className="text-center"\>No course data available.\</div\>;
}

return (
\<div className="course-detail-page"\>
\<div className="course-header"\>
\<h1\>{course.title}\</h1\>
\<p className="course-creator"\>Created by: {course.creator\_username}\</p\>
\</div\>

```
  <div className="course-info">
    <p><strong>Description:</strong> {course.description}</p>
    <p><strong>Difficulty:</strong> {course.difficulty_level}</p>
    <p><strong>Status:</strong> {course.status}</p>
    <p><strong>Created At:</strong> {new Date(course.created_at).toLocaleDateString()}</p>
    <p><strong>Last Updated:</strong> {new Date(course.updated_at).toLocaleDateString()}</p>
  </div>

  <section className="course-sections">
    <h2>Course Content</h2>
    {/* Placeholder for course content/sections */}
    <div className="section-placeholder">
      <p>Course content will be displayed here.</p>
      <ul>
        <li>Module 1: Introduction</li>
        <li>Module 2: Core Concepts</li>
        <li>Module 3: Advanced Topics</li>
        <li>Module 4: Practical Application</li>
      </ul>
    </div>
  </section>

  {/* Add more sections like comments, ratings, AI tools integration etc. */}
</div>
```

);
}

export default CourseDetailPage;
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "CourseDetailPage.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_course\_detail\_page\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/CourseDetailPage.css"""
content = """.course-detail-page {
padding: 20px;
max-width: 900px;
margin: 0 auto;
background-color: \#ffffff;
border-radius: 8px;
box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
}

.course-header {
text-align: center;
margin-bottom: 30px;
padding-bottom: 20px;
border-bottom: 1px solid \#eee;
}

.course-header h1 {
font-size: 2.8em;
color: \#007bff;
margin-bottom: 10px;
}

.course-creator {
font-size: 1.1em;
color: \#666;
}

.course-info {
margin-bottom: 30px;
font-size: 1.1em;
line-height: 1.8;
}

.course-info p {
margin-bottom: 10px;
}

.course-info strong {
color: \#333;
}

.course-sections h2 {
font-size: 2.2em;
color: \#333;
margin-bottom: 20px;
border-bottom: 2px solid \#007bff;
padding-bottom: 10px;
}

.section-placeholder {
background-color: \#f9f9f9;
border: 1px dashed \#ccc;
padding: 20px;
border-radius: 8px;
text-align: center;
color: \#777;
}

.section-placeholder ul {
list-style-type: none;
padding: 0;
margin-top: 15px;
}

.section-placeholder li {
background-color: \#e6f7ff;
margin-bottom: 8px;
padding: 10px;
border-left: 5px solid \#007bff;
text-align: left;
color: \#333;
}
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "CourseDetailPage.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_dashboard\_page\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/DashboardPage.js"""
content = """import React, { useEffect, useState } from 'react';
import { useAuth } from '../hooks/useAuth';
import { getRecommendedCoursesForUser } from '../services/courseService'; // Assuming this service will handle recommendations
import LoadingSpinner from '../components/common/LoadingSpinner';
import { Link } from 'react-router-dom';
import './DashboardPage.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function DashboardPage() {
const { user } = useAuth();
const [recommendedCourses, setRecommendedCourses] = useState([]);
const [loading, setLoading] = useState(true);
const [error, setError] = useState('');

useEffect(() =\> {
const fetchRecommendations = async () =\> {
if (user) {
try {
const courses = await getRecommendedCoursesForUser(user.id); // Pass user ID for personalized recs
setRecommendedCourses(courses);
} catch (err) {
setError('Failed to load recommendations.');
console.error('Error fetching recommendations:', err);
} finally {
setLoading(false);
}
} else {
setLoading(false); // No user, no recommendations to fetch
}
};

```
fetchRecommendations();
```

}, [user]);

if (loading) {
return \<LoadingSpinner /\>;
}

if (error) {
return \<div className="error-message text-center"\>{error}\</div\>;
}

if (\!user) {
return \<div className="text-center"\>Please log in to view your dashboard.\</div\>;
}

return (
\<div className="dashboard-page"\>
\<h1\>Welcome, {user.username || user.email}\!\</h1\>
\<p\>Your role: {user.role}\</p\>

```
  <section className="dashboard-section">
    <h2>Your Recommended Courses</h2>
    {recommendedCourses.length > 0 ? (
      <div className="course-list">
        {recommendedCourses.map((course) => (
          <div key={course.id} className="course-card">
            <h3><Link to={`/courses/${course.id}`}>{course.title}</Link></h3>
            <p>{course.description.substring(0, 100)}...</p>
            <p>Difficulty: {course.difficulty_level}</p>
            <Link to={`/courses/${course.id}`} className="view-course-button">View Course</Link>
          </div>
        ))}
      </div>
    ) : (
      <p>No personalized recommendations available at the moment. Explore our <Link to="/courses">courses</Link>!</p>
    )}
  </section>

  {user.role === 'teacher' || user.role === 'admin' ? (
    <section className="dashboard-section">
      <h2>Teacher/Admin Tools</h2>
      <div className="admin-tools-grid">
        <Link to="/create-course" className="tool-card">
          <h3>Create New Course</h3>
          <p>Start building a new educational module.</p>
        </Link>
        <Link to="/manage-courses" className="tool-card">
          <h3>Manage My Courses</h3>
          <p>Edit or delete your existing courses.</p>
        </Link>
        <Link to="/ai-tools" className="tool-card">
          <h3>AI Content Tools</h3>
          <p>Utilize AI for summarization, analysis, and quiz generation.</p>
        </Link>
      </div>
    </section>
  ) : (
    <section className="dashboard-section">
        <h2>Student Resources</h2>
        <div className="student-resources-grid">
            <Link to="/my-progress" className="tool-card">
                <h3>My Progress</h3>
                <p>Track your learning journey and completed courses.</p>
            </Link>
            <Link to="/quiz-history" className="tool-card">
                <h3>Quiz History</h3>
                <p>Review your past quiz attempts and scores.</p>
            </Link>
        </div>
    </section>
  )}

  {/* Add more dashboard sections as needed */}
</div>
```

);
}

export default DashboardPage;
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "DashboardPage.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_dashboard\_page\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/DashboardPage.css"""
content = """.dashboard-page {
padding: 20px;
}

.dashboard-page h1 {
font-size: 2.5em;
margin-bottom: 10px;
color: \#333;
}

.dashboard-page p {
font-size: 1.1em;
color: \#555;
margin-bottom: 30px;
}

.dashboard-section {
margin-bottom: 40px;
background-color: \#ffffff;
padding: 30px;
border-radius: 8px;
box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
}

.dashboard-section h2 {
font-size: 2em;
color: \#007bff;
margin-bottom: 25px;
border-bottom: 2px solid \#e0e0e0;
padding-bottom: 10px;
}

.course-list {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
gap: 20px;
}

/\* Reusing course-card styles from HomePage.css, ensure it's imported or global */
.dashboard-section .course-card {
background-color: \#f8f9fa; /* Lighter background for dashboard cards \*/
border: 1px solid \#dee2e6;
padding: 20px;
border-radius: 8px;
box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
transition: transform 0.2s ease;
}

.dashboard-section .course-card:hover {
transform: translateY(-3px);
}

.dashboard-section .course-card h3 {
font-size: 1.3em;
margin-bottom: 8px;
}

.dashboard-section .course-card p {
font-size: 0.9em;
color: \#666;
margin-bottom: 15px;
}

.dashboard-section .view-course-button {
background-color: \#17a2b8; /\* Info blue \*/
padding: 8px 15px;
font-size: 0.9em;
}

.dashboard-section .view-course-button:hover {
background-color: \#138496;
}

.admin-tools-grid,
.student-resources-grid {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
gap: 20px;
}

.tool-card {
background-color: \#e2f0ff; /\* Light blue \*/
border: 1px solid \#b3d9ff;
border-radius: 8px;
padding: 25px;
text-align: center;
text-decoration: none;
color: \#0056b3;
box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
transition: transform 0.2s ease, background-color 0.2s ease;
}

.tool-card:hover {
transform: translateY(-5px);
background-color: \#cce7ff;
}

.tool-card h3 {
font-size: 1.4em;
margin-bottom: 10px;
color: \#004085;
}

.tool-card p {
font-size: 0.95em;
color: \#004085;
margin-bottom: 0;
}
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "DashboardPage.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_not\_found\_page\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/NotFoundPage.js"""
content = """import React from 'react';
import { Link } from 'react-router-dom';
import './NotFoundPage.css'; // Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø­Ù‚Ù‹Ø§

function NotFoundPage() {
return (
\<div className="not-found-page"\>
\<h1\>404 - Page Not Found\</h1\>
\<p\>Oops\! The page you are looking for does not exist.\</p\>
\<Link to="/" className="home-link-button"\>Go to Home Page\</Link\>
\</div\>
);
}

export default NotFoundPage;
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "NotFoundPage.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_pages\_not\_found\_page\_css():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/pages/NotFoundPage.css"""
content = """.not-found-page {
display: flex;
flex-direction: column;
justify-content: center;
align-items: center;
min-height: 70vh; /\* Adjust height as needed \*/
text-align: center;
color: \#333;
}

.not-found-page h1 {
font-size: 4em;
color: \#dc3545; /\* Red for error \*/
margin-bottom: 20px;
}

.not-found-page p {
font-size: 1.5em;
margin-bottom: 30px;
}

.home-link-button {
background-color: \#007bff;
color: white;
padding: 15px 30px;
border-radius: 5px;
text-decoration: none;
font-weight: bold;
font-size: 1.2em;
transition: background-color 0.3s ease;
}

.home-link-button:hover {
background-color: \#0056b3;
}
"""
file\_path = os.path.join(frontend\_path, "src", "pages", "NotFoundPage.css")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_services\_auth\_service\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/services/authService.js"""
content = """import api from './api';
import { API\_ENDPOINTS } from '../utils/constants';

const authService = {
login: async (email, password) =\> {
try {
const response = await api.post(API\_ENDPOINTS.LOGIN, new URLSearchParams({ username: email, password: password }), {
headers: {
'Content-Type': 'application/x-www-form-urlencoded'
}
});
return response.data; // Contains access\_token and token\_type
} catch (error) {
console.error('Login error:', error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Login failed');
}
},

register: async (username, email, password) =\> {
try {
const response = await api.post(API\_ENDPOINTS.REGISTER, { username, email, password });
return response.data;
} catch (error) {
console.error('Registration error:', error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Registration failed');
}
},

getMe: async (token) =\> {
try {
const response = await api.get(API\_ENDPOINTS.GET\_ME, {
headers: {
Authorization: `Bearer ${token}`
}
});
return response.data;
} catch (error) {
console.error('Get user info error:', error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Failed to fetch user info');
}
}
};

export default authService;
"""
file\_path = os.path.join(frontend\_path, "src", "services", "authService.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_services\_course\_service\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/services/courseService.js"""
content = """import api from './api';
import { API\_ENDPOINTS } from '../utils/constants';

const courseService = {
getAllPublishedCourses: async (skip = 0, limit = 100) =\> {
try {
const response = await api.get(`${API_ENDPOINTS.COURSES}?skip=${skip}&limit=${limit}`);
return response.data;
} catch (error) {
console.error('Error fetching all published courses:', error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Failed to fetch courses');
}
},

getCourseById: async (id) =\> {
try {
const response = await api.get(`${API_ENDPOINTS.COURSES}/${id}`);
return response.data;
} catch (error) {
console.error(`Error fetching course with ID ${id}:`, error.response?.data || error.message);
throw new Error(error.response?.data?.detail || `Failed to fetch course ${id}`);
}
},

getPopularCourses: async (limit = 10) =\> {
try {
const response = await api.get(`${API_ENDPOINTS.RECOMMENDATIONS_POPULAR}?limit=${limit}`);
return response.data;
} catch (error) {
console.error('Error fetching popular courses:', error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Failed to fetch popular courses');
}
},

getRecommendedCoursesForUser: async (userId, limit = 10) =\> {
// In the backend, this endpoint uses the current authenticated user's ID.
// The `userId` parameter here is primarily for conceptual clarity or if we had an admin endpoint.
// For the current user, the backend will infer the ID from the token.
try {
const response = await api.get(`${API_ENDPOINTS.RECOMMENDATIONS_FOR_YOU}?limit=${limit}`);
return response.data;
} catch (error) {
console.error(`Error fetching recommendations for user ${userId}:`, error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Failed to fetch personalized recommendations');
}
},

getRelatedCourses: async (courseId, limit = 10) =\> {
try {
const response = await api.get(`${API_ENDPOINTS.RECOMMENDATIONS_RELATED}/${courseId}?limit=${limit}`);
return response.data;
} catch (error) {
console.error(`Error fetching related courses for course ${courseId}:`, error.response?.data || error.message);
throw new Error(error.response?.data?.detail || 'Failed to fetch related courses');
}
},

// Add more course-related services as needed (e.g., createCourse, updateCourse, deleteCourse)
// These would require authentication and specific user roles.
};

export default courseService;
"""
file\_path = os.path.join(frontend\_path, "src", "services", "courseService.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_services\_api\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/services/api.js"""
content = """import axios from 'axios';
import { API\_BASE\_URL } from '../utils/constants';

const api = axios.create({
baseURL: API\_BASE\_URL,
headers: {
'Content-Type': 'application/json',
},
});

// Request interceptor to add the auth token
api.interceptors.request.use(
(config) =\> {
const token = localStorage.getItem('accessToken');
if (token) {
config.headers.Authorization = `Bearer ${token}`;
}
return config;
},
(error) =\> {
return Promise.reject(error);
}
);

// Response interceptor to handle errors globally (e.g., 401 Unauthorized)
api.interceptors.response.use(
(response) =\> response,
(error) =\> {
// Example: If 401 Unauthorized, redirect to login page
if (error.response && error.response.status === 401) {
console.warn('Unauthorized access. Redirecting to login...');
localStorage.removeItem('accessToken');
localStorage.removeItem('user');
// window.location.href = '/login'; // Or use navigate from react-router-dom if in a component context
}
return Promise.reject(error);
}
);

export default api;
"""
file\_path = os.path.join(frontend\_path, "src", "services", "api.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_context\_auth\_context\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/context/AuthContext.js"""
content = """import React, { createContext, useState, useEffect } from 'react';
import authService from '../services/authService';

const AuthContext = createContext(null);

export const AuthProvider = ({ children }) =\> {
const [user, setUser] = useState(null);
const [loading, setLoading] = useState(true);

useEffect(() =\> {
const loadUserFromStorage = async () =\> {
const token = localStorage.getItem('accessToken');
if (token) {
try {
const userData = await authService.getMe(token);
setUser(userData);
} catch (error) {
console.error('Failed to fetch user data from token:', error);
localStorage.removeItem('accessToken');
localStorage.removeItem('user');
setUser(null);
}
}
setLoading(false);
};

```
loadUserFromStorage();
```

}, []);

const login = async (email, password) =\> {
const data = await authService.login(email, password);
localStorage.setItem('accessToken', data.access\_token);
const userData = await authService.getMe(data.access\_token);
setUser(userData);
localStorage.setItem('user', JSON.stringify(userData));
};

const register = async (username, email, password) =\> {
const data = await authService.register(username, email, password);
// Optionally log in the user immediately after registration
// await login(email, password);
return data;
};

const logout = () =\> {
localStorage.removeItem('accessToken');
localStorage.removeItem('user');
setUser(null);
};

return (
\<AuthContext.Provider value={{ user, login, register, logout, loading }}\>
{children}
\</AuthContext.Provider\>
);
};

export default AuthContext;
"""
file\_path = os.path.join(frontend\_path, "src", "context", "AuthContext.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_hooks\_use\_auth\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/hooks/useAuth.js"""
content = """import { useContext } from 'react';
import AuthContext from '../context/AuthContext';

export const useAuth = () =\> {
const context = useContext(AuthContext);
if (\!context) {
throw new Error('useAuth must be used within an AuthProvider');
}
return context;
};
"""
file\_path = os.path.join(frontend\_path, "src", "hooks", "useAuth.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_utils\_constants\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/utils/constants.js"""
content = """export const API\_BASE\_URL = process.env.REACT\_APP\_API\_URL || 'http://localhost:8000/api/v1';

export const API\_ENDPOINTS = {
LOGIN: '/auth/token',
REGISTER: '/auth/register',
GET\_ME: '/auth/me',
COURSES: '/courses', // For published courses
COURSES\_ALL: '/courses/all', // For all courses (admin/teacher)
RECOMMENDATIONS\_POPULAR: '/recommendations/popular-courses',
RECOMMENDATIONS\_FOR\_YOU: '/recommendations/for-you',
RECOMMENDATIONS\_RELATED: '/recommendations/related-to-course',
AI\_GENERATE\_TEXT: '/ai/generate-text',
AI\_ANALYZE\_CONTENT: '/ai/analyze-content',
AI\_SUMMARIZE\_TEXT: '/ai/summarize-text',
AI\_GENERATE\_QUIZ: '/ai/generate-quiz',
USERS: '/users', // For user management (admin)
};

export const USER\_ROLES = {
STUDENT: 'student',
TEACHER: 'teacher',
ADMIN: 'admin',
};

export const COURSE\_STATUS = {
DRAFT: 'draft',
PUBLISHED: 'published',
ARCHIVED: 'archived',
};

export const DIFFICULTY\_LEVELS = {
BEGINNER: 'Beginner',
INTERMEDIATE: 'Intermediate',
ADVANCED: 'Advanced',
};

// Other constants like messages, default values, etc.
export const DEFAULT\_PAGE\_LIMIT = 10;
export const DEFAULT\_RECOMMENDATION\_LIMIT = 5;
"""
file\_path = os.path.join(frontend\_path, "src", "utils", "constants.js")
return write\_file\_safely(file\_path, content)

def create\_frontend\_src\_router\_app\_router\_js():
"""Ø¥Ù†Ø´Ø§Ø¡ frontend/src/router/AppRouter.js"""
content = """import React from 'react';
import { BrowserRouter as Router, Routes, Route, Navigate } from 'react-router-dom';
import HomePage from '../pages/HomePage';
import CoursesPage from '../pages/CoursesPage';
import CourseDetailPage from '../pages/CourseDetailPage';
import DashboardPage from '../pages/DashboardPage';
import NotFoundPage from '../pages/NotFoundPage';
import LoginForm from '../components/auth/LoginForm';
import RegisterForm from '../components/auth/RegisterForm';
import { useAuth } from '../hooks/useAuth';
import LoadingSpinner from '../components/common/LoadingSpinner';

// PrivateRoute component to protect routes
const PrivateRoute = ({ children, allowedRoles }) =\> {
const { user, loading } = useAuth();

if (loading) {
return \<LoadingSpinner /\>; // Show loading spinner while checking auth status
}

if (\!user) {
// Not authenticated, redirect to login
return \<Navigate to="/login" replace /\>;
}

if (allowedRoles && \!allowedRoles.includes(user.role)) {
// Authenticated but not authorized, redirect to home or unauthorized page
return \<Navigate to="/" replace /\>; // Or a specific unauthorized page
}

return children;
};

function AppRouter() {
return (
\<Router\>
\<Routes\>
\<Route path="/" element={\<HomePage /\>} /\>
\<Route path="/courses" element={\<CoursesPage /\>} /\>
\<Route path="/courses/:id" element={\<CourseDetailPage /\>} /\>
\<Route path="/login" element={\<LoginForm /\>} /\>
\<Route path="/register" element={\<RegisterForm /\>} /\>

```
    {/* Protected routes */}
    <Route 
      path="/dashboard" 
      element={
        <PrivateRoute allowedRoles={['student', 'teacher', 'admin']}>
          <DashboardPage />
        </PrivateRoute>
      } 
    />
    {/* Example of a teacher/admin only route */}
    {/* <Route 
      path="/create-course" 
      element={
        <PrivateRoute allowedRoles={['teacher', 'admin']}>
          <CreateCoursePage />
        </PrivateRoute>
      } 
    /> */}

    {/* Catch-all for undefined routes */}
    <Route path="*" element={<NotFoundPage />} />
  </Routes>
</Router>
```

);
}

export default AppRouter;
"""
file\_path = os.path.join(frontend\_path, "src", "router", "AppRouter.js")
return write\_file\_safely(file\_path, content)

# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§

frontend\_files = [
("README.md", create\_frontend\_readme),
("package.json", create\_frontend\_package\_json),
("public/index.html", create\_frontend\_public\_index\_html),
("src/index.js", create\_frontend\_src\_index\_js),
("src/App.js", create\_frontend\_src\_app\_js),
("src/App.css", create\_frontend\_src\_app\_css),
("src/components/common/Header.js", create\_frontend\_src\_components\_common\_header\_js),
("src/components/common/Header.css", create\_frontend\_src\_components\_common\_header\_css),
("src/components/common/Footer.js", create\_frontend\_src\_components\_common\_footer\_js),
("src/components/common/Footer.css", create\_frontend\_src\_components\_common\_footer\_css),
("src/components/common/LoadingSpinner.js", create\_frontend\_src\_components\_common\_loading\_spinner\_js),
("src/components/common/LoadingSpinner.css", create\_frontend\_src\_components\_common\_loading\_spinner\_css),
("src/components/auth/LoginForm.js", create\_frontend\_src\_components\_auth\_login\_form\_js),
("src/components/auth/RegisterForm.js", create\_frontend\_src\_components\_auth\_register\_form\_js),
("src/pages/HomePage.js", create\_frontend\_src\_pages\_home\_page\_js),
("src/pages/HomePage.css", create\_frontend\_src\_pages\_home\_page\_css),
("src/pages/CoursesPage.js", create\_frontend\_src\_pages\_courses\_page\_js),
("src/pages/CoursesPage.css", create\_frontend\_src\_pages\_courses\_page\_css),
("src/pages/CourseDetailPage.js", create\_frontend\_src\_pages\_course\_detail\_page\_js),
("src/pages/CourseDetailPage.css", create\_frontend\_src\_pages\_course\_detail\_page\_css),
("src/pages/DashboardPage.js", create\_frontend\_src\_pages\_dashboard\_page\_js),
("src/pages/DashboardPage.css", create\_frontend\_src\_pages\_dashboard\_page\_css),
("src/pages/NotFoundPage.js", create\_frontend\_src\_pages\_not\_found\_page\_js),
("src/pages/NotFoundPage.css", create\_frontend\_src\_pages\_not\_found\_page\_css),
("src/services/authService.js", create\_frontend\_src\_services\_auth\_service\_js),
("src/services/courseService.js", create\_frontend\_src\_services\_course\_service\_js),
("src/services/api.js", create\_frontend\_src\_services\_api\_js),
("src/context/AuthContext.js", create\_frontend\_src\_context\_auth\_context\_js),
("src/hooks/useAuth.js", create\_frontend\_src\_hooks\_use\_auth\_js),
("src/utils/constants.js", create\_frontend\_src\_utils\_constants\_js),
("src/router/AppRouter.js", create\_frontend\_src\_router\_app\_router\_js),
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `frontend`...")

created\_frontend\_files\_count = 0
for relative\_path, create\_function in frontend\_files:
full\_path = os.path.join(frontend\_path, relative\_path)
print(f"\\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {relative\_path}...")
if create\_function():
created\_frontend\_files\_count += 1
size = os.path.getsize(full\_path)
print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {relative\_path} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
else:
print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {relative\_path}.")

print(f"\\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created\_frontend\_files\_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(frontend\_files)} ÙÙŠ Ù…Ø¬Ù„Ø¯ frontend Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§

print(f"\\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª frontend Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©:")
for relative\_path, \_ in frontend\_files:
full\_path = os.path.join(frontend\_path, relative\_path)
if os.path.exists(full\_path):
size = os.path.getsize(full\_path)
print(f"  âœ… {relative\_path} ({size} bytes)")
else:
print(f"  âŒ {relative\_path} (Ù…ÙÙ‚ÙˆØ¯)")

print("\\nğŸ‰ ØªÙ‡Ø§Ù†ÙŠÙ†Ø§\! Ù„Ù‚Ø¯ ØªÙ… Ø§Ù„Ø¢Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `frontend`.")
print("ğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù„ÙˆÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰.")

```

---
### ğŸ“ Ù…Ù„Ø®Øµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `frontend`

Ù„Ù‚Ø¯ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¹Ø¨Ø¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ `frontend`ØŒ Ù…Ù…Ø§ ÙŠÙˆÙØ± Ù‡ÙŠÙƒÙ„Ø§Ù‹ Ù„ØªØ·Ø¨ÙŠÙ‚ React Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©. Ù‡Ø°Ø§ Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙŠØªØ¶Ù…Ù†:

* **Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ**: Ù…Ù„ÙØ§Øª `README.md`ØŒ `package.json`ØŒ `public/index.html`ØŒ `src/index.js`ØŒ `src/App.js`ØŒ Ùˆ `src/App.css` Ù„ØªÙ‡ÙŠØ¦Ø© ØªØ·Ø¨ÙŠÙ‚ React.
* **Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© (`components/common`)**: Ù…Ø«Ù„ `Header`ØŒ `Footer`ØŒ Ùˆ `LoadingSpinner` Ù„Ø¶Ù…Ø§Ù† ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªÙ†Ø§Ø³Ù‚Ø©.
* **Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (`components/auth`)**: `LoginForm` Ùˆ `RegisterForm` Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªØ³Ø¬ÙŠÙ„Ù‡.
* **Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (`pages`)**: `HomePage`ØŒ `CoursesPage`ØŒ `CourseDetailPage`ØŒ `DashboardPage`ØŒ Ùˆ `NotFoundPage` Ù„ØªÙ…Ø«ÙŠÙ„ Ø£Ù‚Ø³Ø§Ù… Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
* **Ø§Ù„Ø®Ø¯Ù…Ø§Øª (`services`)**: `authService.js` Ùˆ `courseService.js` Ùˆ `api.js` Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© (Backend API)ØŒ ÙˆØªÙ†Ø¸ÙŠÙ… Ù…Ù†Ø·Ù‚ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
* **Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø©**: `AuthContext.js` Ùˆ `useAuth.js` Ù„ØªØ¨Ø³ÙŠØ· Ø¥Ø¯Ø§Ø±Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ø¹Ø¨Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
* **Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„Ù…Ø±Ø§ÙÙ‚ (`utils`)**: `constants.js` Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª API.
* **Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ (`router`)**: `AppRouter.js` Ù„Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙˆØ¬ÙŠÙ‡ React Router ÙˆØ­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª.

**Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…Ù„ÙØ§Øª `frontend` Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡:**
* **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­**: 30/30

---
Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Ù†Ø§ Ø§Ù„Ø¢Ù† Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙˆÙ…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ù„Ù…Ø¬Ù„Ø¯ `frontend`. Ù‡Ø°Ø§ ÙŠÙ…Ø«Ù„ Ø¬Ø²Ø¡Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.

ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø³Ù†Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ù…Ø«Ù„ `monitoring`, `management`, `tests`, `docs`, `scripts`, `data`, Ùˆ `config`.
```-----

### ğŸ—ï¸ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `monitoring`

Ø¨Ø¹Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ØµØ¯Ø±ÙŠ Ù„Ù„ÙˆØ§Ø¬Ù‡ØªÙŠÙ† Ø§Ù„Ø®Ù„ÙÙŠØ© ÙˆØ§Ù„Ø£Ù…Ø§Ù…ÙŠØ©ØŒ Ø³Ù†Ù†ØªÙ‚Ù„ Ø§Ù„Ø¢Ù† Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ **`monitoring`**. Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ø®ØµØµ Ù„Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ ØªØ¶Ù…Ù† Ø£Ø¯Ø§Ø¡ ÙˆØ§Ø³ØªÙ‚Ø±Ø§Ø± ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ ØªÙˆÙÙŠØ± Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©.

Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©:

  * `monitoring/performance/metrics_collector.py`: Ù„ØªØ¬Ù…ÙŠØ¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡.
  * `monitoring/performance/performance_monitor.py`: Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù….
  * `monitoring/performance/alert_system.py`: Ù„Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³.
  * `monitoring/quality/quality_assurance.py`: Ù„Ø¯ÙˆØ§Ù„ Ø¶Ù…Ø§Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©.
  * `monitoring/quality/automated_testing.py`: Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¢Ù„ÙŠØ© (Ù…Ø¤Ù‚ØªØ§Ù‹).
  * `monitoring/diagnostics/system_diagnostics.py`: Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù†Ø¸Ø§Ù….
  * `monitoring/diagnostics/error_tracker.py`: Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.
  * `monitoring/diagnostics/log_analyzer.py`: Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª.

-----

### ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„ÙØ§Øª `monitoring`

```python
import os

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_name = "BTEC_EduverseAI"
base_path = f"/home/user/output/{project_name}"
monitoring_path = os.path.join(base_path, "monitoring")

def write_file_safely(file_path, content):
    """ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡."""
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© {file_path}: {e}")
        return False

def create_monitoring_performance_metrics_collector_py():
    """Ø¥Ù†Ø´Ø§Ø¡ monitoring/performance/metrics_collector.py"""
    content = """from prometheus_client import Gauge, Counter, Histogram, generate_latest
from typing import Dict, Any
import time
import psutil # Ù„ØªØ¬Ù…ÙŠØ¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ø¸Ø§Ù…
from utils.logger import get_logger
from core.config import settings

logger = get_logger(__name__)

# Ù…Ù‚Ø§ÙŠÙŠØ³ Prometheus Ø§Ù„Ù…Ø®ØµØµØ©
# Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª (Counters)
REQUESTS_TOTAL = Counter('btec_eduverseai_http_requests_total', 'Total HTTP Requests', ['method', 'endpoint', 'status'])
DB_QUERIES_TOTAL = Counter('btec_eduverseai_db_queries_total', 'Total Database Queries', ['type', 'status'])
AI_REQUESTS_TOTAL = Counter('btec_eduverseai_ai_requests_total', 'Total AI Service Requests', ['service', 'status'])
USER_LOGINS_TOTAL = Counter('btec_eduverseai_user_logins_total', 'Total User Login Attempts', ['status'])
COURSE_CREATIONS_TOTAL = Counter('btec_eduverseai_course_creations_total', 'Total Course Creation Attempts', ['status'])

# Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ (Gauges)
ACTIVE_USERS = Gauge('btec_eduverseai_active_users', 'Currently Active Users')
SYSTEM_CPU_USAGE = Gauge('btec_eduverseai_system_cpu_usage_percent', 'System CPU Usage Percentage')
SYSTEM_MEMORY_USAGE = Gauge('btec_eduverseai_system_memory_usage_percent', 'System Memory Usage Percentage')
DB_CONNECTIONS_ACTIVE = Gauge('btec_eduverseai_db_active_connections', 'Active Database Connections')
REDIS_CONNECTIONS_ACTIVE = Gauge('btec_eduverseai_redis_active_connections', 'Active Redis Connections')
PENDING_CELERY_TASKS = Gauge('btec_eduverseai_celery_pending_tasks', 'Number of Pending Celery Tasks')

# Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© (Histograms)
REQUEST_LATENCY_SECONDS = Histogram('btec_eduverseai_request_latency_seconds', 'HTTP Request Latency in Seconds', ['endpoint'])
DB_QUERY_LATENCY_SECONDS = Histogram('btec_eduverseai_db_query_latency_seconds', 'Database Query Latency in Seconds', ['type'])
AI_INFERENCE_LATENCY_SECONDS = Histogram('btec_eduverseai_ai_inference_latency_seconds', 'AI Inference Latency in Seconds', ['service'])

def collect_system_metrics():
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„Ù†Ø¸Ø§Ù….\"\"\"
    try:
        cpu_percent = psutil.cpu_percent(interval=None) # Non-blocking
        mem_info = psutil.virtual_memory()
        memory_percent = mem_info.percent
        
        SYSTEM_CPU_USAGE.set(cpu_percent)
        SYSTEM_MEMORY_USAGE.set(memory_percent)
        logger.debug(f"Collected system metrics: CPU={cpu_percent}%, Memory={memory_percent}%")
    except Exception as e:
        logger.error(f"Failed to collect system metrics: {e}")

async def collect_db_metrics():
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\"\"\"
    try:
        # Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØªØ·Ù„Ø¨ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # Ù„Ù„ØªØ¨Ø³ÙŠØ·ØŒ Ù†ÙØªØ±Ø¶ Ù‚ÙŠÙ…Ù‹Ø§ ÙˆÙ‡Ù…ÙŠØ© Ø£Ùˆ Ù†Ø³ØªØ®Ø¯Ù… check_database_connection
        # ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªØªÙØ§Ø¹Ù„ Ù…Ø¹ SQLAlchemy Ø£Ùˆ psycopg2 Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª
        from core.database import check_database_connection # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
        db_connected = await check_database_connection()
        if db_connected:
            # Ù…Ø«Ø§Ù„: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø© (ÙŠØªØ·Ù„Ø¨ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø®Ø§Øµ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
            # from core.database import engine
            # async with engine.connect() as conn:
            #     result = await conn.execute(text("SELECT count(*) FROM pg_stat_activity WHERE datname = :db_name"), {"db_name": settings.DB_NAME})
            #     active_connections = result.scalar_one()
            active_connections = 5 # Ù‚ÙŠÙ…Ø© ÙˆÙ‡Ù…ÙŠØ©
            DB_CONNECTIONS_ACTIVE.set(active_connections)
            logger.debug(f"Collected DB metrics: active connections={active_connections}")
        else:
            DB_CONNECTIONS_ACTIVE.set(0) # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØµÙ„Ø©
            logger.warning("DB connection failed during metrics collection.")
    except Exception as e:
        logger.error(f"Failed to collect DB metrics: {e}")

async def collect_redis_metrics():
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§ØªØµØ§Ù„ Redis.\"\"\"
    try:
        from core.cache import check_redis_connection, redis_client # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
        redis_connected = await check_redis_connection()
        if redis_connected and redis_client:
            info = await redis_client.info()
            connected_clients = info.get('connected_clients', 0)
            REDIS_CONNECTIONS_ACTIVE.set(connected_clients)
            logger.debug(f"Collected Redis metrics: connected clients={connected_clients}")
        else:
            REDIS_CONNECTIONS_ACTIVE.set(0)
            logger.warning("Redis connection failed during metrics collection.")
    except Exception as e:
        logger.error(f"Failed to collect Redis metrics: {e}")

async def collect_celery_metrics():
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Celery (Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©ØŒ Ù‚ÙŠØ¯ Ø§Ù„ØªÙ†ÙÙŠØ°).\"\"\"
    try:
        # ÙŠØªØ·Ù„Ø¨ Celery Inspect Ø£Ùˆ Flower API
        # For a basic example, we'll just set a dummy value
        pending_tasks = 0 # Dummy value
        PENDING_CELERY_TASKS.set(pending_tasks)
        logger.debug(f"Collected Celery metrics: pending tasks={pending_tasks}")
    except Exception as e:
        logger.error(f"Failed to collect Celery metrics: {e}")

def get_prometheus_metrics() -> bytes:
    \"\"\"ÙŠÙØ±Ø¬Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¨ØªÙ†Ø³ÙŠÙ‚ Prometheus.\"\"\"
    collect_system_metrics()
    # ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© async collect_db_metrics() Ùˆ collect_redis_metrics()
    # Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ ÙÙŠ Ø®Ù„ÙÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø£Ùˆ Ù…Ù† Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© /metrics
    return generate_latest()

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    import asyncio
    import logging
    from core.config import Settings
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    class MockSettingsForMetrics(Settings):
        LOG_LEVEL = "DEBUG"
        DB_HOST = "localhost" # Ù„ØªÙ…ÙƒÙŠÙ† check_database_connection
        DB_NAME = "eduverseai_test_metrics"
        REDIS_HOST = "localhost" # Ù„ØªÙ…ÙƒÙŠÙ† check_redis_connection
        # For actual tests, ensure real DB/Redis are running or mock deeply

    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆÙ‡Ù…ÙŠØ©
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForMetrics()})()

    async def run_metrics_collector_test():
        print("--- Testing Metrics Collection ---")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ø¸Ø§Ù…
        collect_system_metrics()
        print("System metrics collected.")

        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠØªØ·Ù„Ø¨ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¹Ù…Ù„ ÙØ¹Ù„Ø§Ù‹ Ø£Ùˆ Ù…Ø­Ø§ÙƒØ§Ø© Ø£Ø¹Ù…Ù‚
        print("\\nAttempting to collect DB metrics (may fail if no DB running)...")
        await collect_db_metrics()
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Redis
        # Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ Ø³ÙŠØªØ·Ù„Ø¨ Redis ÙŠØ¹Ù…Ù„ ÙØ¹Ù„Ø§Ù‹ Ø£Ùˆ Ù…Ø­Ø§ÙƒØ§Ø© Ø£Ø¹Ù…Ù‚
        print("\\nAttempting to collect Redis metrics (may fail if no Redis running)...")
        await collect_redis_metrics()

        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Celery
        print("\\nCollecting Celery metrics (mocked)...")
        await collect_celery_metrics()

        # Ø§Ø®ØªØ¨Ø§Ø± ØªØ¬Ù…ÙŠØ¹ Prometheus
        print("\\nGenerating Prometheus metrics exposure text...")
        metrics_text = get_prometheus_metrics().decode('utf-8')
        print(metrics_text[:500] + "...") # Ø·Ø¨Ø§Ø¹Ø© Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³

        # Ø²ÙŠØ§Ø¯Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ø§Ø®ØªØ¨Ø§Ø±Ù‡Ø§
        REQUESTS_TOTAL.labels(method='GET', endpoint='/health', status='200').inc()
        DB_QUERIES_TOTAL.labels(type='select', status='success').inc(5)
        AI_REQUESTS_TOTAL.labels(service='summarize', status='success').inc()
        USER_LOGINS_TOTAL.labels(status='success').inc()
        USER_LOGINS_TOTAL.labels(status='failed').inc()
        
        ACTIVE_USERS.set(15)
        
        # ØªØ³Ø¬ÙŠÙ„ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© (latency)
        with REQUEST_LATENCY_SECONDS.labels(endpoint='/api/v1/courses').time():
            time.sleep(0.05)
        with DB_QUERY_LATENCY_SECONDS.labels(type='insert').time():
            time.sleep(0.01)

        print("\\nMetrics after incrementing:")
        metrics_text_after_inc = get_prometheus_metrics().decode('utf-8')
        print(metrics_text_after_inc[:500] + "...")

        print("\\nMetrics collection test completed.")

    asyncio.run(run_metrics_collector_test())
"""
    file_path = os.path.join(monitoring_path, "performance", "metrics_collector.py")
    return write_file_safely(file_path, content)

def create_monitoring_performance_performance_monitor_py():
    """Ø¥Ù†Ø´Ø§Ø¡ monitoring/performance/performance_monitor.py"""
    content = """from collections import deque
import time
from typing import Dict, Any, Deque
from utils.logger import get_logger
from core.config import settings

logger = get_logger(__name__)

class PerformanceMonitor:
    def __init__(self, history_size: int = 100):
        self.request_latencies: Deque[float] = deque(maxlen=history_size)
        self.db_latencies: Deque[float] = deque(maxlen=history_size)
        self.ai_latencies: Deque[float] = deque(maxlen=history_size)
        self.error_rates: Dict[str, Deque[int]] = {
            'http': deque(maxlen=history_size),
            'db': deque(maxlen=history_size),
            'ai': deque(maxlen=history_size)
        }
        self.last_cpu_time = None
        self.last_disk_io_time = None
        
        logger.info("PerformanceMonitor initialized.")

    def record_request_latency(self, latency: float):
        \"\"\"ÙŠØ³Ø¬Ù„ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø·Ù„Ø¨ HTTP.\"\"\"
        self.request_latencies.append(latency)
        logger.debug(f"Recorded request latency: {latency:.4f}s")

    def record_db_latency(self, latency: float):
        \"\"\"ÙŠØ³Ø¬Ù„ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\"\"\"
        self.db_latencies.append(latency)
        logger.debug(f"Recorded DB query latency: {latency:.4f}s")

    def record_ai_latency(self, latency: float):
        \"\"\"ÙŠØ³Ø¬Ù„ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.\"\"\"
        self.ai_latencies.append(latency)
        logger.debug(f"Recorded AI inference latency: {latency:.4f}s")

    def record_error(self, error_type: str):
        \"\"\"ÙŠØ³Ø¬Ù„ Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ Ù„Ù†ÙˆØ¹ Ù…Ø¹ÙŠÙ†.\"\"\"
        if error_type in self.error_rates:
            self.error_rates[error_type].append(1)
            logger.debug(f"Recorded {error_type} error.")
        else:
            logger.warning(f"Attempted to record unknown error type: {error_type}")

    def get_average_latency(self, latency_type: str = 'request') -> float:
        \"\"\"ÙŠØ­Ø³Ø¨ Ù…ØªÙˆØ³Ø· Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù†ÙˆØ¹ Ù…Ø¹ÙŠÙ†.\"\"\"
        if latency_type == 'request':
            data = self.request_latencies
        elif latency_type == 'db':
            data = self.db_latencies
        elif latency_type == 'ai':
            data = self.ai_latencies
        else:
            return 0.0 # Ù†ÙˆØ¹ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ

        if not data:
            return 0.0
        return sum(data) / len(data)

    def get_error_rate(self, error_type: str) -> float:
        \"\"\"ÙŠØ­Ø³Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ Ù„Ù†ÙˆØ¹ Ù…Ø¹ÙŠÙ†.\"\"\"
        if error_type not in self.error_rates or not self.error_rates[error_type]:
            return 0.0
        return sum(self.error_rates[error_type]) / len(self.error_rates[error_type])

    def get_current_metrics(self) -> Dict[str, Any]:
        \"\"\"
        ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø­ÙˆÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©.
        ÙŠÙ…ÙƒÙ† ØªÙˆØ³ÙŠØ¹ Ù‡Ø°Ø§ Ù„ÙŠØ´Ù…Ù„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ (CPU, RAM, Disk I/O, Network)
        Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© Ù…Ø«Ù„ `psutil`.
        \"\"\"
        metrics = {
            "average_request_latency_s": self.get_average_latency('request'),
            "average_db_latency_s": self.get_average_latency('db'),
            "average_ai_latency_s": self.get_average_latency('ai'),
            "http_error_rate": self.get_error_rate('http'),
            "db_error_rate": self.get_error_rate('db'),
            "ai_error_rate": self.get_error_rate('ai'),
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        }
        logger.debug("Generated current performance metrics.")
        return metrics

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.config import Settings

    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    class MockSettingsForMonitor(Settings):
        LOG_LEVEL = "DEBUG"
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForMonitor()})()
    
    monitor = PerformanceMonitor(history_size=10)

    async def simulate_traffic():
        print("--- Simulating Performance Monitoring Data ---")
        for i in range(20):
            # Simulate request latency
            req_latency = 0.05 + (i % 5) * 0.01
            monitor.record_request_latency(req_latency)
Ù‡â€
            # Simulate DB latency
            db_latency = 0.01 + (i % 3) * 0.005
            monitor.record_db_latency(db_latency)

            # Simulate AI latency
            ai_latency = 0.1 + (i % 4) * 0.02
            monitor.record_ai_latency(ai_latency)

            # Simulate occasional errors
            if i % 7 == 0:
                monitor.record_error('http')
            if i % 11 == 0:
                monitor.record_error('db')
            if i % 13 == 0:
                monitor.record_error('ai')

            if i % 5 == 0:
                metrics = monitor.get_current_metrics()
                print(f"[{i+1}/20] Current Metrics: {metrics}")
            
            await asyncio.sleep(0.01) # Simulate some time passing

        print("\\n--- Final Performance Metrics ---")
        final_metrics = monitor.get_current_metrics()
        for key, value in final_metrics.items():
            print(f"{key}: {value:.4f}")
        
        # ØªØ­Ù‚Ù‚ Ø¨Ø³ÙŠØ·
        assert monitor.get_average_latency('request') > 0
        assert monitor.get_error_rate('http') >= 0

    asyncio.run(simulate_traffic())
```

```
file_path = os.path.join(monitoring_path, "performance", "performance_monitor.py")
return write_file_safely(file_path, content)
```

def create\_monitoring\_performance\_alert\_system\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ monitoring/performance/alert\_system.py"""
content = """from typing import Dict, Any
from utils.logger import get\_logger
from services.notification\_service import NotificationService \# Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
from core.config import settings
import asyncio \# Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ù„Ù‚Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø« (event loop)

logger = get\_logger(**name**)

class AlertSystem:
def **init**(self, notification\_service: NotificationService = None):
self.notification\_service = notification\_service if notification\_service else NotificationService()
self.alerts\_history: Dict[str, Any] = {} \# Ù„ØªØªØ¨Ø¹ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª (ØªÙ… Ø¥Ø·Ù„Ø§Ù‚Ù‡Ø§ØŒ ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯)
self.alert\_thresholds = {
"cpu\_high": {"threshold": 80, "cooldown\_minutes": 5, "last\_alert": None}, \# %
"memory\_high": {"threshold": 85, "cooldown\_minutes": 5, "last\_alert": None}, \# %
"http\_error\_rate\_high": {"threshold": 0.05, "cooldown\_minutes": 2, "last\_alert": None}, \# 5%
"db\_latency\_high": {"threshold": 0.5, "cooldown\_minutes": 3, "last\_alert": None}, \# seconds
"redis\_unreachable": {"cooldown\_minutes": 10, "last\_alert": None},
"db\_unreachable": {"cooldown\_minutes": 10, "last\_alert": None},
"ai\_service\_unreachable": {"cooldown\_minutes": 10, "last\_alert": None},
"disk\_full": {"threshold": 90, "cooldown\_minutes": 10, "last\_alert": None}, \# %
"critical\_log\_event": {"cooldown\_minutes": 1, "last\_alert": None}, \# Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹ØªØ¨Ø© Ø±Ù‚Ù…ÙŠØ©
}
logger.info("AlertSystem initialized with default thresholds.")

```
def _should_send_alert(self, alert_name: str) -> bool:
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙØªØ±Ø© Ø§Ù„ØªÙ‡Ø¯Ø¦Ø©.\"\"\"
    now = time.time()
    alert_info = self.alert_thresholds.get(alert_name)
    if not alert_info:
        return False

    last_alert_time = alert_info.get("last_alert")
    cooldown_seconds = alert_info.get("cooldown_minutes", 0) * 60

    if last_alert_time is None or (now - last_alert_time > cooldown_seconds):
        alert_info["last_alert"] = now
        return True
    return False

async def _send_alert_notification(self, alert_name: str, message: str, severity: str = "critical"):
    \"\"\"ÙŠØ±Ø³Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ø¨Ø± Ø®Ø¯Ù…Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª.\"\"\"
    if self._should_send_alert(alert_name):
        subject = f"BTEC EduverseAI ALERT: {severity.upper()} - {alert_name.replace('_', ' ').title()}"
        body = f"Severity: {severity.upper()}\\nAlert: {alert_name}\\nTime: {datetime.now().isoformat()}\\nDetails: {message}\\n\\nPlease investigate immediately."
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (Ù„Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ†)
        if settings.ADMIN_EMAIL:
            await self.notification_service.send_email(settings.ADMIN_EMAIL, subject, body)
            logger.info(f"Alert email sent for {alert_name}.")
        
        # ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¯ÙØ¹ (Push Notification) Ù„Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ†
        # if settings.ADMIN_DEVICE_TOKENS:
        #     await self.notification_service.send_push_notification(settings.ADMIN_DEVICE_TOKENS, subject, message)

        logger.error(f"ALERT TRIGGERED: {alert_name} - {message}")
    else:
        logger.debug(f"Alert {alert_name} is in cooldown period.")

async def check_cpu_usage(self, cpu_percent: float):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU.\"\"\"
    threshold = self.alert_thresholds["cpu_high"]["threshold"]
    if cpu_percent > threshold:
        await self._send_alert_notification(
            "cpu_high", 
            f"CPU usage is {cpu_percent:.2f}% which is above the threshold of {threshold}%."
        )

async def check_memory_usage(self, memory_percent: float):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©.\"\"\"
    threshold = self.alert_thresholds["memory_high"]["threshold"]
    if memory_percent > threshold:
        await self._send_alert_notification(
            "memory_high",
            f"Memory usage is {memory_percent:.2f}% which is above the threshold of {threshold}%."
        )
        
async def check_http_error_rate(self, error_rate: float):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ø¯Ù„ Ø®Ø·Ø£ HTTP.\"\"\"
    threshold = self.alert_thresholds["http_error_rate_high"]["threshold"]
    if error_rate > threshold:
        await self._send_alert_notification(
            "http_error_rate_high",
            f"HTTP error rate is {error_rate:.2f} which is above the threshold of {threshold:.2f}."
        )

async def check_db_connection(self, is_connected: bool):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.\"\"\"
    if not is_connected:
        await self._send_alert_notification("db_unreachable", "Database is not reachable.", severity="critical")
    
    # ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Ù„Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØªØ§Ø­Ø§Ù‹ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡
    # ÙˆØ¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± "Ø§Ø³ØªØ¹Ø§Ø¯Ø©"

async def check_redis_connection(self, is_connected: bool):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ Redis.\"\"\"
    if not is_connected:
        await self._send_alert_notification("redis_unreachable", "Redis is not reachable.", severity="critical")

async def check_ai_service_status(self, is_available: bool):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©.\"\"\"
    if not is_available:
        await self._send_alert_notification("ai_service_unreachable", "External AI service is unreachable or failing.", severity="high")
        
async def check_disk_usage(self, disk_usage_percent: float):
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù‚Ø±Øµ.\"\"\"
    threshold = self.alert_thresholds["disk_full"]["threshold"]
    if disk_usage_percent > threshold:
        await self._send_alert_notification(
            "disk_full",
            f"Disk usage is {disk_usage_percent:.2f}% which is above the threshold of {threshold}%."
        )

async def process_log_event(self, log_level: str, message: str):
    \"\"\"ÙŠØ¹Ø§Ù„Ø¬ Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø³Ø¬Ù„ ÙˆÙŠØ·Ù„Ù‚ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù„Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø­Ø±Ø¬Ø©.\"\"\"
    if log_level.upper() in ["ERROR", "CRITICAL"]:
        # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªØ§Ø¬ Ù„ØªÙ†Ø¨ÙŠÙ‡ Ù…Ø­Ø¯Ø¯
        if "database connection failed" in message.lower():
            await self._send_alert_notification("db_unreachable", message, severity="critical")
        elif "authentication failure" in message.lower():
            await self._send_alert_notification("security_alert", message, severity="high")
        elif "out of memory" in message.lower():
            await self._send_alert_notification("memory_high", message, severity="critical")
        else:
            await self._send_alert_notification("critical_log_event", message, severity="error")
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
import asyncio
import logging
from datetime import datetime, timedelta
import time
from core.config import Settings
from services.notification\_service import NotificationService

```
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù€ AlertSystem
class MockSettingsForAlert(Settings):
    LOG_LEVEL = "INFO"
    ADMIN_EMAIL = "admin@example.com" # Ù„Ù„ØªØ¬Ø±ÙŠØ¨
    # Ù„Ø§ ØªØ¶Ø¹ Ù…ÙØ§ØªÙŠØ­ Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù‡Ù†Ø§
    EMAIL_USER = "mock_email@example.com"
    EMAIL_PASSWORD = "mock_password"
    SMTP_SERVER = "smtp.mock.com"
    SMTP_PORT = 587
    PUSH_NOTIFICATIONS_API_KEY = "mock_key"

import sys
sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForAlert()})()

async def run_alert_system_test():
    print("--- Testing Alert System ---")
    
    # ØªÙ‡ÙŠØ¦Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª (Ù‚Ø¯ ØªÙƒÙˆÙ† mock Ù„Ø¹Ø¯Ù… Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ø¦Ù„ Ø­Ù‚ÙŠÙ‚ÙŠØ©)
    notification_service = NotificationService()
    alert_system = AlertSystem(notification_service)

    # 1. Ø§Ø®ØªØ¨Ø§Ø± CPU Ø¹Ø§Ù„ÙŠ (Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ ÙˆØ§Ø­Ø¯)
    print("\\nTesting high CPU usage (should alert once)...")
    await alert_system.check_cpu_usage(90.0) # ÙÙˆÙ‚ Ø§Ù„Ø¹ØªØ¨Ø© 80%
    await alert_system.check_cpu_usage(92.0) # Ù„Ù† ÙŠØ±Ø³Ù„ ØªÙ†Ø¨ÙŠÙ‡Ù‹Ø§ Ø¢Ø®Ø± Ø¨Ø³Ø¨Ø¨ Ø§Ù„ØªÙ‡Ø¯Ø¦Ø©
    await asyncio.sleep(alert_system.alert_thresholds["cpu_high"]["cooldown_minutes"] * 60 + 1) # Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„ØªÙ‡Ø¯Ø¦Ø©
    await alert_system.check_cpu_usage(95.0) # ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ±Ø³Ù„ ØªÙ†Ø¨ÙŠÙ‡Ù‹Ø§ Ø¢Ø®Ø±
    
    # 2. Ø§Ø®ØªØ¨Ø§Ø± ÙØ´Ù„ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("\\nTesting DB connection failure (should alert)...")
    await alert_system.check_db_connection(False)
    await alert_system.check_db_connection(False) # Ù„Ù† ÙŠØ±Ø³Ù„ ØªÙ†Ø¨ÙŠÙ‡Ù‹Ø§ Ø¢Ø®Ø±

    # 3. Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø¯Ø« Ø³Ø¬Ù„ Ø­Ø±Ø¬
    print("\\nTesting critical log event (should alert)...")
    await alert_system.process_log_event("ERROR", "Database connection lost unexpectedly.")
    await alert_system.process_log_event("CRITICAL", "Server out of memory.")
    
    # 4. Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø¯Ù„ Ø®Ø·Ø£ HTTP Ù…Ø±ØªÙØ¹
    print("\\nTesting high HTTP error rate (should alert)...")
    await alert_system.check_http_error_rate(0.06) # ÙÙˆÙ‚ Ø§Ù„Ø¹ØªØ¨Ø© 0.05
    
    # 5. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø±Øµ Ø§Ù„ÙƒØ§Ù…Ù„
    print("\\nTesting high disk usage (should alert)...")
    await alert_system.check_disk_usage(91.0) # ÙÙˆÙ‚ Ø§Ù„Ø¹ØªØ¨Ø© 90%

    print("\\nAlert System tests completed. Check logs for alert messages.")

asyncio.run(run_alert_system_test())
```

"""
file\_path = os.path.join(monitoring\_path, "performance", "alert\_system.py")
return write\_file\_safely(file\_path, content)

def create\_monitoring\_quality\_quality\_assurance\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ monitoring/quality/quality\_assurance.py"""
content = """from typing import List, Dict, Any, Tuple
import re
from utils.logger import get\_logger
from services.ai\_service import AIService \# Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ QA

logger = get\_logger(**name**)

class QualityAssurance:
def **init**(self, ai\_service: AIService = None):
self.ai\_service = ai\_service
logger.info("QualityAssurance service initialized.")

```
async def analyze_text_quality(self, text: str) -> Dict[str, Any]:
    \"\"\"
    ÙŠØ­Ù„Ù„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ø­ÙŠØ« Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŒ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI).
    ÙŠØªØ·Ù„Ø¨ AI Service.
    \"\"\"
    if not self.ai_service:
        logger.warning("AI Service not available for text quality analysis. Returning basic analysis.")
        return self._basic_text_analysis(text)

    logger.info(f"Analyzing text quality using AI for text: {text[:50]}...")
    prompt = f\"\"\"Analyze the quality of the following text.
    Provide a readability score (e.g., Flesch-Kincaid scale - conceptual), identify any grammatical errors, suggest improvements, and estimate the sentiment.
    Return the result as a JSON object with keys: "readability_score" (float), "grammar_issues" (list of strings), "suggestions" (list of strings), "sentiment" (string - e.g., "positive", "neutral", "negative").
    Text:
    {text}
    \"\"\"
    try:
        ai_response_str = await self.ai_service.generate_text(prompt, max_tokens=700, temperature=0.2)
        import json
        try:
            ai_analysis = json.loads(ai_response_str)
            logger.info("AI text quality analysis successful.")
            return ai_analysis
        except json.JSONDecodeError:
            logger.warning(f"AI returned invalid JSON for text quality: {ai_response_str[:200]}...")
            return {"error": "AI response was not valid JSON.", "raw_response": ai_response_str, **self._basic_text_analysis(text)}
    except Exception as e:
        logger.error(f"AI text quality analysis failed: {e}. Falling back to basic analysis.")
        return self._basic_text_analysis(text)

def _basic_text_analysis(self, text: str) -> Dict[str, Any]:
    \"\"\"ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø£Ø³Ø§Ø³ÙŠ Ø¨Ø¯ÙˆÙ† AI.\"\"\"
    num_words = len(text.split())
    num_sentences = len(re.split(r'[.!?]\\s*', text))
    
    readability_score = 0.0
    if num_sentences > 0:
        readability_score = 206.835 - 1.015 * (num_words / num_sentences) # Flesch Reading Ease (simplified)

    return {
        "readability_score": round(readability_score, 2),
        "word_count": num_words,
        "sentence_count": num_sentences,
        "grammar_issues": ["Basic grammar check requires advanced NLP library or AI."],
        "suggestions": ["Consider using shorter sentences for better readability.", "Check for typos."],
        "sentiment": "neutral" # Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ø¯Ù‚Ø© Ø¨Ø¯ÙˆÙ† AI
    }

async def check_plagiarism(self, text1: str, text2: str) -> Dict[str, Any]:
    \"\"\"
    ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„ Ø¨ÙŠÙ† Ù†ØµÙŠÙ†.
    ÙÙŠ Ø¨ÙŠØ¦Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©ØŒ Ø³ÙŠØªØ·Ù„Ø¨ Ù‡Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ AI Ù…ØªØ®ØµØµØ© Ø£Ùˆ APIs Ø®Ø§Ø±Ø¬ÙŠØ©.
    \"\"\"
    if not self.ai_service:
        logger.warning("AI Service not available for plagiarism check. Returning dummy result.")
        return {"similarity_score": 0.0, "is_plagiarized": False, "detail": "AI service required for proper plagiarism check."}

    logger.info(f"Checking plagiarism between two texts using AI (first 50 chars of each): '{text1[:50]}...' vs '{text2[:50]}...'")
    prompt = f\"\"\"Analyze the semantic similarity between the two texts provided below.
    Determine a similarity score (0.0 to 1.0, where 1.0 is identical) and state whether plagiarism is likely based on significant overlap.
    Return a JSON object with keys: "similarity_score" (float), "is_plagiarized" (boolean), "explanation" (string).
    
    Text 1:
    {text1}
    
    Text 2:
    {text2}
    \"\"\"
    try:
        ai_response_str = await self.ai_service.generate_text(prompt, max_tokens=500, temperature=0.1)
        import json
        try:
            ai_analysis = json.loads(ai_response_str)
            logger.info("AI plagiarism check successful.")
            return ai_analysis
        except json.JSONDecodeError:
            logger.warning(f"AI returned invalid JSON for plagiarism check: {ai_response_str[:200]}...")
            return {"similarity_score": 0.0, "is_plagiarized": False, "detail": "AI response was not valid JSON.", "raw_response": ai_response_str}
    except Exception as e:
        logger.error(f"AI plagiarism check failed: {e}. Returning dummy result.")
        return {"similarity_score": 0.0, "is_plagiarized": False, "detail": "AI service encountered an error."}

def validate_course_structure(self, course_data: Dict[str, Any]) -> Tuple[bool, List[str]]:
    \"\"\"ÙŠØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø±Ø±.\"\"\"
    errors = []
    if not isinstance(course_data, dict):
        errors.append("Course data must be a dictionary.")
        return False, errors
    
    required_fields = ["title", "description", "creator_id", "status"]
    for field in required_fields:
        if field not in course_data or not course_data[field]:
            errors.append(f"Missing or empty required field: '{field}'.")
    
    if not isinstance(course_data.get("title"), str) or len(course_data["title"]) < 5:
        errors.append("Course title must be a string and at least 5 characters long.")
    
    # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù‡Ù†Ø§ (Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ØŒ Ø§Ù„Ø­Ø¯ÙˆØ¯ØŒ Ø¥Ù„Ø®)
    
    if errors:
        logger.warning(f"Course structure validation failed: {errors}")
        return False, errors
    logger.info("Course structure validation successful.")
    return True, []
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
import asyncio
import logging
from core.config import Settings
from services.ai\_service import AIService \# Ù„Ù„Ø­Ù‚Ù† ÙÙŠ QA

```
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class MockSettingsForQA(Settings):
    LOG_LEVEL = "INFO"
    AI_PROVIDER = os.environ.get("AI_PROVIDER_TEST", "openai").lower() # 'openai' or 'anthropic'
    OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY_TEST", "sk-mock-openai-key") # Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙØªØ§Ø­ Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙØ¹Ù„ÙŠ
    OPENAI_MODEL = "gpt-3.5-turbo"
    ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY_TEST", "sk-mock-anthropic-key")
    ANTHROPIC_MODEL = "claude-3-haiku-20240307"
    AI_SERVICE_TIMEOUT = 30.0

import sys
sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForQA()})()

# ØªÙ‡ÙŠØ¦Ø© AI Service (Ù‚Ø¯ ØªÙƒÙˆÙ† mock Ù„Ø¹Ø¯Ù… Ø¥Ø¬Ø±Ø§Ø¡ Ù…ÙƒØ§Ù„Ù…Ø§Øª API Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªØªÙˆÙØ± Ù…ÙØ§ØªÙŠØ­)
ai_service_instance = AIService()
qa_service = QualityAssurance(ai_service=ai_service_instance)

async def run_qa_tests():
    print("--- Testing Quality Assurance Service ---")

    # 1. Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Øµ
    print("\\nTesting text quality analysis...")
    text_to_analyze = "This is a simple sentence. It has good readability. However, some grammer issues might be present."
    
    # Ù‡Ø°Ø§ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØªØ§Ø­ AI API Ø­Ù‚ÙŠÙ‚ÙŠÙ‹Ø§
    if "mock" not in ai_service_instance.openai_api_key and "mock" not in ai_service_instance.anthropic_api_key:
        analysis_result = await qa_service.analyze_text_quality(text_to_analyze)
        print(f"Text Quality Analysis (AI): {analysis_result}")
        assert "readability_score" in analysis_result
    else:
        print("Skipping AI text quality analysis: AI API keys are mocked. Running basic analysis.")
        basic_analysis_result = await qa_service.analyze_text_quality(text_to_analyze) # Ø³ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        print(f"Text Quality Analysis (Basic): {basic_analysis_result}")
        assert "readability_score" in basic_analysis_result

    # 2. Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„
    print("\\nTesting plagiarism check...")
    text_orig = "Artificial intelligence is a rapidly developing field that is transforming various industries."
    text_plagiarized = "AI is a fast-growing field that is changing many sectors quickly." # A slightly rephrased version
    text_unrelated = "The capital of France is Paris, a beautiful city."

    if "mock" not in ai_service_instance.openai_api_key and "mock" not in ai_service_instance.anthropic_api_key:
        plagiarism_result1 = await qa_service.check_plagiarism(text_orig, text_plagiarized)
        print(f"Plagiarism Check (similar): {plagiarism_result1}")
        assert plagiarism_result1.get("similarity_score", 0.0) > 0.5 # Expect some similarity

        plagiarism_result2 = await qa_service.check_plagiarism(text_orig, text_unrelated)
        print(f"Plagiarism Check (unrelated): {plagiarism_result2}")
        assert plagiarism_result2.get("similarity_score", 1.0) < 0.5 # Expect low similarity
    else:
        print("Skipping AI plagiarism check: AI API keys are mocked. Returning dummy results.")
        dummy_res1 = await qa_service.check_plagiarism(text_orig, text_plagiarized)
        print(f"Plagiarism Check (similar - mock): {dummy_res1}")
        dummy_res2 = await qa_service.check_plagiarism(text_orig, text_unrelated)
        print(f"Plagiarism Check (unrelated - mock): {dummy_res2}")

    # 3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±
    print("\\nTesting course structure validation...")
    valid_course = {"title": "Valid Course", "description": "Desc", "creator_id": 1, "status": "draft"}
    is_valid, errors = qa_service.validate_course_structure(valid_course)
    print(f"Valid course check: Is Valid={is_valid}, Errors={errors}")
    assert is_valid and not errors

    invalid_course1 = {"title": "Short", "creator_id": 1} # Missing description, short title
    is_valid, errors = qa_service.validate_course_structure(invalid_course1)
    print(f"Invalid course check 1: Is Valid={is_valid}, Errors={errors}")
    assert not is_valid and len(errors) > 0

    invalid_course2 = {"description": "Only desc"} # Missing title, creator_id, status
    is_valid, errors = qa_service.validate_course_structure(invalid_course2)
    print(f"Invalid course check 2: Is Valid={is_valid}, Errors={errors}")
    assert not is_valid and len(errors) > 0

    print("\\nQuality Assurance tests completed (some dependent on live AI).")

asyncio.run(run_qa_tests())
```

"""
file\_path = os.path.join(monitoring\_path, "quality", "quality\_assurance.py")
return write\_file\_safely(file\_path, content)

def create\_monitoring\_quality\_automated\_testing\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ monitoring/quality/automated\_testing.py"""
content = """from typing import List, Dict, Any, Callable
import asyncio
from utils.logger import get\_logger

logger = get\_logger(**name**)

class AutomatedTestingSystem:
def **init**(self):
self.tests: List[Dict[str, Any]] = []
logger.info("AutomatedTestingSystem initialized.")

```
def add_test(self, name: str, test_function: Callable[..., bool], tags: List[str] = None, description: str = None):
    \"\"\"ÙŠØ¶ÙŠÙ Ø§Ø®ØªØ¨Ø§Ø±Ù‹Ø§ Ø¢Ù„ÙŠÙ‹Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù….\"\"\"
    if tags is None:
        tags = []
    self.tests.append({
        "name": name,
        "function": test_function,
        "tags": tags,
        "description": description or f"Automated test for {name}",
        "last_run_status": None,
        "last_run_time": None
    })
    logger.info(f"Added test: {name} (Tags: {', '.join(tags)})")

async def run_single_test(self, test_name: str) -> Dict[str, Any]:
    \"\"\"ÙŠØ´ØºÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ù‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ø³Ù…Ù‡.\"\"\"
    for test in self.tests:
        if test["name"] == test_name:
            logger.info(f"Running single test: {test_name}")
            start_time = asyncio.get_event_loop().time()
            try:
                result = await test["function"]()
                status = "PASSED" if result else "FAILED"
                message = "Test executed successfully." if result else "Test failed."
            except Exception as e:
                status = "ERROR"
                message = f"Test raised an exception: {e}"
                logger.exception(f"Test '{test_name}' encountered an error.")
            end_time = asyncio.get_event_loop().time()
            duration = end_time - start_time
            
            test["last_run_status"] = status
            test["last_run_time"] = datetime.now().isoformat()
            test_result = {
                "name": test_name,
                "status": status,
                "message": message,
                "duration_s": round(duration, 4),
                "timestamp": datetime.now().isoformat()
            }
            logger.info(f"Test '{test_name}' finished with status: {status}")
            return test_result
    
    logger.warning(f"Test '{test_name}' not found.")
    return {"name": test_name, "status": "NOT_FOUND", "message": "Test not found.", "duration_s": 0}

async def run_tests_by_tag(self, tag: str) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ´ØºÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø© Ù…Ø¹ÙŠÙ†Ø©.\"\"\"
    results = []
    logger.info(f"Running tests with tag: {tag}")
    for test in self.tests:
        if tag in test["tags"]:
            result = await self.run_single_test(test["name"])
            results.append(result)
    logger.info(f"Finished running tests with tag '{tag}'. Total {len(results)} tests.")
    return results

async def run_all_tests(self) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ´ØºÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©.\"\"\"
    results = []
    logger.info("Running all automated tests.")
    for test in self.tests:
        result = await self.run_single_test(test["name"])
        results.append(result)
    logger.info(f"Finished running all automated tests. Total {len(results)} tests.")
    return results
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø¯ÙˆØ§Ù„ Ø§Ø®ØªØ¨Ø§Ø± ÙˆÙ‡Ù…ÙŠØ©

async def dummy\_db\_connection\_test():
await asyncio.sleep(0.02) \# Simulate async operation
return True \# Simulate success

async def dummy\_api\_response\_test():
await asyncio.sleep(0.03)
\# Simulate a failure occasionally
if random.random() \< 0.1: \# 10% chance of failure
logger.warning("Simulated API test failure.")
return False
return True

async def dummy\_ai\_integration\_test():
await asyncio.sleep(0.05)
\# Simulate a more complex scenario
if random.random() \< 0.05: \# 5% chance of error
raise ValueError("AI model not responding.")
return True

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
import asyncio
import logging
import random
from datetime import datetime \# Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹Ø±ÙŠÙ datetime

```
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø± Ù„Ù€ logger)
class MockSettingsForTest(object): # ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙƒØ§Ø¦Ù†Ù‹Ø§ Ø¨Ø³ÙŠØ·Ù‹Ø§ Ù„Ù€ logger.py
    LOG_LEVEL = "INFO"
    LOG_TO_FILE = False
    LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import sys
sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForTest()})()

async def run_automated_testing_system_tests():
    print("--- Testing Automated Testing System ---")
    
    ats = AutomatedTestingSystem()

    # Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    ats.add_test("DB_Connectivity_Test", dummy_db_connection_test, tags=["unit", "database"], description="Checks if database is reachable.")
    ats.add_test("API_Health_Endpoint_Test", dummy_api_response_test, tags=["integration", "api", "health"], description="Checks API health endpoint response.")
    ats.add_test("AI_Summarization_Functional_Test", dummy_ai_integration_test, tags=["e2e", "ai", "feature"], description="Tests AI summarization functionality.")
    
    # ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ø­Ø¯
    print("\\nRunning single test 'DB_Connectivity_Test':")
    result = await ats.run_single_test("DB_Connectivity_Test")
    print(f"Result: {result}")
    assert result["status"] == "PASSED"

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù„Ø§Ù…Ø©
    print("\\nRunning tests with tag 'api':")
    api_results = await ats.run_tests_by_tag("api")
    for res in api_results:
        print(f"  - {res['name']}: {res['status']} ({res['duration_s']:.4f}s)")
    assert len(api_results) > 0

    # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    print("\\nRunning all tests:")
    all_results = await ats.run_all_tests()
    for res in all_results:
        print(f"  - {res['name']}: {res['status']} ({res['duration_s']:.4f}s)")
    assert len(all_results) == 3 # 3 tests added

    print("\\nAutomated Testing System tests completed.")

asyncio.run(run_automated_testing_system_tests())
```

"""
file\_path = os.path.join(monitoring\_path, "quality", "automated\_testing.py")
return write\_file\_safely(file\_path, content)

def create\_monitoring\_diagnostics\_system\_diagnostics\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ monitoring/diagnostics/system\_diagnostics.py"""
content = """import psutil
import platform
import socket
from datetime import datetime
from typing import Dict, Any, List
from utils.logger import get\_logger
import os

logger = get\_logger(**name**)

class SystemDiagnostics:
def **init**(self):
logger.info("SystemDiagnostics initialized.")

```
def get_cpu_info(self) -> Dict[str, Any]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª CPU.\"\"\"
    try:
        return {
            "cpu_count": psutil.cpu_count(logical=False),
            "cpu_count_logical": psutil.cpu_count(logical=True),
            "cpu_percent_overall": psutil.cpu_percent(interval=0.1), # Blocking call for a short interval
            "cpu_per_core": psutil.cpu_percent(interval=0.1, percpu=True),
            "cpu_frequency_mhz": psutil.cpu_freq().current if psutil.cpu_freq() else None,
        }
    except Exception as e:
        logger.error(f"Error collecting CPU info: {e}")
        return {"error": str(e)}

def get_memory_info(self) -> Dict[str, Any]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© (RAM).\"\"\"
    try:
        mem = psutil.virtual_memory()
        return {
            "total_gb": round(mem.total / (1024**3), 2),
            "available_gb": round(mem.available / (1024**3), 2),
            "used_gb": round(mem.used / (1024**3), 2),
            "percent_used": mem.percent,
        }
    except Exception as e:
        logger.error(f"Error collecting memory info: {e}")
        return {"error": str(e)}

def get_disk_info(self) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø±Øµ.\"\"\"
    disk_partitions = []
    try:
        for partition in psutil.disk_partitions():
            if 'cdrom' in partition.opts or partition.fstype == '':
                continue
            try:
                usage = psutil.disk_usage(partition.mountpoint)
                disk_partitions.append({
                    "device": partition.device,
                    "mountpoint": partition.mountpoint,
                    "fstype": partition.fstype,
                    "total_gb": round(usage.total / (1024**3), 2),
                    "used_gb": round(usage.used / (1024**3), 2),
                    "free_gb": round(usage.free / (1024**3), 2),
                    "percent_used": usage.percent,
                })
            except Exception as e:
                logger.warning(f"Could not get usage for partition {partition.mountpoint}: {e}")
        return disk_partitions
    except Exception as e:
        logger.error(f"Error collecting disk info: {e}")
        return [{"error": str(e)}]

def get_network_info(self) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©.\"\"\"
    net_io = psutil.net_io_counters(pernic=True)
    net_info = []
    try:
        for interface, stats in net_io.items():
            net_info.append({
                "interface": interface,
                "bytes_sent_mb": round(stats.bytes_sent / (1024**2), 2),
                "bytes_recv_mb": round(stats.bytes_recv / (1024**2), 2),
                "packets_sent": stats.packets_sent,
                "packets_recv": stats.packets_recv,
                "err_in": stats.errin,
                "err_out": stats.errout,
                "drop_in": stats.dropin,
                "drop_out": stats.dropout,
            })
        return net_info
    except Exception as e:
        logger.error(f"Error collecting network info: {e}")
        return [{"error": str(e)}]

def get_process_info(self, top_n: int = 5) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø£Ù‡Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU/Memory.\"\"\"
    processes = []
    try:
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent', 'cmdline']):
            try:
                processes.append({
                    "pid": proc.info['pid'],
                    "name": proc.info['name'],
                    "cpu_percent": proc.info['cpu_percent'],
                    "memory_percent": round(proc.info['memory_percent'], 2),
                    "cmdline": " ".join(proc.info['cmdline']) if proc.info['cmdline'] else proc.info['name'],
                })
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        
        # Sort by CPU usage descending
        processes.sort(key=lambda x: x.get('cpu_percent', 0.0), reverse=True)
        return processes[:top_n]
    except Exception as e:
        logger.error(f"Error collecting process info: {e}")
        return [{"error": str(e)}]

def get_system_overview(self) -> Dict[str, Any]:
    \"\"\"ÙŠØ¬Ù…Ø¹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù….\"\"\"
    try:
        boot_time_timestamp = psutil.boot_time()
        boot_time = datetime.fromtimestamp(boot_time_timestamp).isoformat()
        
        return {
            "timestamp": datetime.now().isoformat(),
            "os_name": platform.system(),
            "os_version": platform.release(),
            "machine_type": platform.machine(),
            "python_version": platform.python_version(),
            "hostname": socket.gethostname(),
            "uptime": str(timedelta(seconds=time.time() - boot_time_timestamp)).split('.')[0],
            "cpu": self.get_cpu_info(),
            "memory": self.get_memory_info(),
            "disk": self.get_disk_info(),
            "network": self.get_network_info(),
            "top_processes": self.get_process_info(top_n=settings.TOP_PROCESSES_TO_MONITOR),
        }
    except Exception as e:
        logger.error(f"Error getting system overview: {e}")
        return {"error": str(e)}
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
import asyncio
import logging
from core.config import Settings
from datetime import timedelta \# Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹Ø±ÙŠÙ timedelta

```
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class MockSettingsForDiag(Settings):
    LOG_LEVEL = "INFO"
    TOP_PROCESSES_TO_MONITOR = 3 # Ù„ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
    LOG_TO_FILE = False
    LOG_FILE_NAME = "test_diagnostics.log"
    LOG_MAX_BYTES = 1048576
    LOG_BACKUP_COUNT = 5
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import sys
sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForDiag()})()

diagnostics = SystemDiagnostics()

async def run_diagnostics_tests():
    print("--- Testing System Diagnostics ---")
    
    print("\\nFetching CPU Info:")
    cpu_info = diagnostics.get_cpu_info()
    print(f"CPU Count: {cpu_info.get('cpu_count')}, Usage: {cpu_info.get('cpu_percent_overall')}%")
    
    print("\\nFetching Memory Info:")
    memory_info = diagnostics.get_memory_info()
    print(f"Memory Total: {memory_info.get('total_gb')}GB, Used: {memory_info.get('percent_used')}%")
    
    print("\\nFetching Disk Info:")
    disk_info = diagnostics.get_disk_info()
    for disk in disk_info:
        print(f"  Device: {disk.get('device')}, Used: {disk.get('percent_used')}%")
    
    print("\\nFetching Network Info:")
    network_info = diagnostics.get_network_info()
    for net in network_info:
        print(f"  Interface: {net.get('interface')}, Sent: {net.get('bytes_sent_mb')}MB, Recv: {net.get('bytes_recv_mb')}MB")

    print("\\nFetching Top Processes (first 3):")
    process_info = diagnostics.get_process_info(top_n=3)
    for proc in process_info:
        print(f"  PID: {proc.get('pid')}, Name: {proc.get('name')}, CPU: {proc.get('cpu_percent')}%, Mem: {proc.get('memory_percent')}%")
    
    print("\\nFetching Full System Overview:")
    overview = diagnostics.get_system_overview()
    # Ø·Ø¨Ø§Ø¹Ø© Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù„ØªØ¬Ù†Ø¨ Ø¥Ø®Ø±Ø§Ø¬ ÙƒØ¨ÙŠØ± Ø¬Ø¯Ù‹Ø§
    print(f"OS: {overview.get('os_name')} {overview.get('os_version')}")
    print(f"Hostname: {overview.get('hostname')}")
    print(f"Uptime: {overview.get('uptime')}")
    print(f"CPU Usage (overall): {overview.get('cpu', {}).get('cpu_percent_overall')}%")
    print(f"Memory Usage (overall): {overview.get('memory', {}).get('percent_used')}%")
    
    print("\\nSystem Diagnostics tests completed. Review the output above.")

asyncio.run(run_diagnostics_tests())
```

"""
file\_path = os.path.join(monitoring\_path, "diagnostics", "system\_diagnostics.py")
return write\_file\_safely(file\_path, content)

def create\_monitoring\_diagnostics\_error\_tracker\_py():
"""Ø¥Ù†Ø´Ø§Ø¡ monitoring/diagnostics/error\_tracker.py"""
content = """from datetime import datetime
from typing import Dict, Any, List, Optional
from utils.logger import get\_logger
from core.config import settings
import json \# Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙƒÙ€ JSON Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±

logger = get\_logger(**name**)

class ErrorTracker:
def **init**(self, storage\_file: str = None):
\# ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Redis Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ…Ø±
self.errors\_in\_memory: List[Dict[str, Any]] = [] \# Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ÙÙˆØ±ÙŠ
self.max\_errors\_in\_memory = 100 \# Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
self.storage\_file = storage\_file if storage\_file else os.path.join(settings.BASE\_DIR, settings.ERROR\_LOG\_FILE)

```
    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¹Ù†Ø¯ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
    self._load_errors_from_file()
    logger.info(f"ErrorTracker initialized. Storing up to {self.max_errors_in_memory} errors in memory. Persistence: {self.storage_file}")

def _load_errors_from_file(self):
    \"\"\"ÙŠØ­Ø§ÙˆÙ„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù…Ù† Ù…Ù„Ù Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„.\"\"\"
    if os.path.exists(self.storage_file):
        try:
            with open(self.storage_file, 'r', encoding='utf-8') as f:
                self.errors_in_memory = json.load(f)
            logger.info(f"Loaded {len(self.errors_in_memory)} errors from {self.storage_file}")
            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ ÙÙ‚Ø· Ø¨Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            self.errors_in_memory = self.errors_in_memory[-self.max_errors_in_memory:]
        except Exception as e:
            logger.error(f"Failed to load errors from {self.storage_file}: {e}")
    else:
        logger.info(f"No existing error log file found at {self.storage_file}.")

def _save_errors_to_file(self):
    \"\"\"ÙŠØ­ÙØ¸ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªØ®Ø²ÙŠÙ†.\"\"\"
    try:
        with open(self.storage_file, 'w', encoding='utf-8') as f:
            json.dump(self.errors_in_memory, f, indent=2, ensure_ascii=False)
        logger.debug(f"Saved {len(self.errors_in_memory)} errors to {self.storage_file}")
    except Exception as e:
        logger.error(f"Failed to save errors to {self.storage_file}: {e}")

def track_error(self, 
                error_type: str, 
                message: str, 
                details: Optional[Dict[str, Any]] = None,
                level: str = "ERROR"):
    \"\"\"ÙŠØ³Ø¬Ù„ Ø®Ø·Ø£ Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….\"\"\"
    error_entry = {
        "timestamp": datetime.now().isoformat(),
        "level": level.upper(),
        "type": error_type,
        "message": message,
        "details": details or {}
    }
    
    self.errors_in_memory.append(error_entry)
    # Ø¥Ø²Ø§Ù„Ø© Ø£Ù‚Ø¯Ù… Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¥Ø°Ø§ ØªØ¬Ø§ÙˆØ²Ù†Ø§ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
    if len(self.errors_in_memory) > self.max_errors_in_memory:
        self.errors_in_memory.pop(0) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù‚Ø¯Ù…

    logger.log(getattr(logging, level.upper(), logging.ERROR), f"Tracked Error: {error_type} - {message}")
    self._save_errors_to_file() # Ø­ÙØ¸ Ø¨Ø¹Ø¯ ÙƒÙ„ ØªØªØ¨Ø¹ (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù„Ù„Ø­ÙØ¸ Ø§Ù„Ø¯ÙˆØ±ÙŠ)

def get_recent_errors(self, limit: int = 10) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ¬Ù„Ø¨ Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø³Ø¬Ù„Ø©.\"\"\"
    return list(self.errors_in_memory[-limit:])

def get_errors_by_type(self, error_type: str) -> List[Dict[str, Any]]:
    \"\"\"ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹.\"\"\"
    return [error for error in self.errors_in_memory if error["type"].lower() == error_type.lower()]

def clear_errors(self):
    \"\"\"ÙŠÙ…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ù…Ù„Ù.\"\"\"
    self.errors_in_memory = []
    if os.path.exists(self.storage_file):
        try:
            os.remove(self.storage_file)
            logger.info(f"Cleared error log file: {self.storage_file}")
        except Exception as e:
            logger.error(f"Failed to clear error log file {self.storage_file}: {e}")
    logger.info("All tracked errors cleared.")
```

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

if **name** == "**main**":
import asyncio
import logging
from core.config import Settings

```
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class MockSettingsForErrorTracker(Settings):
    LOG_LEVEL = "INFO"
    ERROR_LOG_FILE = "error_tracker_test.json"
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    LOG_TO_FILE = False # Ù„Ø§ ØªØ³Ø¬Ù„ Ù‡Ù†Ø§

import sys
sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForErrorTracker()})()

error_tracker = ErrorTracker() # Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹/error_tracker_test.json

async def run_error_tracker_tests():
    print("--- Testing Error Tracker ---")
    
    # Ù…Ø³Ø­ Ø£ÙŠ Ø£Ø®Ø·Ø§Ø¡ Ø³Ø§Ø¨Ù‚Ø© Ù…Ù† ØªØ´ØºÙŠÙ„ Ø³Ø§Ø¨Ù‚ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    error_tracker.clear_errors()
    print("Cleared previous errors for fresh test.")
    
    # ØªØªØ¨Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    error_tracker.track_error("DatabaseError", "Failed to connect to primary DB.", {"host": "db1", "port": 5432})
    error_tracker.track_error("APIError", "Invalid authentication token.", {"endpoint": "/api/v1/auth/me", "status": 401})
    error_tracker.track_error("ValidationError", "Missing required field 'title'.", {"field": "title", "input": {"name": "test"}}, level="WARNING")
    
    # ØªØªØ¨Ø¹ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    for i in range(110):
        error_tracker.track_error(f"SimulatedError_{i//10}", f"Simulated error message {i}", {"count": i})
    
    print("\\nRecent errors (max 10):")
    recent_errors = error_tracker.get_recent_errors(limit=5)
    for err in recent_errors:
        print(f"- {err['timestamp']} [{err['level']}] {err['type']}: {err['message']}")
    assert len(recent_errors) <= 5

    print("\\nErrors of type 'DatabaseError':")
    db_errors = error_tracker.get_errors_by_type("DatabaseError")
    for err in db_errors:
        print(f"- {err['timestamp']} [{err['level']}] {err['type']}: {err['message']}")
    assert len(db_errors) == 1

    print("\\nChecking total errors in memory:")
    print(f"Total errors: {len(error_tracker.errors_in_memory)}")
    assert len(error_tracker.errors_in_memory) <= error_tracker.max_errors_in_memory # ÙŠØ¬Ø¨ Ø£Ù† Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 100

    print("\\nClearing all errors...")
    error_tracker.clear_errors()
    print(f"Errors after clear: {len(error_tracker.errors_in_memory)}")
    assert len(error_tracker.errors_in_memory) == 0
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù‚Ø¯ ØªÙ… Ø­Ø°ÙÙ‡
    file_path = os.path.join(MockSettingsForErrorTracker.BASE_DIR, MockSettingsForErrorTracker.ERROR_LOG_FILE)
    print(f"Error log file exists after clear: {os.path.exists(file_path)}")
    assert not os.path.exists(file_path)

    print("\\nError Tracker tests completed.")

asyncio.run(run_error_tracker_tests())
```

```
    file_path = os.path.join(monitoring_path, "diagnostics", "error_tracker.py")
    return write_file_safely(file_path, content)

def create_monitoring_diagnostics_log_analyzer_py():
    """Ø¥Ù†Ø´Ø§Ø¡ monitoring/diagnostics/log_analyzer.py"""
    content = """import re
import os
import json
from collections import Counter
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from utils.logger import get_logger
from core.config import settings

logger = get_logger(__name__)

class LogAnalyzer:
    def __init__(self, log_file_path: str = None):
        self.log_file_path = log_file_path if log_file_path else os.path.join(settings.BASE_DIR, settings.LOG_FILE)
        logger.info(f"LogAnalyzer initialized for log file: {self.log_file_path}")

    async def analyze_logs(self, hours_back: int = 24) -> Dict[str, Any]:
        \"\"\"ÙŠØ­Ù„Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª.\"\"\"
        analysis_results = {
            "total_log_entries": 0,
            "log_level_counts": Counter(),
            "error_types": Counter(),
            "top_messages": Counter(),
            "critical_events": [],
            "start_time": None,
            "end_time": None,
            "file_size_bytes": 0,
            "analysis_timestamp": datetime.now().isoformat()
        }

        if not os.path.exists(self.log_file_path):
            logger.warning(f"Log file not found at {self.log_file_path}. Cannot perform analysis.")
            return {"error": "Log file not found."}

        min_timestamp = datetime.now() - timedelta(hours=hours_back)
        log_file_size = os.path.getsize(self.log_file_path)
        analysis_results["file_size_bytes"] = log_file_size

        try:
            with open(self.log_file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    analysis_results["total_log_entries"] += 1
                    log_entry = self._parse_log_line(line, settings.LOG_FORMAT)
                    
                    if log_entry:
                        log_timestamp_str = log_entry.get("timestamp")
                        if log_timestamp_str:
                            try:
                                log_timestamp = datetime.fromisoformat(log_timestamp_str.replace('Z', '+00:00'))
                                if analysis_results["start_time"] is None or log_timestamp < analysis_results["start_time"]:
                                    analysis_results["start_time"] = log_timestamp
                                if analysis_results["end_time"] is None or log_timestamp > analysis_results["end_time"]:
                                    analysis_results["end_time"] = log_timestamp

                                if log_timestamp < min_timestamp:
                                    continue # ØªØ®Ø·ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©

                            except ValueError:
                                logger.warning(f"Could not parse timestamp from log entry: {log_timestamp_str}")
                                continue

                        level = log_entry.get("level", "UNKNOWN").upper()
                        message = log_entry.get("message", "N/A")
                        
                        analysis_results["log_level_counts"][level] += 1
                        analysis_results["top_messages"][message] += 1

                        if level in ["ERROR", "CRITICAL"]:
                            analysis_results["error_types"][log_entry.get("type", "General Error")] += 1
                            analysis_results["critical_events"].append(log_entry)

            # ÙØ±Ø² Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªÙƒØ±Ø§Ø±Ù‹Ø§
            analysis_results["top_messages"] = analysis_results["top_messages"].most_common(5)
            
            logger.info(f"Log analysis completed for {self.log_file_path}. Total entries: {analysis_results['total_log_entries']}")
            return analysis_results

        except Exception as e:
            logger.error(f"Error during log analysis of {self.log_file_path}: {e}")
            return {"error": f"Error during log analysis: {e}"}

    def _parse_log_line(self, line: str, log_format: str) -> Optional[Dict[str, Any]]:
        \"\"\"
        ÙŠØ­Ù„Ù„ Ø³Ø·Ø±Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚.
        ÙŠØ¯Ø¹Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª JSON Ùˆ Standard.
        \"\"\"
        if log_format == "json":
            try:
                return json.loads(line)
            except json.JSONDecodeError:
                logger.warning(f"Invalid JSON log line: {line.strip()}")
                return None
        else: # Standard format (e.g., "%(asctime)s - %(name)s - %(levelname)s - %(message)s")
            # Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø³ÙŠÙƒÙˆÙ† ØªÙ‚Ø±ÙŠØ¨ÙŠØ§Ù‹ ÙˆÙ‚Ø¯ Ù„Ø§ ÙŠÙƒÙˆÙ† Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©
            match = re.match(r'^(?P<timestamp>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2})) - (?P<name>[\\w.]+) - (?P<level>\\w+) - (?P<message>.*)$', line)
            if match:
                data = match.groupdict()
                # ÙŠÙ…ÙƒÙ† Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ "type" Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                return {
                    "timestamp": data["timestamp"],
                    "name": data["name"],
                    "level": data["level"],
                    "message": data["message"].strip(),
                    "type": "General" # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ØŒ ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡
                }
            # ØªÙ†Ø³ÙŠÙ‚ Ø£Ø¨Ø³Ø· Ù„Ù€ %(asctime)s - %(levelname)s - %(message)s
            match_simple = re.match(r'^(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}(?:,\\d+)?)([ ]*-[ ]*)(?P<level>\\w+)([ ]*-[ ]*)(?P<message>.*)$', line)
            if match_simple:
                data = match_simple.groupdict()
                return {
                    "timestamp": datetime.strptime(data["timestamp"].split(',')[0], '%Y-%m-%d %H:%M:%S').isoformat() + "Z", # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ISO
                    "name": "root", # Ø§ÙØªØ±Ø§Ø¶ÙŠ
                    "level": data["level"],
                    "message": data["message"].strip(),
                    "type": "General"
                }
            logger.warning(f"Could not parse standard log line: {line.strip()}")
            return None

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)
if __name__ == "__main__":
    import asyncio
    import logging
    from core.config import Settings
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø³Ø¬Ù„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    def create_dummy_log_file(file_path, num_entries=50):
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            for i in range(num_entries):
                ts = (datetime.now() - timedelta(minutes=num_entries - i)).isoformat(timespec='seconds') + 'Z'
                if i % 10 == 0:
                    f.write(json.dumps({"timestamp": ts, "name": "app.core", "level": "ERROR", "message": f"Database connection failed. Attempt {i/10}", "type": "DB_CONNECT_ERROR"}) + "\\n")
                elif i % 7 == 0:
                    f.write(json.dumps({"timestamp": ts, "name": "api.auth", "level": "WARNING", "message": f"Invalid login attempt for user: user{i}", "type": "AUTH_FAILED"}) + "\\n")
                else:
                    f.write(json.dumps({"timestamp": ts, "name": "app.service", "level": "INFO", "message": f"Processed request {i}", "type": "REQUEST_INFO"}) + "\\n")
            
            # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¬Ø¯Ø§Ù‹
            for i in range(5):
                ts_old = (datetime.now() - timedelta(days=2, minutes=i)).isoformat(timespec='seconds') + 'Z'
                f.write(json.dumps({"timestamp": ts_old, "name": "old.log", "level": "DEBUG", "message": f"Old log entry {i}", "type": "OLD_DATA"}) + "\\n")

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    class MockSettingsForLogAnalyzer(Settings):
        LOG_LEVEL = "INFO"
        LOG_TO_FILE = True # Ù„Ø¬Ø¹Ù„ logger ÙŠÙƒØªØ¨ Ø¥Ù„Ù‰ Ù…Ù„Ù (Ù…Ø·Ù„ÙˆØ¨ Ù„Ù€ LogAnalyzer)
        LOG_FILE = "data/logs/app_test_analyzer.log" # Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡
        LOG_FORMAT = "json"
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        # ØªØ£ÙƒØ¯ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø± ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ LOG_FILE ÙÙŠ LogAnalyzer
        
    import sys
    sys.modules['core.config'] = type('module', (object,), {'settings': MockSettingsForLogAnalyzer()})()

    # Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ¬ÙŠÙ‡ Ù…Ø³Ø§Ø± Ø§Ù„Ø³Ø¬Ù„ ÙÙŠ LogAnalyzer Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    log_file_for_analyzer = os.path.join(MockSettingsForLogAnalyzer.BASE_DIR, MockSettingsForLogAnalyzer.LOG_FILE)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø³Ø¬Ù„ ÙˆÙ‡Ù…ÙŠ
    print(f"Creating dummy log file at: {log_file_for_analyzer}")
    create_dummy_log_file(log_file_for_analyzer)
    
    analyzer = LogAnalyzer(log_file_path=log_file_for_analyzer)

    async def run_log_analyzer_tests():
        print("--- Testing Log Analyzer ---")
        
        print("\\nAnalyzing logs for last 24 hours...")
        analysis_results = await analyzer.analyze_logs(hours_back=24)
        
        if "error" in analysis_results:
            print(f"Analysis Error: {analysis_results['error']}")
        else:
            print("\\n--- Analysis Results ---")
            print(f"Total Log Entries processed: {analysis_results['total_log_entries']}")
            print(f"Log File Size: {analysis_results['file_size_bytes']} bytes")
            print(f"Analysis Period: {analysis_results.get('start_time')} to {analysis_results.get('end_time')}")
            print("\\nLog Level Counts:")
            for level, count in analysis_results["log_level_counts"].items():
                print(f"  {level}: {count}")
            
            print("\\nError Types:")
            for error_type, count in analysis_results["error_types"].items():
                print(f"  {error_type}: {count}")
                
            print("\\nTop 5 Most Common Messages:")
            for message, count in analysis_results["top_messages"]:
                print(f"  '{message}': {count}")
                
            print("\\nCritical Events (last 5):")
            for event in analysis_results["critical_events"][-5:]:
                print(f"  [{event.get('timestamp')}] [{event.get('level')}]: {event.get('message')}")
            
            # ØªØ­Ù‚Ù‚ Ø¨Ø³ÙŠØ·
            assert analysis_results["total_log_entries"] > 0
            assert analysis_results["log_level_counts"]["INFO"] > 0
            assert analysis_results["log_level_counts"]["ERROR"] > 0
            assert len(analysis_results["critical_events"]) > 0

        print("\\nLog Analyzer tests completed. Review the output above.")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙˆÙ‡Ù…ÙŠ
        os.remove(log_file_for_analyzer)
        print(f"Cleaned up dummy log file: {log_file_for_analyzer}")

    asyncio.run(run_log_analyzer_tests())
"""
    file_path = os.path.join(monitoring_path, "diagnostics", "log_analyzer.py")
    return write_file_safely(file_path, content)


# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§
monitoring_files = [
    ("performance/metrics_collector.py", create_monitoring_performance_metrics_collector_py),
    ("performance/performance_monitor.py", create_monitoring_performance_performance_monitor_py),
    ("performance/alert_system.py", create_monitoring_performance_alert_system_py),
    ("quality/quality_assurance.py", create_monitoring_quality_quality_assurance_py),
    ("quality/automated_testing.py", create_monitoring_quality_automated_testing_py),
    ("diagnostics/system_diagnostics.py", create_monitoring_diagnostics_system_diagnostics_py),
    ("diagnostics/error_tracker.py", create_monitoring_diagnostics_error_tracker_py),
    ("diagnostics/log_analyzer.py", create_monitoring_diagnostics_log_analyzer_py),
]

print("ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `monitoring`...")

created_monitoring_files_count = 0
for relative_path, create_function in monitoring_files:
    full_path = os.path.join(monitoring_path, relative_path)
    print(f"\nğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù: {relative_path}...")
    if create_function():
        created_monitoring_files_count += 1
        size = os.path.getsize(full_path)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {relative_path} Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ø­Ø¬Ù…: {size} Ø¨Ø§ÙŠØª")
    else:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ {relative_path}.")

print(f"\nğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {created_monitoring_files_count} Ù…Ù„Ù Ù…Ù† Ø£ØµÙ„ {len(monitoring_files)} ÙÙŠ Ù…Ø¬Ù„Ø¯ monitoring Ø¨Ù†Ø¬Ø§Ø­.")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§
print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„ÙØ§Øª monitoring Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©:")
for relative_path, _ in monitoring_files:
    full_path = os.path.join(monitoring_path, relative_path)
    if os.path.exists(full_path):
        size = os.path.getsize(full_path)
        print(f"  âœ… {relative_path} ({size} bytes)")
    else:
        print(f"  âŒ {relative_path} (Ù…ÙÙ‚ÙˆØ¯)")

print("\nğŸ‰ ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ù„Ù‚Ø¯ ØªÙ… Ø§Ù„Ø¢Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ `monitoring`.")
print("ğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ `management`.")
```

-----

### ğŸ“ Ù…Ù„Ø®Øµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `monitoring`

Ù„Ù‚Ø¯ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¹Ø¨Ø¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ **`monitoring`**. Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø­ÙŠÙˆÙŠ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØµØ­Ø© ÙˆØ£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ ÙˆØªÙˆÙÙŠØ± Ø±Ø¤Ù‰ Ù‚ÙŠÙ…Ø© Ø­ÙˆÙ„ Ø¹Ù…Ù„Ù‡.

Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© ØªØ´Ù…Ù„:

  * **`monitoring/performance/metrics_collector.py`**: ÙŠØ¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `Prometheus client`ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©ØŒ ÙˆØ¹Ø¯Ø¯ Ø·Ù„Ø¨Ø§Øª HTTP ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ®Ø¯Ù…Ø§Øª AI.
  * **`monitoring/performance/performance_monitor.py`**: ÙŠØªØªØ¨Ø¹ ÙˆÙŠØ­Ù„Ù„ Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø·Ù„Ø¨Ø§ØªØŒ ÙˆØ§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØ§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª AIØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ ÙˆÙŠÙˆÙØ± Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡.
  * **`monitoring/performance/alert_system.py`**: ÙŠØ¯ÙŠØ± Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹ØªØ¨Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø£Ùˆ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ ÙˆÙŠØ³ØªØ®Ø¯Ù… `NotificationService` Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª.
  * **`monitoring/quality/quality_assurance.py`**: ÙŠÙˆÙØ± Ø¯ÙˆØ§Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†ØµÙˆØµ (Ù…Ø«Ù„ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ©) ÙˆÙƒØ´Ù Ø§Ù„Ø§Ù†ØªØ­Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø§Øª AIØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
  * **`monitoring/quality/automated_testing.py`**: ÙŠÙ‚Ø¯Ù… Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø£Ø³Ø§Ø³ÙŠ Ù„Ø¥Ø¶Ø§ÙØ© ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¢Ù„ÙŠØ© (Ø§Ù„ÙˆØ­Ø¯Ø©ØŒ Ø§Ù„ØªÙƒØ§Ù…Ù„ØŒ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©) Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø£Ùˆ ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª.
  * **`monitoring/diagnostics/system_diagnostics.py`**: ÙŠØ¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø© Ø­ÙˆÙ„ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ù‚Ø±Øµ ÙˆØ§Ù„Ø´Ø¨ÙƒØ©ØŒ Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª.
  * **`monitoring/diagnostics/error_tracker.py`**: ÙŠØªØªØ¨Ø¹ ÙˆÙŠØ³Ø¬Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ØŒ ÙˆÙŠØ­ØªÙØ¸ Ø¨Ø³Ø¬Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ù„Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ÙÙˆØ±ÙŠ) ÙˆÙÙŠ Ù…Ù„Ù (Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø³ØªÙ…Ø±)ØŒ Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹.
  * **`monitoring/diagnostics/log_analyzer.py`**: ÙŠØ­Ù„Ù„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø³Ø¬Ù„ (JSON Ø£Ùˆ Ù‚ÙŠØ§Ø³ÙŠØ©) Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø«Ù„ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©ØŒ ÙˆØ£Ù‡Ù… Ø§Ù„Ø±Ø³Ø§Ø¦Ù„.

**Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…Ù„ÙØ§Øª `monitoring` Ø§Ù„ØªÙŠ ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§:**

  * **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¨Ù†Ø¬Ø§Ø­**: 8/8

-----

Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Ù†Ø§ Ø§Ù„Ø¢Ù† Ø¬Ø²Ø¡Ù‹Ø§ Ù‡Ø§Ù…Ù‹Ø§ Ù…Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹. ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø³Ù†Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ **`management`** Ø§Ù„Ø°ÙŠ Ø³ÙŠØªØ¶Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ± ÙˆØ§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¢Ù„ÙŠØ©.

Ù‡Ù„ Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…Ø¬Ù„Ø¯ `management`ØŸ